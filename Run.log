

======================================================
*********************************************************
Start logging 20130305172410
 ../Util/Log.pyc

[17.24.11]	M5_L_STM: Start constructing Bog
[17.24.11]	BogBuilder.GetBog(
/home/xj229/data/7nat_lvl123_6000each.sen ->
 /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.arff
[17.24.32]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[17.24.32]	[BogBuilder] First pass vocab scan, #vocab = 30988
[17.24.32]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6536
[17.24.56]	Done! Number of instance wrote: 208906
[17.24.56]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.arff -o /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.libsvm
[17.25.06]	Finished, output to:
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.arff
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.libsvm

[17.25.06]	M10_L_STM: Start constructing Bog
[17.25.06]	BogBuilder.GetBog(
/home/xj229/data/7nat_lvl123_6000each.sen ->
 /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM.arff
[17.25.27]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:10 -alphanumonly:False
[17.25.27]	[BogBuilder] First pass vocab scan, #vocab = 30988
[17.25.27]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 4025
[17.25.51]	Done! Number of instance wrote: 208885
[17.25.51]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM.arff -o /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM.libsvm
[17.25.58]	Finished, output to:
/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM.arff
/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM.libsvm

[17.25.58]	M5_STM: Start constructing Bog
[17.25.58]	BogBuilder.GetBog(
/home/xj229/data/7nat_lvl123_6000each.sen ->
 /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM.arff
[17.26.19]	BOG setting: BogBuilder -stmmer:True -lower:False -minFreq:5 -alphanumonly:False
[17.26.19]	[BogBuilder] First pass vocab scan, #vocab = 36898
[17.26.19]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 7546
[17.26.43]	Done! Number of instance wrote: 208896
[17.26.43]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM.arff -o /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM.libsvm
[17.26.54]	Finished, output to:
/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM.arff
/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM.libsvm

[17.26.54]	M5_L: Start constructing Bog
[17.26.54]	BogBuilder.GetBog(
/home/xj229/data/7nat_lvl123_6000each.sen ->
 /home/xj229/data/7nat_lvl123_6000each.bog_M5_L.arff
[17.27.00]	BOG setting: BogBuilder -stmmer:False -lower:True -minFreq:5 -alphanumonly:False
[17.27.00]	[BogBuilder] First pass vocab scan, #vocab = 36047
[17.27.00]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 7476
[17.27.10]	Done! Number of instance wrote: 208903
[17.27.10]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/7nat_lvl123_6000each.bog_M5_L.arff -o /home/xj229/data/7nat_lvl123_6000each.bog_M5_L.libsvm
[17.27.21]	Finished, output to:
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L.arff
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L.libsvm

[17.27.21]	M5_L_STM_ALPHANUM: Start constructing Bog
[17.27.21]	BogBuilder.GetBog(
/home/xj229/data/7nat_lvl123_6000each.sen ->
 /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.arff
[17.27.42]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:True
[17.27.42]	[BogBuilder] First pass vocab scan, #vocab = 25112
[17.27.42]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 5791
[17.28.06]	Done! Number of instance wrote: 208845
[17.28.06]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.arff -o /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.libsvm
[17.28.14]	Finished, output to:
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.arff
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.libsvm

[17.28.14]	M5_L_STM_RMSTP: Start constructing Bog
[17.28.14]	BogBuilder.GetBog(
/home/xj229/data/7nat_lvl123_6000each.sen ->
 /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.arff
[17.28.31]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[17.28.31]	[BogBuilder] First pass vocab scan, #vocab = 30808
[17.28.31]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6295
[17.28.50]	Done! Number of instance wrote: 203805
[17.28.50]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.arff -o /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.libsvm
[17.28.59]	Finished, output to:
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.arff
/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.libsvm



======================================================
*********************************************************
Start logging 20130305173159
 /home/xj229/workspace/AcsProj/Util/Log.py

[17.31.59]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM
[17.31.59]	nFold Splitting! Original data set size: 208906
New nFold result size:
	Fold 0 -> 52223
	Fold 1 -> 52223
	Fold 2 -> 52223
	Fold 3 -> 52237
Total = 208906

[17.31.59]	Fold 0 test, 52223 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm
[17.31.59]	Fold 0 train, 156683 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm
[17.32.00]	Fold 1 test, 52223 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm
[17.32.00]	Fold 1 train, 156683 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm
[17.32.00]	Fold 2 test, 52223 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm
[17.32.00]	Fold 2 train, 156683 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm
[17.32.00]	Fold 3 test, 52237 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm
[17.32.00]	Fold 3 train, 156669 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm
[17.32.00]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm
[17.32.00]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm.model
[17.32.57]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm
[17.32.57]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[17.32.57]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[17.32.57]	lable [1]: tp=2208, fp=2912, fn=4607, tn=42496, total=52223
P=0.43125, R=0.32399, F1=0.37000

[17.32.57]	lable [0]: tp=3137, fp=4146, fn=5163, tn=39777, total=52223
P=0.43073, R=0.37795, F1=0.40262

[17.32.57]	lable [3]: tp=2601, fp=2938, fn=4855, tn=41829, total=52223
P=0.46958, R=0.34885, F1=0.40031

[17.32.57]	lable [2]: tp=5819, fp=9757, fn=3184, tn=33463, total=52223
P=0.37359, R=0.64634, F1=0.47349

[17.32.57]	lable [5]: tp=3127, fp=5664, fn=4485, tn=38947, total=52223
P=0.35570, R=0.41080, F1=0.38127

[17.32.57]	lable [4]: tp=1826, fp=1979, fn=4463, tn=43955, total=52223
P=0.47989, R=0.29035, F1=0.36180

[17.32.57]	lable [6]: tp=2665, fp=3444, fn=4083, tn=42031, total=52223
P=0.43624, R=0.39493, F1=0.41456

[17.32.57]	Average F1 = 0.40058
Accuracy = 21383/52223 = 0.409456
[17.32.57]	Got evaluation for current fold, Avg. F1 = 0.40058
[17.32.57]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm
[17.32.57]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm.model
[17.33.40]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm
[17.33.40]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[17.33.40]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[17.33.40]	lable [1]: tp=2456, fp=3085, fn=4359, tn=42323, total=52223
P=0.44324, R=0.36038, F1=0.39754

[17.33.40]	lable [0]: tp=3119, fp=4442, fn=5181, tn=39481, total=52223
P=0.41251, R=0.37578, F1=0.39329

[17.33.40]	lable [3]: tp=2682, fp=3321, fn=4774, tn=41446, total=52223
P=0.44678, R=0.35971, F1=0.39854

[17.33.40]	lable [2]: tp=5583, fp=8657, fn=3420, tn=34563, total=52223
P=0.39206, R=0.62013, F1=0.48040

[17.33.40]	lable [5]: tp=3203, fp=5042, fn=4409, tn=39569, total=52223
P=0.38848, R=0.42078, F1=0.40399

[17.33.40]	lable [4]: tp=1934, fp=2398, fn=4355, tn=43536, total=52223
P=0.44645, R=0.30752, F1=0.36418

[17.33.40]	lable [6]: tp=2749, fp=3552, fn=3999, tn=41923, total=52223
P=0.43628, R=0.40738, F1=0.42133

[17.33.40]	Average F1 = 0.40847
Accuracy = 21726/52223 = 0.416024
[17.33.40]	Got evaluation for current fold, Avg. F1 = 0.40847
[17.33.40]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm
[17.33.40]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm.model
[17.34.22]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm
[17.34.22]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[17.34.22]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[17.34.23]	lable [1]: tp=2378, fp=3148, fn=4437, tn=42260, total=52223
P=0.43033, R=0.34894, F1=0.38538

[17.34.23]	lable [0]: tp=2963, fp=4006, fn=5337, tn=39917, total=52223
P=0.42517, R=0.35699, F1=0.38811

[17.34.23]	lable [3]: tp=2809, fp=3554, fn=4647, tn=41213, total=52223
P=0.44146, R=0.37674, F1=0.40654

[17.34.23]	lable [2]: tp=5466, fp=9161, fn=3537, tn=34059, total=52223
P=0.37369, R=0.60713, F1=0.46263

[17.34.23]	lable [5]: tp=3151, fp=5267, fn=4461, tn=39344, total=52223
P=0.37432, R=0.41395, F1=0.39314

[17.34.23]	lable [4]: tp=1792, fp=2145, fn=4497, tn=43789, total=52223
P=0.45517, R=0.28494, F1=0.35048

[17.34.23]	lable [6]: tp=2575, fp=3808, fn=4173, tn=41667, total=52223
P=0.40342, R=0.38159, F1=0.39220

[17.34.23]	Average F1 = 0.39693
Accuracy = 21134/52223 = 0.404688
[17.34.23]	Got evaluation for current fold, Avg. F1 = 0.39693
[17.34.23]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm
[17.34.23]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm.model
[17.35.04]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm
[17.35.04]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[17.35.04]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[17.35.05]	lable [1]: tp=2235, fp=2901, fn=4582, tn=42519, total=52237
P=0.43516, R=0.32786, F1=0.37396

[17.35.05]	lable [0]: tp=3151, fp=4478, fn=5150, tn=39458, total=52237
P=0.41303, R=0.37959, F1=0.39561

[17.35.05]	lable [3]: tp=2745, fp=3750, fn=4714, tn=41028, total=52237
P=0.42263, R=0.36801, F1=0.39344

[17.35.05]	lable [2]: tp=5494, fp=8880, fn=3512, tn=34351, total=52237
P=0.38222, R=0.61004, F1=0.46997

[17.35.05]	lable [5]: tp=3090, fp=5684, fn=4524, tn=38939, total=52237
P=0.35218, R=0.40583, F1=0.37711

[17.35.05]	lable [4]: tp=1926, fp=2316, fn=4366, tn=43629, total=52237
P=0.45403, R=0.30610, F1=0.36567

[17.35.05]	lable [6]: tp=2518, fp=3069, fn=4230, tn=42420, total=52237
P=0.45069, R=0.37315, F1=0.40827

[17.35.05]	Average F1 = 0.39772
Accuracy = 21159/52237 = 0.405058
[17.35.05]	Got evaluation for current fold, Avg. F1 = 0.39772
[17.35.05]	Evaluation Done! Final after 4-fold Avg. F1 = 0.40092
[17.35.05]	

Perfmon Summary:
Time Used(s): 185.646250
Memory Used (Mb): 41.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	42456
ru_minflt ->	52479
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	193
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	18
ru_oublock ->	7824
ru_stime ->	0.152009
ru_utime ->	183.111443

=========== ======== ============
		
[17.35.05]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM
[17.35.05]	nFold Splitting! Original data set size: 208885
New nFold result size:
	Fold 0 -> 52219
	Fold 1 -> 52219
	Fold 2 -> 52219
	Fold 3 -> 52228
Total = 208885

[17.35.05]	Fold 0 test, 52219 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm
[17.35.05]	Fold 0 train, 156666 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm
[17.35.05]	Fold 1 test, 52219 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm
[17.35.05]	Fold 1 train, 156666 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm
[17.35.05]	Fold 2 test, 52219 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm
[17.35.05]	Fold 2 train, 156666 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm
[17.35.06]	Fold 3 test, 52228 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm
[17.35.06]	Fold 3 train, 156657 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm
[17.35.06]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm
[17.35.06]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm.model
[17.35.47]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm
[17.35.47]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[17.35.47]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[17.35.48]	lable [1]: tp=2107, fp=2948, fn=4708, tn=42456, total=52219
P=0.41682, R=0.30917, F1=0.35501

[17.35.48]	lable [0]: tp=3012, fp=4104, fn=5287, tn=39816, total=52219
P=0.42327, R=0.36294, F1=0.39079

[17.35.48]	lable [3]: tp=2507, fp=3164, fn=4949, tn=41599, total=52219
P=0.44207, R=0.33624, F1=0.38196

[17.35.48]	lable [2]: tp=5764, fp=10233, fn=3239, tn=32983, total=52219
P=0.36032, R=0.64023, F1=0.46112

[17.35.48]	lable [5]: tp=2951, fp=5693, fn=4660, tn=38915, total=52219
P=0.34139, R=0.38773, F1=0.36309

[17.35.48]	lable [4]: tp=1681, fp=1876, fn=4607, tn=44055, total=52219
P=0.47259, R=0.26733, F1=0.34149

[17.35.48]	lable [6]: tp=2565, fp=3614, fn=4182, tn=41858, total=52219
P=0.41512, R=0.38017, F1=0.39687

[17.35.48]	Average F1 = 0.38433
Accuracy = 20587/52219 = 0.394243
[17.35.48]	Got evaluation for current fold, Avg. F1 = 0.38433
[17.35.48]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm
[17.35.48]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm.model
[17.36.31]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm
[17.36.31]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[17.36.31]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[17.36.31]	lable [1]: tp=2323, fp=3144, fn=4492, tn=42260, total=52219
P=0.42491, R=0.34087, F1=0.37828

[17.36.31]	lable [0]: tp=2954, fp=4323, fn=5345, tn=39597, total=52219
P=0.40594, R=0.35595, F1=0.37930

[17.36.31]	lable [3]: tp=2589, fp=3521, fn=4867, tn=41242, total=52219
P=0.42373, R=0.34724, F1=0.38169

[17.36.31]	lable [2]: tp=5548, fp=9195, fn=3455, tn=34021, total=52219
P=0.37631, R=0.61624, F1=0.46728

[17.36.31]	lable [5]: tp=3049, fp=5200, fn=4562, tn=39408, total=52219
P=0.36962, R=0.40060, F1=0.38449

[17.36.31]	lable [4]: tp=1790, fp=2404, fn=4498, tn=43527, total=52219
P=0.42680, R=0.28467, F1=0.34154

[17.36.31]	lable [6]: tp=2628, fp=3551, fn=4119, tn=41921, total=52219
P=0.42531, R=0.38951, F1=0.40662

[17.36.31]	Average F1 = 0.39131
Accuracy = 20881/52219 = 0.399874
[17.36.31]	Got evaluation for current fold, Avg. F1 = 0.39131
[17.36.31]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm
[17.36.31]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm.model
[17.37.13]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm
[17.37.13]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[17.37.13]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[17.37.13]	lable [1]: tp=2198, fp=3132, fn=4617, tn=42272, total=52219
P=0.41238, R=0.32252, F1=0.36196

[17.37.13]	lable [0]: tp=2847, fp=4027, fn=5452, tn=39893, total=52219
P=0.41417, R=0.34305, F1=0.37527

[17.37.13]	lable [3]: tp=2657, fp=3708, fn=4799, tn=41055, total=52219
P=0.41744, R=0.35636, F1=0.38449

[17.37.13]	lable [2]: tp=5458, fp=9839, fn=3545, tn=33377, total=52219
P=0.35680, R=0.60624, F1=0.44922

[17.37.13]	lable [5]: tp=2959, fp=5244, fn=4652, tn=39364, total=52219
P=0.36072, R=0.38878, F1=0.37423

[17.37.13]	lable [4]: tp=1703, fp=2103, fn=4585, tn=43828, total=52219
P=0.44745, R=0.27083, F1=0.33743

[17.37.13]	lable [6]: tp=2501, fp=3843, fn=4246, tn=41629, total=52219
P=0.39423, R=0.37068, F1=0.38209

[17.37.13]	Average F1 = 0.38067
Accuracy = 20323/52219 = 0.389188
[17.37.13]	Got evaluation for current fold, Avg. F1 = 0.38067
[17.37.13]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm
[17.37.13]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm.model
[17.37.56]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm
[17.37.56]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[17.37.56]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[17.37.56]	lable [1]: tp=2103, fp=2981, fn=4712, tn=42432, total=52228
P=0.41365, R=0.30858, F1=0.35348

[17.37.56]	lable [0]: tp=3022, fp=4420, fn=5278, tn=39508, total=52228
P=0.40607, R=0.36410, F1=0.38394

[17.37.56]	lable [3]: tp=2673, fp=3896, fn=4784, tn=40875, total=52228
P=0.40691, R=0.35846, F1=0.38115

[17.37.56]	lable [2]: tp=5475, fp=9353, fn=3529, tn=33871, total=52228
P=0.36923, R=0.60806, F1=0.45947

[17.37.56]	lable [5]: tp=2917, fp=5711, fn=4696, tn=38904, total=52228
P=0.33809, R=0.38316, F1=0.35921

[17.37.56]	lable [4]: tp=1768, fp=2251, fn=4523, tn=43686, total=52228
P=0.43991, R=0.28104, F1=0.34297

[17.37.56]	lable [6]: tp=2415, fp=3243, fn=4333, tn=42237, total=52228
P=0.42683, R=0.35788, F1=0.38933

[17.37.56]	Average F1 = 0.38136
Accuracy = 20373/52228 = 0.390078
[17.37.56]	Got evaluation for current fold, Avg. F1 = 0.38136
[17.37.56]	Evaluation Done! Final after 4-fold Avg. F1 = 0.38442
[17.37.56]	

Perfmon Summary:
Time Used(s): 171.330652
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	42456
ru_minflt ->	52479
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	193
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	18
ru_oublock ->	7824
ru_stime ->	0.152009
ru_utime ->	183.111443

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	42456
ru_minflt ->	104467
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	367
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	34
ru_oublock ->	13040
ru_stime ->	0.216013
ru_utime ->	352.005999

=========== ======== ============
		
[17.37.56]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM
[17.37.56]	nFold Splitting! Original data set size: 208896
New nFold result size:
	Fold 0 -> 52221
	Fold 1 -> 52221
	Fold 2 -> 52221
	Fold 3 -> 52233
Total = 208896

[17.37.56]	Fold 0 test, 52221 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm
[17.37.57]	Fold 0 train, 156675 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm
[17.37.57]	Fold 1 test, 52221 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm
[17.37.57]	Fold 1 train, 156675 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm
[17.37.57]	Fold 2 test, 52221 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm
[17.37.57]	Fold 2 train, 156675 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm
[17.37.57]	Fold 3 test, 52233 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm
[17.37.57]	Fold 3 train, 156663 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm
[17.37.57]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm
[17.37.57]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm.model
[17.38.39]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm
[17.38.39]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[17.38.39]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[17.38.40]	lable [1]: tp=2285, fp=2896, fn=4530, tn=42510, total=52221
P=0.44103, R=0.33529, F1=0.38096

[17.38.40]	lable [0]: tp=3534, fp=5354, fn=4766, tn=38567, total=52221
P=0.39761, R=0.42578, F1=0.41122

[17.38.40]	lable [3]: tp=2571, fp=2843, fn=4885, tn=41922, total=52221
P=0.47488, R=0.34482, F1=0.39953

[17.38.40]	lable [2]: tp=5648, fp=8900, fn=3355, tn=34318, total=52221
P=0.38823, R=0.62735, F1=0.47964

[17.38.40]	lable [5]: tp=3161, fp=5721, fn=4451, tn=38888, total=52221
P=0.35589, R=0.41527, F1=0.38329

[17.38.40]	lable [4]: tp=1815, fp=2079, fn=4473, tn=43854, total=52221
P=0.46610, R=0.28865, F1=0.35651

[17.38.40]	lable [6]: tp=2555, fp=2859, fn=4192, tn=42615, total=52221
P=0.47192, R=0.37869, F1=0.42020

[17.38.40]	Average F1 = 0.40448
Accuracy = 21569/52221 = 0.413033
[17.38.40]	Got evaluation for current fold, Avg. F1 = 0.40448
[17.38.40]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm
[17.38.40]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm.model
[17.39.21]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm
[17.39.21]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[17.39.22]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[17.39.22]	lable [1]: tp=2473, fp=2985, fn=4342, tn=42421, total=52221
P=0.45310, R=0.36288, F1=0.40300

[17.39.22]	lable [0]: tp=3564, fp=5621, fn=4736, tn=38300, total=52221
P=0.38802, R=0.42940, F1=0.40766

[17.39.22]	lable [3]: tp=2694, fp=3227, fn=4762, tn=41538, total=52221
P=0.45499, R=0.36132, F1=0.40278

[17.39.22]	lable [2]: tp=5573, fp=8390, fn=3430, tn=34828, total=52221
P=0.39913, R=0.61902, F1=0.48533

[17.39.22]	lable [5]: tp=3093, fp=4684, fn=4519, tn=39925, total=52221
P=0.39771, R=0.40633, F1=0.40198

[17.39.22]	lable [4]: tp=1946, fp=2325, fn=4342, tn=43608, total=52221
P=0.45563, R=0.30948, F1=0.36860

[17.39.22]	lable [6]: tp=2660, fp=2986, fn=4087, tn=42488, total=52221
P=0.47113, R=0.39425, F1=0.42927

[17.39.22]	Average F1 = 0.41409
Accuracy = 22003/52221 = 0.421344
[17.39.22]	Got evaluation for current fold, Avg. F1 = 0.41409
[17.39.22]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm
[17.39.22]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm.model
[17.40.03]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm
[17.40.03]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[17.40.03]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[17.40.04]	lable [1]: tp=2312, fp=2901, fn=4503, tn=42505, total=52221
P=0.44351, R=0.33925, F1=0.38444

[17.40.04]	lable [0]: tp=3407, fp=5029, fn=4893, tn=38892, total=52221
P=0.40386, R=0.41048, F1=0.40715

[17.40.04]	lable [3]: tp=2798, fp=3265, fn=4658, tn=41500, total=52221
P=0.46149, R=0.37527, F1=0.41394

[17.40.04]	lable [2]: tp=5380, fp=8906, fn=3623, tn=34312, total=52221
P=0.37659, R=0.59758, F1=0.46202

[17.40.04]	lable [5]: tp=3198, fp=5464, fn=4414, tn=39145, total=52221
P=0.36920, R=0.42013, F1=0.39302

[17.40.04]	lable [4]: tp=1860, fp=2159, fn=4428, tn=43774, total=52221
P=0.46280, R=0.29580, F1=0.36092

[17.40.04]	lable [6]: tp=2526, fp=3016, fn=4221, tn=42458, total=52221
P=0.45579, R=0.37439, F1=0.41110

[17.40.04]	Average F1 = 0.40465
Accuracy = 21481/52221 = 0.411348
[17.40.04]	Got evaluation for current fold, Avg. F1 = 0.40465
[17.40.04]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm
[17.40.04]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm.model
[17.40.46]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm
[17.40.46]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[17.40.46]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[17.40.46]	lable [1]: tp=2252, fp=2939, fn=4565, tn=42477, total=52233
P=0.43383, R=0.33035, F1=0.37508

[17.40.46]	lable [0]: tp=3559, fp=5602, fn=4742, tn=38330, total=52233
P=0.38849, R=0.42874, F1=0.40763

[17.40.46]	lable [3]: tp=2756, fp=3707, fn=4702, tn=41068, total=52233
P=0.42643, R=0.36954, F1=0.39595

[17.40.46]	lable [2]: tp=5408, fp=8441, fn=3597, tn=34787, total=52233
P=0.39050, R=0.60056, F1=0.47327

[17.40.46]	lable [5]: tp=2918, fp=5110, fn=4695, tn=39510, total=52233
P=0.36348, R=0.38329, F1=0.37312

[17.40.46]	lable [4]: tp=1918, fp=2218, fn=4373, tn=43724, total=52233
P=0.46373, R=0.30488, F1=0.36789

[17.40.46]	lable [6]: tp=2511, fp=2894, fn=4237, tn=42591, total=52233
P=0.46457, R=0.37211, F1=0.41323

[17.40.46]	Average F1 = 0.40088
Accuracy = 21322/52233 = 0.408209
[17.40.46]	Got evaluation for current fold, Avg. F1 = 0.40088
[17.40.46]	Evaluation Done! Final after 4-fold Avg. F1 = 0.40603
[17.40.46]	

Perfmon Summary:
Time Used(s): 170.320693
Memory Used (Mb): 4.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	42456
ru_minflt ->	104467
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	367
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	34
ru_oublock ->	13040
ru_stime ->	0.216013
ru_utime ->	352.005999

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	157114
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	542
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	50
ru_oublock ->	21920
ru_stime ->	0.348021
ru_utime ->	519.776484

=========== ======== ============
		
[17.40.46]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L
[17.40.47]	nFold Splitting! Original data set size: 208903
New nFold result size:
	Fold 0 -> 52223
	Fold 1 -> 52223
	Fold 2 -> 52223
	Fold 3 -> 52234
Total = 208903

[17.40.47]	Fold 0 test, 52223 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm
[17.40.47]	Fold 0 train, 156680 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm
[17.40.47]	Fold 1 test, 52223 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm
[17.40.47]	Fold 1 train, 156680 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm
[17.40.47]	Fold 2 test, 52223 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm
[17.40.47]	Fold 2 train, 156680 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm
[17.40.47]	Fold 3 test, 52234 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm
[17.40.47]	Fold 3 train, 156669 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm
[17.40.47]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm
[17.40.47]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm.model
[17.41.27]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm
[17.41.27]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm.predict
[17.41.27]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm.predict
[17.41.27]	lable [1]: tp=2252, fp=2804, fn=4563, tn=42604, total=52223
P=0.44541, R=0.33045, F1=0.37941

[17.41.27]	lable [0]: tp=3264, fp=4607, fn=5036, tn=39316, total=52223
P=0.41469, R=0.39325, F1=0.40369

[17.41.27]	lable [3]: tp=2593, fp=2941, fn=4863, tn=41826, total=52223
P=0.46856, R=0.34777, F1=0.39923

[17.41.27]	lable [2]: tp=5888, fp=9632, fn=3115, tn=33588, total=52223
P=0.37938, R=0.65400, F1=0.48020

[17.41.27]	lable [5]: tp=3160, fp=5491, fn=4452, tn=39120, total=52223
P=0.36528, R=0.41513, F1=0.38861

[17.41.27]	lable [4]: tp=1880, fp=2048, fn=4409, tn=43886, total=52223
P=0.47862, R=0.29893, F1=0.36801

[17.41.27]	lable [6]: tp=2628, fp=3035, fn=4120, tn=42440, total=52223
P=0.46406, R=0.38945, F1=0.42350

[17.41.27]	Average F1 = 0.40609
Accuracy = 21665/52223 = 0.414856
[17.41.27]	Got evaluation for current fold, Avg. F1 = 0.40609
[17.41.27]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm
[17.41.27]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm.model
[17.42.08]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm
[17.42.08]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm.predict
[17.42.08]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm.predict
[17.42.09]	lable [1]: tp=2458, fp=2917, fn=4357, tn=42491, total=52223
P=0.45730, R=0.36067, F1=0.40328

[17.42.09]	lable [0]: tp=3203, fp=4821, fn=5097, tn=39102, total=52223
P=0.39918, R=0.38590, F1=0.39243

[17.42.09]	lable [3]: tp=2721, fp=3263, fn=4735, tn=41504, total=52223
P=0.45471, R=0.36494, F1=0.40491

[17.42.09]	lable [2]: tp=5553, fp=8447, fn=3450, tn=34773, total=52223
P=0.39664, R=0.61679, F1=0.48281

[17.42.09]	lable [5]: tp=3196, fp=5058, fn=4416, tn=39553, total=52223
P=0.38721, R=0.41986, F1=0.40287

[17.42.09]	lable [4]: tp=2004, fp=2543, fn=4285, tn=43391, total=52223
P=0.44073, R=0.31865, F1=0.36988

[17.42.09]	lable [6]: tp=2751, fp=3288, fn=3997, tn=42187, total=52223
P=0.45554, R=0.40768, F1=0.43028

[17.42.09]	Average F1 = 0.41235
Accuracy = 21886/52223 = 0.419087
[17.42.09]	Got evaluation for current fold, Avg. F1 = 0.41235
[17.42.09]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm
[17.42.09]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm.model
[17.42.48]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm
[17.42.48]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm.predict
[17.42.48]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm.predict
[17.42.48]	lable [1]: tp=2397, fp=3050, fn=4418, tn=42358, total=52223
P=0.44006, R=0.35172, F1=0.39096

[17.42.48]	lable [0]: tp=3040, fp=4221, fn=5260, tn=39702, total=52223
P=0.41868, R=0.36627, F1=0.39072

[17.42.48]	lable [3]: tp=2781, fp=3476, fn=4675, tn=41291, total=52223
P=0.44446, R=0.37299, F1=0.40560

[17.42.48]	lable [2]: tp=5487, fp=9192, fn=3516, tn=34028, total=52223
P=0.37380, R=0.60946, F1=0.46339

[17.42.48]	lable [5]: tp=3123, fp=5057, fn=4489, tn=39554, total=52223
P=0.38178, R=0.41027, F1=0.39552

[17.42.48]	lable [4]: tp=1843, fp=2177, fn=4446, tn=43757, total=52223
P=0.45846, R=0.29305, F1=0.35755

[17.42.48]	lable [6]: tp=2608, fp=3771, fn=4140, tn=41704, total=52223
P=0.40884, R=0.38648, F1=0.39735

[17.42.48]	Average F1 = 0.40016
Accuracy = 21279/52223 = 0.407464
[17.42.48]	Got evaluation for current fold, Avg. F1 = 0.40016
[17.42.48]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm
[17.42.48]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm.model
[17.43.29]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm
[17.43.29]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm.predict
[17.43.29]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm.predict
[17.43.29]	lable [1]: tp=2280, fp=2849, fn=4537, tn=42568, total=52234
P=0.44453, R=0.33446, F1=0.38172

[17.43.29]	lable [0]: tp=3305, fp=5088, fn=4995, tn=38846, total=52234
P=0.39378, R=0.39819, F1=0.39597

[17.43.29]	lable [3]: tp=2717, fp=3640, fn=4742, tn=41135, total=52234
P=0.42740, R=0.36426, F1=0.39331

[17.43.29]	lable [2]: tp=5539, fp=8686, fn=3467, tn=34542, total=52234
P=0.38938, R=0.61503, F1=0.47686

[17.43.29]	lable [5]: tp=3071, fp=5219, fn=4542, tn=39402, total=52234
P=0.37045, R=0.40339, F1=0.38622

[17.43.29]	lable [4]: tp=1968, fp=2275, fn=4323, tn=43668, total=52234
P=0.46382, R=0.31283, F1=0.37365

[17.43.29]	lable [6]: tp=2556, fp=3041, fn=4192, tn=42445, total=52234
P=0.45667, R=0.37878, F1=0.41409

[17.43.29]	Average F1 = 0.40312
Accuracy = 21436/52234 = 0.410384
[17.43.29]	Got evaluation for current fold, Avg. F1 = 0.40312
[17.43.29]	Evaluation Done! Final after 4-fold Avg. F1 = 0.40543
[17.43.29]	

Perfmon Summary:
Time Used(s): 162.529880
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	157114
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	542
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	50
ru_oublock ->	21920
ru_stime ->	0.348021
ru_utime ->	519.776484

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	209667
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	708
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	66
ru_oublock ->	30720
ru_stime ->	0.464029
ru_utime ->	679.802485

=========== ======== ============
		
[17.43.29]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM
[17.43.29]	nFold Splitting! Original data set size: 208845
New nFold result size:
	Fold 0 -> 52209
	Fold 1 -> 52209
	Fold 2 -> 52209
	Fold 3 -> 52218
Total = 208845

[17.43.29]	Fold 0 test, 52209 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
[17.43.29]	Fold 0 train, 156636 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
[17.43.29]	Fold 1 test, 52209 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
[17.43.29]	Fold 1 train, 156636 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
[17.43.30]	Fold 2 test, 52209 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
[17.43.30]	Fold 2 train, 156636 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
[17.43.30]	Fold 3 test, 52218 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
[17.43.30]	Fold 3 train, 156627 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
[17.43.30]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[17.43.30]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model
[17.44.10]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[17.44.10]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[17.44.11]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[17.44.11]	lable [1]: tp=2093, fp=2678, fn=4719, tn=42719, total=52209
P=0.43869, R=0.30725, F1=0.36139

[17.44.11]	lable [0]: tp=2979, fp=4073, fn=5319, tn=39838, total=52209
P=0.42243, R=0.35900, F1=0.38814

[17.44.11]	lable [3]: tp=2597, fp=3110, fn=4858, tn=41644, total=52209
P=0.45506, R=0.34836, F1=0.39462

[17.44.11]	lable [2]: tp=5751, fp=9932, fn=3250, tn=33276, total=52209
P=0.36670, R=0.63893, F1=0.46597

[17.44.11]	lable [5]: tp=3140, fp=6085, fn=4470, tn=38514, total=52209
P=0.34038, R=0.41261, F1=0.37303

[17.44.11]	lable [4]: tp=1793, fp=1985, fn=4494, tn=43937, total=52209
P=0.47459, R=0.28519, F1=0.35628

[17.44.11]	lable [6]: tp=2476, fp=3517, fn=4270, tn=41946, total=52209
P=0.41315, R=0.36703, F1=0.38873

[17.44.11]	Average F1 = 0.38974
Accuracy = 20829/52209 = 0.398954
[17.44.11]	Got evaluation for current fold, Avg. F1 = 0.38974
[17.44.11]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[17.44.11]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model
[17.44.50]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[17.44.50]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[17.44.50]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[17.44.50]	lable [1]: tp=2321, fp=2843, fn=4491, tn=42554, total=52209
P=0.44946, R=0.34072, F1=0.38761

[17.44.50]	lable [0]: tp=2965, fp=4282, fn=5333, tn=39629, total=52209
P=0.40913, R=0.35732, F1=0.38147

[17.44.50]	lable [3]: tp=2701, fp=3627, fn=4754, tn=41127, total=52209
P=0.42683, R=0.36231, F1=0.39193

[17.44.50]	lable [2]: tp=5470, fp=8664, fn=3531, tn=34544, total=52209
P=0.38701, R=0.60771, F1=0.47288

[17.44.50]	lable [5]: tp=3270, fp=5651, fn=4340, tn=38948, total=52209
P=0.36655, R=0.42970, F1=0.39562

[17.44.50]	lable [4]: tp=1884, fp=2314, fn=4403, tn=43608, total=52209
P=0.44879, R=0.29967, F1=0.35937

[17.44.50]	lable [6]: tp=2578, fp=3639, fn=4168, tn=41824, total=52209
P=0.41467, R=0.38215, F1=0.39775

[17.44.50]	Average F1 = 0.39809
Accuracy = 21189/52209 = 0.405850
[17.44.50]	Got evaluation for current fold, Avg. F1 = 0.39809
[17.44.50]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[17.44.50]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model
[17.45.30]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[17.45.30]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[17.45.30]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[17.45.30]	lable [1]: tp=2224, fp=2823, fn=4588, tn=42574, total=52209
P=0.44066, R=0.32648, F1=0.37507

[17.45.30]	lable [0]: tp=2905, fp=4123, fn=5393, tn=39788, total=52209
P=0.41335, R=0.35008, F1=0.37909

[17.45.30]	lable [3]: tp=2826, fp=3819, fn=4629, tn=40935, total=52209
P=0.42528, R=0.37907, F1=0.40085

[17.45.30]	lable [2]: tp=5338, fp=9119, fn=3663, tn=34089, total=52209
P=0.36923, R=0.59305, F1=0.45511

[17.45.30]	lable [5]: tp=3196, fp=5827, fn=4414, tn=38772, total=52209
P=0.35421, R=0.41997, F1=0.38430

[17.45.30]	lable [4]: tp=1758, fp=2060, fn=4529, tn=43862, total=52209
P=0.46045, R=0.27962, F1=0.34795

[17.45.30]	lable [6]: tp=2392, fp=3799, fn=4354, tn=41664, total=52209
P=0.38637, R=0.35458, F1=0.36979

[17.45.30]	Average F1 = 0.38745
Accuracy = 20639/52209 = 0.395315
[17.45.30]	Got evaluation for current fold, Avg. F1 = 0.38745
[17.45.30]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[17.45.30]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model
[17.46.08]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[17.46.08]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[17.46.08]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[17.46.09]	lable [1]: tp=2087, fp=2753, fn=4725, tn=42653, total=52218
P=0.43120, R=0.30637, F1=0.35822

[17.46.09]	lable [0]: tp=3072, fp=4636, fn=5229, tn=39281, total=52218
P=0.39855, R=0.37008, F1=0.38378

[17.46.09]	lable [3]: tp=2762, fp=3994, fn=4696, tn=40766, total=52218
P=0.40882, R=0.37034, F1=0.38863

[17.46.09]	lable [2]: tp=5390, fp=8954, fn=3611, tn=34263, total=52218
P=0.37577, R=0.59882, F1=0.46177

[17.46.09]	lable [5]: tp=3034, fp=5866, fn=4577, tn=38741, total=52218
P=0.34090, R=0.39863, F1=0.36751

[17.46.09]	lable [4]: tp=1899, fp=2239, fn=4390, tn=43690, total=52218
P=0.45892, R=0.30196, F1=0.36425

[17.46.09]	lable [6]: tp=2392, fp=3140, fn=4354, tn=42332, total=52218
P=0.43239, R=0.35458, F1=0.38964

[17.46.09]	Average F1 = 0.38769
Accuracy = 20636/52218 = 0.395189
[17.46.09]	Got evaluation for current fold, Avg. F1 = 0.38769
[17.46.09]	Evaluation Done! Final after 4-fold Avg. F1 = 0.39074
[17.46.09]	

Perfmon Summary:
Time Used(s): 159.807842
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	209667
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	708
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	66
ru_oublock ->	30720
ru_stime ->	0.464029
ru_utime ->	679.802485

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	260962
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	875
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	82
ru_oublock ->	37744
ru_stime ->	0.620038
ru_utime ->	837.120316

=========== ======== ============
		
[17.46.09]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP
[17.46.09]	nFold Splitting! Original data set size: 203805
New nFold result size:
	Fold 0 -> 50948
	Fold 1 -> 50948
	Fold 2 -> 50948
	Fold 3 -> 50961
Total = 203805

[17.46.09]	Fold 0 test, 50948 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
[17.46.09]	Fold 0 train, 152857 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
[17.46.09]	Fold 1 test, 50948 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
[17.46.09]	Fold 1 train, 152857 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
[17.46.09]	Fold 2 test, 50948 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
[17.46.09]	Fold 2 train, 152857 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
[17.46.09]	Fold 3 test, 50961 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
[17.46.10]	Fold 3 train, 152844 data, output to /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
[17.46.10]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[17.46.10]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model
[17.46.36]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[17.46.36]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[17.46.36]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[17.46.36]	lable [1]: tp=2178, fp=3204, fn=4538, tn=41028, total=50948
P=0.40468, R=0.32430, F1=0.36006

[17.46.36]	lable [0]: tp=3052, fp=3844, fn=5025, tn=39027, total=50948
P=0.44258, R=0.37786, F1=0.40767

[17.46.36]	lable [3]: tp=2460, fp=2810, fn=4831, tn=40847, total=50948
P=0.46679, R=0.33740, F1=0.39169

[17.46.36]	lable [2]: tp=5380, fp=8737, fn=3361, tn=33470, total=50948
P=0.38110, R=0.61549, F1=0.47073

[17.46.36]	lable [5]: tp=3145, fp=6045, fn=4227, tn=37531, total=50948
P=0.34222, R=0.42661, F1=0.37979

[17.46.36]	lable [4]: tp=1806, fp=2202, fn=4365, tn=42575, total=50948
P=0.45060, R=0.29266, F1=0.35485

[17.46.36]	lable [6]: tp=2643, fp=3442, fn=3937, tn=40926, total=50948
P=0.43435, R=0.40167, F1=0.41737

[17.46.36]	Average F1 = 0.39745
Accuracy = 20664/50948 = 0.405590
[17.46.36]	Got evaluation for current fold, Avg. F1 = 0.39745
[17.46.36]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[17.46.36]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model
[17.47.02]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[17.47.02]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[17.47.02]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[17.47.03]	lable [1]: tp=2327, fp=3049, fn=4389, tn=41183, total=50948
P=0.43285, R=0.34649, F1=0.38488

[17.47.03]	lable [0]: tp=2985, fp=4459, fn=5092, tn=38412, total=50948
P=0.40099, R=0.36957, F1=0.38464

[17.47.03]	lable [3]: tp=2474, fp=3247, fn=4817, tn=40410, total=50948
P=0.43244, R=0.33932, F1=0.38026

[17.47.03]	lable [2]: tp=5225, fp=8153, fn=3516, tn=34054, total=50948
P=0.39057, R=0.59776, F1=0.47244

[17.47.03]	lable [5]: tp=3062, fp=4981, fn=4310, tn=38595, total=50948
P=0.38070, R=0.41536, F1=0.39728

[17.47.03]	lable [4]: tp=1923, fp=2800, fn=4248, tn=41977, total=50948
P=0.40716, R=0.31162, F1=0.35304

[17.47.03]	lable [6]: tp=2698, fp=3565, fn=3882, tn=40803, total=50948
P=0.43078, R=0.41003, F1=0.42015

[17.47.03]	Average F1 = 0.39896
Accuracy = 20694/50948 = 0.406179
[17.47.03]	Got evaluation for current fold, Avg. F1 = 0.39896
[17.47.03]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[17.47.03]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model
[17.47.30]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[17.47.30]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[17.47.30]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[17.47.30]	lable [1]: tp=2351, fp=3416, fn=4365, tn=40816, total=50948
P=0.40766, R=0.35006, F1=0.37667

[17.47.30]	lable [0]: tp=2872, fp=3927, fn=5205, tn=38944, total=50948
P=0.42242, R=0.35558, F1=0.38613

[17.47.30]	lable [3]: tp=2654, fp=3458, fn=4637, tn=40199, total=50948
P=0.43423, R=0.36401, F1=0.39603

[17.47.30]	lable [2]: tp=4987, fp=8204, fn=3754, tn=34003, total=50948
P=0.37806, R=0.57053, F1=0.45477

[17.47.30]	lable [5]: tp=3169, fp=5713, fn=4203, tn=37863, total=50948
P=0.35679, R=0.42987, F1=0.38993

[17.47.30]	lable [4]: tp=1787, fp=2321, fn=4384, tn=42456, total=50948
P=0.43500, R=0.28958, F1=0.34770

[17.47.30]	lable [6]: tp=2504, fp=3585, fn=4076, tn=40783, total=50948
P=0.41123, R=0.38055, F1=0.39530

[17.47.30]	Average F1 = 0.39236
Accuracy = 20324/50948 = 0.398917
[17.47.30]	Got evaluation for current fold, Avg. F1 = 0.39236
[17.47.30]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[17.47.30]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model
[17.47.56]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[17.47.56]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[17.47.56]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[17.47.56]	lable [1]: tp=2122, fp=2662, fn=4596, tn=41581, total=50961
P=0.44356, R=0.31587, F1=0.36898

[17.47.56]	lable [0]: tp=3053, fp=4504, fn=5025, tn=38379, total=50961
P=0.40400, R=0.37794, F1=0.39053

[17.47.56]	lable [3]: tp=2552, fp=3520, fn=4742, tn=40147, total=50961
P=0.42029, R=0.34988, F1=0.38186

[17.47.56]	lable [2]: tp=5083, fp=7872, fn=3660, tn=34346, total=50961
P=0.39236, R=0.58138, F1=0.46852

[17.47.56]	lable [5]: tp=3015, fp=5709, fn=4359, tn=37878, total=50961
P=0.34560, R=0.40887, F1=0.37458

[17.47.56]	lable [4]: tp=1936, fp=2708, fn=4237, tn=42080, total=50961
P=0.41688, R=0.31362, F1=0.35796

[17.47.56]	lable [6]: tp=2578, fp=3647, fn=4003, tn=40733, total=50961
P=0.41414, R=0.39173, F1=0.40262

[17.47.56]	Average F1 = 0.39215
Accuracy = 20339/50961 = 0.399109
[17.47.56]	Got evaluation for current fold, Avg. F1 = 0.39215
[17.47.56]	Evaluation Done! Final after 4-fold Avg. F1 = 0.39523
[17.47.56]	

Perfmon Summary:
Time Used(s): 107.804774
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	260962
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	875
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	82
ru_oublock ->	37744
ru_stime ->	0.620038
ru_utime ->	837.120316

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	160
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	46824
ru_minflt ->	304724
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	986
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	98
ru_oublock ->	45256
ru_stime ->	0.712044
ru_utime ->	942.798921

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130305175656
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[17.56.56]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[17.56.57]	nFold Splitting! Original data set size: 240149
New nFold result size:
	Fold 0 -> 60036
	Fold 1 -> 60036
	Fold 2 -> 60036
	Fold 3 -> 60041
Total = 240149

[17.56.57]	Fold 0 test, 60036 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[17.56.57]	Fold 0 train, 180113 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[17.56.57]	Fold 1 test, 60036 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[17.56.57]	Fold 1 train, 180113 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[17.56.57]	Fold 2 test, 60036 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[17.56.57]	Fold 2 train, 180113 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[17.56.57]	Fold 3 test, 60041 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[17.56.57]	Fold 3 train, 180108 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[17.56.57]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[17.56.57]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model
[17.57.19]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[17.57.19]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[17.57.19]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[17.57.19]	lable [1]: tp=15691, fp=10159, fn=6524, tn=27662, total=60036
P=0.60700, R=0.70632, F1=0.65291

[17.57.19]	lable [0]: tp=10170, fp=5179, fn=9519, tn=35168, total=60036
P=0.66258, R=0.51653, F1=0.58051

[17.57.19]	lable [2]: tp=11062, fp=7775, fn=7070, tn=34129, total=60036
P=0.58725, R=0.61008, F1=0.59845

[17.57.19]	Average F1 = 0.61062
Accuracy = 36923/60036 = 0.615014
[17.57.19]	Got evaluation for current fold, Avg. F1 = 0.61062
[17.57.19]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[17.57.19]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model
[17.57.41]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[17.57.41]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[17.57.41]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[17.57.41]	lable [1]: tp=16009, fp=10648, fn=6206, tn=27173, total=60036
P=0.60056, R=0.72064, F1=0.65514

[17.57.41]	lable [0]: tp=9901, fp=5480, fn=9788, tn=34867, total=60036
P=0.64372, R=0.50287, F1=0.56464

[17.57.41]	lable [2]: tp=10959, fp=7039, fn=7173, tn=34865, total=60036
P=0.60890, R=0.60440, F1=0.60664

[17.57.41]	Average F1 = 0.60881
Accuracy = 36869/60036 = 0.614115
[17.57.41]	Got evaluation for current fold, Avg. F1 = 0.60881
[17.57.41]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm
[17.57.41]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm.model
[17.58.03]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm
[17.58.03]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[17.58.03]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[17.58.03]	lable [1]: tp=16008, fp=10260, fn=6207, tn=27561, total=60036
P=0.60941, R=0.72059, F1=0.66036

[17.58.03]	lable [0]: tp=10211, fp=5446, fn=9478, tn=34901, total=60036
P=0.65217, R=0.51861, F1=0.57777

[17.58.03]	lable [2]: tp=10883, fp=7228, fn=7249, tn=34676, total=60036
P=0.60091, R=0.60021, F1=0.60056

[17.58.03]	Average F1 = 0.61290
Accuracy = 37102/60036 = 0.617996
[17.58.03]	Got evaluation for current fold, Avg. F1 = 0.61290
[17.58.03]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm
[17.58.03]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm.model
[17.58.25]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm
[17.58.25]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[17.58.25]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[17.58.25]	lable [1]: tp=16096, fp=10679, fn=6120, tn=27146, total=60041
P=0.60116, R=0.72452, F1=0.65710

[17.58.25]	lable [0]: tp=10174, fp=5439, fn=9517, tn=34911, total=60041
P=0.65164, R=0.51668, F1=0.57637

[17.58.25]	lable [2]: tp=10597, fp=7056, fn=7537, tn=34851, total=60041
P=0.60029, R=0.58437, F1=0.59223

[17.58.25]	Average F1 = 0.60856
Accuracy = 36867/60041 = 0.614030
[17.58.25]	Got evaluation for current fold, Avg. F1 = 0.60856
[17.58.25]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61022
[17.58.25]	

Perfmon Summary:
Time Used(s): 88.984789
Memory Used (Mb): 45.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	43879
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	92
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	15
ru_oublock ->	4144
ru_stime ->	0.108006
ru_utime ->	86.921432

=========== ======== ============
		
[17.58.25]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM
[17.58.26]	nFold Splitting! Original data set size: 240132
New nFold result size:
	Fold 0 -> 60031
	Fold 1 -> 60031
	Fold 2 -> 60031
	Fold 3 -> 60039
Total = 240132

[17.58.26]	Fold 0 test, 60031 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
[17.58.26]	Fold 0 train, 180101 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
[17.58.26]	Fold 1 test, 60031 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
[17.58.26]	Fold 1 train, 180101 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
[17.58.26]	Fold 2 test, 60031 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
[17.58.26]	Fold 2 train, 180101 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
[17.58.26]	Fold 3 test, 60039 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
[17.58.26]	Fold 3 train, 180093 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
[17.58.26]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm
[17.58.26]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm.model
[17.58.49]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm
[17.58.49]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[17.58.49]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[17.58.49]	lable [1]: tp=15250, fp=10228, fn=6964, tn=27589, total=60031
P=0.59856, R=0.68650, F1=0.63952

[17.58.49]	lable [0]: tp=9928, fp=5198, fn=9759, tn=35146, total=60031
P=0.65635, R=0.50429, F1=0.57036

[17.58.49]	lable [2]: tp=11062, fp=8365, fn=7068, tn=33536, total=60031
P=0.56941, R=0.61015, F1=0.58908

[17.58.49]	Average F1 = 0.59965
Accuracy = 36240/60031 = 0.603688
[17.58.49]	Got evaluation for current fold, Avg. F1 = 0.59965
[17.58.49]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm
[17.58.49]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm.model
[17.59.11]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm
[17.59.11]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[17.59.11]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[17.59.11]	lable [1]: tp=15878, fp=11101, fn=6336, tn=26716, total=60031
P=0.58853, R=0.71477, F1=0.64554

[17.59.11]	lable [0]: tp=9632, fp=5572, fn=10055, tn=34772, total=60031
P=0.63352, R=0.48926, F1=0.55212

[17.59.11]	lable [2]: tp=10600, fp=7248, fn=7530, tn=34653, total=60031
P=0.59390, R=0.58467, F1=0.58925

[17.59.11]	Average F1 = 0.59564
Accuracy = 36110/60031 = 0.601523
[17.59.11]	Got evaluation for current fold, Avg. F1 = 0.59564
[17.59.11]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm
[17.59.11]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm.model
[17.59.33]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm
[17.59.33]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[17.59.33]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[17.59.33]	lable [1]: tp=15876, fp=10729, fn=6338, tn=27088, total=60031
P=0.59673, R=0.71468, F1=0.65040

[17.59.33]	lable [0]: tp=9970, fp=5538, fn=9717, tn=34806, total=60031
P=0.64289, R=0.50643, F1=0.56656

[17.59.33]	lable [2]: tp=10534, fp=7384, fn=7596, tn=34517, total=60031
P=0.58790, R=0.58103, F1=0.58444

[17.59.33]	Average F1 = 0.60047
Accuracy = 36380/60031 = 0.606020
[17.59.33]	Got evaluation for current fold, Avg. F1 = 0.60047
[17.59.33]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm
[17.59.33]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm.model
[17.59.54]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm
[17.59.54]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[17.59.54]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[17.59.55]	lable [1]: tp=16009, fp=11109, fn=6208, tn=26713, total=60039
P=0.59035, R=0.72057, F1=0.64899

[17.59.55]	lable [0]: tp=9954, fp=5540, fn=9735, tn=34810, total=60039
P=0.64244, R=0.50556, F1=0.56584

[17.59.55]	lable [2]: tp=10287, fp=7140, fn=7846, tn=34766, total=60039
P=0.59029, R=0.56731, F1=0.57857

[17.59.55]	Average F1 = 0.59780
Accuracy = 36250/60039 = 0.603774
[17.59.55]	Got evaluation for current fold, Avg. F1 = 0.59780
[17.59.55]	Evaluation Done! Final after 4-fold Avg. F1 = 0.59839
[17.59.55]	

Perfmon Summary:
Time Used(s): 89.241995
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	43879
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	92
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	15
ru_oublock ->	4144
ru_stime ->	0.108006
ru_utime ->	86.921432

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	87408
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	183
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	31
ru_oublock ->	7088
ru_stime ->	0.244015
ru_utime ->	173.926869

=========== ======== ============
		
[17.59.55]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM
[17.59.55]	nFold Splitting! Original data set size: 240139
New nFold result size:
	Fold 0 -> 60033
	Fold 1 -> 60033
	Fold 2 -> 60033
	Fold 3 -> 60040
Total = 240139

[17.59.55]	Fold 0 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
[17.59.55]	Fold 0 train, 180106 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
[17.59.55]	Fold 1 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
[17.59.55]	Fold 1 train, 180106 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
[17.59.55]	Fold 2 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
[17.59.55]	Fold 2 train, 180106 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
[17.59.56]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
[17.59.56]	Fold 3 train, 180099 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
[17.59.56]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm
[17.59.56]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm.model
[18.00.17]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm
[18.00.17]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[18.00.17]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[18.00.17]	lable [1]: tp=15640, fp=9840, fn=6573, tn=27980, total=60033
P=0.61381, R=0.70409, F1=0.65586

[18.00.17]	lable [0]: tp=10683, fp=5670, fn=9006, tn=34674, total=60033
P=0.65327, R=0.54259, F1=0.59281

[18.00.17]	lable [2]: tp=10911, fp=7289, fn=7220, tn=34613, total=60033
P=0.59951, R=0.60179, F1=0.60064

[18.00.17]	Average F1 = 0.61644
Accuracy = 37234/60033 = 0.620226
[18.00.17]	Got evaluation for current fold, Avg. F1 = 0.61644
[18.00.17]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm
[18.00.17]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm.model
[18.00.39]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm
[18.00.39]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[18.00.39]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[18.00.39]	lable [1]: tp=15787, fp=10153, fn=6426, tn=27667, total=60033
P=0.60860, R=0.71071, F1=0.65570

[18.00.39]	lable [0]: tp=10433, fp=6085, fn=9256, tn=34259, total=60033
P=0.63161, R=0.52989, F1=0.57630

[18.00.39]	lable [2]: tp=10869, fp=6706, fn=7262, tn=35196, total=60033
P=0.61844, R=0.59947, F1=0.60881

[18.00.39]	Average F1 = 0.61360
Accuracy = 37089/60033 = 0.617810
[18.00.39]	Got evaluation for current fold, Avg. F1 = 0.61360
[18.00.39]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm
[18.00.39]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm.model
[18.01.01]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm
[18.01.01]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[18.01.01]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[18.01.01]	lable [1]: tp=15841, fp=9911, fn=6372, tn=27909, total=60033
P=0.61514, R=0.71314, F1=0.66052

[18.01.01]	lable [0]: tp=10757, fp=5989, fn=8932, tn=34355, total=60033
P=0.64236, R=0.54635, F1=0.59048

[18.01.01]	lable [2]: tp=10763, fp=6772, fn=7368, tn=35130, total=60033
P=0.61380, R=0.59362, F1=0.60354

[18.01.01]	Average F1 = 0.61818
Accuracy = 37361/60033 = 0.622341
[18.01.01]	Got evaluation for current fold, Avg. F1 = 0.61818
[18.01.01]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm
[18.01.01]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm.model
[18.01.21]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm
[18.01.21]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[18.01.21]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[18.01.21]	lable [1]: tp=15780, fp=9985, fn=6436, tn=27839, total=60040
P=0.61246, R=0.71030, F1=0.65776

[18.01.21]	lable [0]: tp=10738, fp=6086, fn=8952, tn=34264, total=60040
P=0.63825, R=0.54535, F1=0.58816

[18.01.21]	lable [2]: tp=10629, fp=6822, fn=7505, tn=35084, total=60040
P=0.60908, R=0.58614, F1=0.59739

[18.01.21]	Average F1 = 0.61443
Accuracy = 37147/60040 = 0.618704
[18.01.21]	Got evaluation for current fold, Avg. F1 = 0.61443
[18.01.21]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61566
[18.01.21]	

Perfmon Summary:
Time Used(s): 86.560902
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	87408
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	183
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	31
ru_oublock ->	7088
ru_stime ->	0.244015
ru_utime ->	173.926869

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	131359
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	272
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	47
ru_oublock ->	11632
ru_stime ->	0.372023
ru_utime ->	258.26014

=========== ======== ============
		
[18.01.21]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L
[18.01.21]	nFold Splitting! Original data set size: 240139
New nFold result size:
	Fold 0 -> 60033
	Fold 1 -> 60033
	Fold 2 -> 60033
	Fold 3 -> 60040
Total = 240139

[18.01.21]	Fold 0 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
[18.01.22]	Fold 0 train, 180106 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
[18.01.22]	Fold 1 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
[18.01.22]	Fold 1 train, 180106 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
[18.01.22]	Fold 2 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
[18.01.22]	Fold 2 train, 180106 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
[18.01.22]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
[18.01.22]	Fold 3 train, 180099 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
[18.01.22]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm
[18.01.22]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm.model
[18.01.43]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm
[18.01.43]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm.predict
[18.01.44]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm.predict
[18.01.44]	lable [1]: tp=15640, fp=9840, fn=6573, tn=27980, total=60033
P=0.61381, R=0.70409, F1=0.65586

[18.01.44]	lable [0]: tp=10683, fp=5670, fn=9006, tn=34674, total=60033
P=0.65327, R=0.54259, F1=0.59281

[18.01.44]	lable [2]: tp=10911, fp=7289, fn=7220, tn=34613, total=60033
P=0.59951, R=0.60179, F1=0.60064

[18.01.44]	Average F1 = 0.61644
Accuracy = 37234/60033 = 0.620226
[18.01.44]	Got evaluation for current fold, Avg. F1 = 0.61644
[18.01.44]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm
[18.01.44]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm.model
[18.02.05]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm
[18.02.05]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm.predict
[18.02.05]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm.predict
[18.02.06]	lable [1]: tp=15787, fp=10153, fn=6426, tn=27667, total=60033
P=0.60860, R=0.71071, F1=0.65570

[18.02.06]	lable [0]: tp=10433, fp=6085, fn=9256, tn=34259, total=60033
P=0.63161, R=0.52989, F1=0.57630

[18.02.06]	lable [2]: tp=10869, fp=6706, fn=7262, tn=35196, total=60033
P=0.61844, R=0.59947, F1=0.60881

[18.02.06]	Average F1 = 0.61360
Accuracy = 37089/60033 = 0.617810
[18.02.06]	Got evaluation for current fold, Avg. F1 = 0.61360
[18.02.06]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm
[18.02.06]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm.model
[18.02.27]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm
[18.02.27]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm.predict
[18.02.28]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm.predict
[18.02.28]	lable [1]: tp=15841, fp=9911, fn=6372, tn=27909, total=60033
P=0.61514, R=0.71314, F1=0.66052

[18.02.28]	lable [0]: tp=10757, fp=5989, fn=8932, tn=34355, total=60033
P=0.64236, R=0.54635, F1=0.59048

[18.02.28]	lable [2]: tp=10763, fp=6772, fn=7368, tn=35130, total=60033
P=0.61380, R=0.59362, F1=0.60354

[18.02.28]	Average F1 = 0.61818
Accuracy = 37361/60033 = 0.622341
[18.02.28]	Got evaluation for current fold, Avg. F1 = 0.61818
[18.02.28]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm
[18.02.28]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm.model
[18.02.47]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm
[18.02.47]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm.predict
[18.02.47]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm.predict
[18.02.48]	lable [1]: tp=15780, fp=9985, fn=6436, tn=27839, total=60040
P=0.61246, R=0.71030, F1=0.65776

[18.02.48]	lable [0]: tp=10738, fp=6086, fn=8952, tn=34264, total=60040
P=0.63825, R=0.54535, F1=0.58816

[18.02.48]	lable [2]: tp=10629, fp=6822, fn=7505, tn=35084, total=60040
P=0.60908, R=0.58614, F1=0.59739

[18.02.48]	Average F1 = 0.61443
Accuracy = 37147/60040 = 0.618704
[18.02.48]	Got evaluation for current fold, Avg. F1 = 0.61443
[18.02.48]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61566
[18.02.48]	

Perfmon Summary:
Time Used(s): 86.492757
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	131359
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	272
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	47
ru_oublock ->	11632
ru_stime ->	0.372023
ru_utime ->	258.26014

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	175320
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	360
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	63
ru_oublock ->	16184
ru_stime ->	0.48003
ru_utime ->	342.553408

=========== ======== ============
		
[18.02.48]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM
[18.02.48]	nFold Splitting! Original data set size: 240151
New nFold result size:
	Fold 0 -> 60037
	Fold 1 -> 60037
	Fold 2 -> 60037
	Fold 3 -> 60040
Total = 240151

[18.02.48]	Fold 0 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
[18.02.48]	Fold 0 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
[18.02.48]	Fold 1 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
[18.02.48]	Fold 1 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
[18.02.48]	Fold 2 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
[18.02.49]	Fold 2 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
[18.02.49]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
[18.02.49]	Fold 3 train, 180111 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
[18.02.49]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[18.02.49]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model
[18.03.11]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[18.03.11]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[18.03.11]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[18.03.11]	lable [1]: tp=15552, fp=10230, fn=6663, tn=27592, total=60037
P=0.60321, R=0.70007, F1=0.64804

[18.03.11]	lable [0]: tp=9995, fp=5134, fn=9694, tn=35214, total=60037
P=0.66065, R=0.50764, F1=0.57413

[18.03.11]	lable [2]: tp=11050, fp=8076, fn=7083, tn=33828, total=60037
P=0.57775, R=0.60939, F1=0.59315

[18.03.11]	Average F1 = 0.60510
Accuracy = 36597/60037 = 0.609574
[18.03.11]	Got evaluation for current fold, Avg. F1 = 0.60510
[18.03.11]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[18.03.11]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model
[18.03.32]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[18.03.32]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[18.03.32]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[18.03.33]	lable [1]: tp=15816, fp=10521, fn=6399, tn=27301, total=60037
P=0.60052, R=0.71195, F1=0.65151

[18.03.33]	lable [0]: tp=9884, fp=5610, fn=9805, tn=34738, total=60037
P=0.63792, R=0.50201, F1=0.56186

[18.03.33]	lable [2]: tp=10946, fp=7260, fn=7187, tn=34644, total=60037
P=0.60123, R=0.60365, F1=0.60244

[18.03.33]	Average F1 = 0.60527
Accuracy = 36646/60037 = 0.610390
[18.03.33]	Got evaluation for current fold, Avg. F1 = 0.60527
[18.03.33]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[18.03.33]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model
[18.03.56]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[18.03.56]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[18.03.56]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[18.03.56]	lable [1]: tp=15882, fp=10318, fn=6333, tn=27504, total=60037
P=0.60618, R=0.71492, F1=0.65608

[18.03.56]	lable [0]: tp=10203, fp=5522, fn=9486, tn=34826, total=60037
P=0.64884, R=0.51821, F1=0.57621

[18.03.56]	lable [2]: tp=10823, fp=7289, fn=7310, tn=34615, total=60037
P=0.59756, R=0.59687, F1=0.59721

[18.03.56]	Average F1 = 0.60983
Accuracy = 36908/60037 = 0.614754
[18.03.56]	Got evaluation for current fold, Avg. F1 = 0.60983
[18.03.56]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[18.03.56]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model
[18.04.24]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[18.04.24]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[18.04.24]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[18.04.24]	lable [1]: tp=15997, fp=10716, fn=6219, tn=27108, total=60040
P=0.59885, R=0.72007, F1=0.65389

[18.04.24]	lable [0]: tp=10084, fp=5512, fn=9607, tn=34837, total=60040
P=0.64658, R=0.51211, F1=0.57154

[18.04.24]	lable [2]: tp=10540, fp=7191, fn=7593, tn=34716, total=60040
P=0.59444, R=0.58126, F1=0.58778

[18.04.24]	Average F1 = 0.60440
Accuracy = 36621/60040 = 0.609943
[18.04.24]	Got evaluation for current fold, Avg. F1 = 0.60440
[18.04.24]	Evaluation Done! Final after 4-fold Avg. F1 = 0.60615
[18.04.24]	

Perfmon Summary:
Time Used(s): 96.749670
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	175320
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	360
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	63
ru_oublock ->	16184
ru_stime ->	0.48003
ru_utime ->	342.553408

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	219204
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	459
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	79
ru_oublock ->	19984
ru_stime ->	0.580036
ru_utime ->	437.015311

=========== ======== ============
		
[18.04.24]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP
[18.04.25]	nFold Splitting! Original data set size: 240151
New nFold result size:
	Fold 0 -> 60037
	Fold 1 -> 60037
	Fold 2 -> 60037
	Fold 3 -> 60040
Total = 240151

[18.04.25]	Fold 0 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
[18.04.25]	Fold 0 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
[18.04.25]	Fold 1 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
[18.04.25]	Fold 1 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
[18.04.25]	Fold 2 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
[18.04.25]	Fold 2 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
[18.04.25]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
[18.04.26]	Fold 3 train, 180111 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
[18.04.26]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[18.04.26]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model
[18.04.47]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[18.04.47]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[18.04.47]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[18.04.48]	lable [1]: tp=15552, fp=10230, fn=6663, tn=27592, total=60037
P=0.60321, R=0.70007, F1=0.64804

[18.04.48]	lable [0]: tp=9995, fp=5134, fn=9694, tn=35214, total=60037
P=0.66065, R=0.50764, F1=0.57413

[18.04.48]	lable [2]: tp=11050, fp=8076, fn=7083, tn=33828, total=60037
P=0.57775, R=0.60939, F1=0.59315

[18.04.48]	Average F1 = 0.60510
Accuracy = 36597/60037 = 0.609574
[18.04.48]	Got evaluation for current fold, Avg. F1 = 0.60510
[18.04.48]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[18.04.48]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model
[18.05.09]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[18.05.09]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[18.05.09]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[18.05.09]	lable [1]: tp=15816, fp=10521, fn=6399, tn=27301, total=60037
P=0.60052, R=0.71195, F1=0.65151

[18.05.09]	lable [0]: tp=9884, fp=5610, fn=9805, tn=34738, total=60037
P=0.63792, R=0.50201, F1=0.56186

[18.05.09]	lable [2]: tp=10946, fp=7260, fn=7187, tn=34644, total=60037
P=0.60123, R=0.60365, F1=0.60244

[18.05.09]	Average F1 = 0.60527
Accuracy = 36646/60037 = 0.610390
[18.05.09]	Got evaluation for current fold, Avg. F1 = 0.60527
[18.05.09]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[18.05.09]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model
[18.05.32]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[18.05.32]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[18.05.32]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[18.05.33]	lable [1]: tp=15882, fp=10318, fn=6333, tn=27504, total=60037
P=0.60618, R=0.71492, F1=0.65608

[18.05.33]	lable [0]: tp=10203, fp=5522, fn=9486, tn=34826, total=60037
P=0.64884, R=0.51821, F1=0.57621

[18.05.33]	lable [2]: tp=10823, fp=7289, fn=7310, tn=34615, total=60037
P=0.59756, R=0.59687, F1=0.59721

[18.05.33]	Average F1 = 0.60983
Accuracy = 36908/60037 = 0.614754
[18.05.33]	Got evaluation for current fold, Avg. F1 = 0.60983
[18.05.33]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[18.05.33]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model
[18.05.54]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[18.05.54]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[18.05.54]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[18.05.54]	lable [1]: tp=15997, fp=10716, fn=6219, tn=27108, total=60040
P=0.59885, R=0.72007, F1=0.65389

[18.05.54]	lable [0]: tp=10084, fp=5512, fn=9607, tn=34837, total=60040
P=0.64658, R=0.51211, F1=0.57154

[18.05.54]	lable [2]: tp=10540, fp=7191, fn=7593, tn=34716, total=60040
P=0.59444, R=0.58126, F1=0.58778

[18.05.54]	Average F1 = 0.60440
Accuracy = 36621/60040 = 0.609943
[18.05.54]	Got evaluation for current fold, Avg. F1 = 0.60440
[18.05.54]	Evaluation Done! Final after 4-fold Avg. F1 = 0.60615
[18.05.54]	

Perfmon Summary:
Time Used(s): 89.648452
Memory Used (Mb): 4.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	219204
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	459
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	79
ru_oublock ->	19984
ru_stime ->	0.580036
ru_utime ->	437.015311

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50328
ru_minflt ->	263089
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	550
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	95
ru_oublock ->	23784
ru_stime ->	0.680042
ru_utime ->	524.408773

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130305181118
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[18.11.19]	M5_L_STM: Start constructing Bog
[18.11.19]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[18.11.40]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[18.11.40]	[BogBuilder] First pass vocab scan, #vocab = 28747
[18.11.40]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6130
[18.12.05]	Done! Number of instance wrote: 240151
[18.12.05]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.libsvm
[18.12.15]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.libsvm

[18.12.15]	M10_L_STM: Start constructing Bog
[18.12.15]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff
[18.12.36]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:10 -alphanumonly:False
[18.12.36]	[BogBuilder] First pass vocab scan, #vocab = 28747
[18.12.36]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 3784
[18.13.01]	Done! Number of instance wrote: 240138
[18.13.01]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.libsvm
[18.13.08]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.libsvm

[18.13.08]	M5_STM: Start constructing Bog
[18.13.08]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff
[18.13.29]	BOG setting: BogBuilder -stmmer:True -lower:False -minFreq:5 -alphanumonly:False
[18.13.29]	[BogBuilder] First pass vocab scan, #vocab = 33610
[18.13.29]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6962
[18.13.54]	Done! Number of instance wrote: 240142
[18.13.54]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.libsvm
[18.14.05]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_STM.libsvm

[18.14.05]	M5_L: Start constructing Bog
[18.14.05]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff
[18.14.12]	BOG setting: BogBuilder -stmmer:False -lower:True -minFreq:5 -alphanumonly:False
[18.14.12]	[BogBuilder] First pass vocab scan, #vocab = 33167
[18.14.12]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6885
[18.14.22]	Done! Number of instance wrote: 240149
[18.14.22]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L.libsvm
[18.14.33]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L.libsvm

[18.14.33]	M5_L_STM_ALPHANUM: Start constructing Bog
[18.14.33]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff
[18.14.55]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:True
[18.14.55]	[BogBuilder] First pass vocab scan, #vocab = 23071
[18.14.55]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 5360
[18.15.20]	Done! Number of instance wrote: 240083
[18.15.20]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.libsvm
[18.15.29]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.libsvm

[18.15.29]	M5_L_STM_RMSTP: Start constructing Bog
[18.15.29]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff
[18.15.46]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[18.15.46]	[BogBuilder] First pass vocab scan, #vocab = 28565
[18.15.46]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 5889
[18.16.06]	Done! Number of instance wrote: 234202
[18.16.06]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.libsvm
[18.16.15]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.libsvm



# TODO JXITC
======================================================
*********************************************************
Start logging 20130305181716
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[18.17.16]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[18.17.16]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[18.17.16]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model
[18.17.38]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[18.17.38]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[18.17.38]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[18.17.38]	lable [1]: tp=15691, fp=10159, fn=6524, tn=27662, total=60036
P=0.60700, R=0.70632, F1=0.65291

[18.17.38]	lable [0]: tp=10170, fp=5179, fn=9519, tn=35168, total=60036
P=0.66258, R=0.51653, F1=0.58051

[18.17.38]	lable [2]: tp=11062, fp=7775, fn=7070, tn=34129, total=60036
P=0.58725, R=0.61008, F1=0.59845

[18.17.38]	Average F1 = 0.61062
Accuracy = 36923/60036 = 0.615014
[18.17.38]	Got evaluation for current fold, Avg. F1 = 0.61062
[18.17.38]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[18.17.38]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model
[18.18.00]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[18.18.00]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[18.18.00]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[18.18.00]	lable [1]: tp=16009, fp=10648, fn=6206, tn=27173, total=60036
P=0.60056, R=0.72064, F1=0.65514

[18.18.00]	lable [0]: tp=9901, fp=5480, fn=9788, tn=34867, total=60036
P=0.64372, R=0.50287, F1=0.56464

[18.18.00]	lable [2]: tp=10959, fp=7039, fn=7173, tn=34865, total=60036
P=0.60890, R=0.60440, F1=0.60664

[18.18.00]	Average F1 = 0.60881
Accuracy = 36869/60036 = 0.614115
[18.18.00]	Got evaluation for current fold, Avg. F1 = 0.60881
[18.18.00]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm
[18.18.00]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm.model
[18.18.22]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm
[18.18.22]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[18.18.22]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[18.18.22]	lable [1]: tp=16008, fp=10260, fn=6207, tn=27561, total=60036
P=0.60941, R=0.72059, F1=0.66036

[18.18.22]	lable [0]: tp=10211, fp=5446, fn=9478, tn=34901, total=60036
P=0.65217, R=0.51861, F1=0.57777

[18.18.22]	lable [2]: tp=10883, fp=7228, fn=7249, tn=34676, total=60036
P=0.60091, R=0.60021, F1=0.60056

[18.18.22]	Average F1 = 0.61290
Accuracy = 37102/60036 = 0.617996
[18.18.22]	Got evaluation for current fold, Avg. F1 = 0.61290
[18.18.22]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm
[18.18.22]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm.model
[18.18.44]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm
[18.18.44]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[18.18.44]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[18.18.44]	lable [1]: tp=16096, fp=10679, fn=6120, tn=27146, total=60041
P=0.60116, R=0.72452, F1=0.65710

[18.18.44]	lable [0]: tp=10174, fp=5439, fn=9517, tn=34911, total=60041
P=0.65164, R=0.51668, F1=0.57637

[18.18.44]	lable [2]: tp=10597, fp=7056, fn=7537, tn=34851, total=60041
P=0.60029, R=0.58437, F1=0.59223

[18.18.44]	Average F1 = 0.60856
Accuracy = 36867/60041 = 0.614030
[18.18.44]	Got evaluation for current fold, Avg. F1 = 0.60856
[18.18.44]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61022
[18.18.44]	

Perfmon Summary:
Time Used(s): 87.747416
Memory Used (Mb): 33.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33872
ru_minflt ->	43817
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	90
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	15
ru_oublock ->	4144
ru_stime ->	0.104006
ru_utime ->	86.73742

=========== ======== ============
		
[18.18.44]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM
[18.18.44]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm
[18.18.44]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm.model
[18.19.06]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm
[18.19.06]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[18.19.06]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[18.19.06]	lable [1]: tp=15250, fp=10228, fn=6964, tn=27589, total=60031
P=0.59856, R=0.68650, F1=0.63952

[18.19.06]	lable [0]: tp=9928, fp=5198, fn=9759, tn=35146, total=60031
P=0.65635, R=0.50429, F1=0.57036

[18.19.06]	lable [2]: tp=11062, fp=8365, fn=7068, tn=33536, total=60031
P=0.56941, R=0.61015, F1=0.58908

[18.19.06]	Average F1 = 0.59965
Accuracy = 36240/60031 = 0.603688
[18.19.06]	Got evaluation for current fold, Avg. F1 = 0.59965
[18.19.06]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm
[18.19.06]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm.model
[18.19.28]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm
[18.19.28]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[18.19.28]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[18.19.29]	lable [1]: tp=15878, fp=11101, fn=6336, tn=26716, total=60031
P=0.58853, R=0.71477, F1=0.64554

[18.19.29]	lable [0]: tp=9632, fp=5572, fn=10055, tn=34772, total=60031
P=0.63352, R=0.48926, F1=0.55212

[18.19.29]	lable [2]: tp=10600, fp=7248, fn=7530, tn=34653, total=60031
P=0.59390, R=0.58467, F1=0.58925

[18.19.29]	Average F1 = 0.59564
Accuracy = 36110/60031 = 0.601523
[18.19.29]	Got evaluation for current fold, Avg. F1 = 0.59564
[18.19.29]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm
[18.19.29]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm.model
[18.19.50]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm
[18.19.50]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[18.19.50]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[18.19.50]	lable [1]: tp=15876, fp=10729, fn=6338, tn=27088, total=60031
P=0.59673, R=0.71468, F1=0.65040

[18.19.50]	lable [0]: tp=9970, fp=5538, fn=9717, tn=34806, total=60031
P=0.64289, R=0.50643, F1=0.56656

[18.19.50]	lable [2]: tp=10534, fp=7384, fn=7596, tn=34517, total=60031
P=0.58790, R=0.58103, F1=0.58444

[18.19.50]	Average F1 = 0.60047
Accuracy = 36380/60031 = 0.606020
[18.19.50]	Got evaluation for current fold, Avg. F1 = 0.60047
[18.19.50]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm
[18.19.50]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm.model
[18.20.12]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm
[18.20.12]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[18.20.12]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[18.20.12]	lable [1]: tp=16009, fp=11109, fn=6208, tn=26713, total=60039
P=0.59035, R=0.72057, F1=0.64899

[18.20.12]	lable [0]: tp=9954, fp=5540, fn=9735, tn=34810, total=60039
P=0.64244, R=0.50556, F1=0.56584

[18.20.12]	lable [2]: tp=10287, fp=7140, fn=7846, tn=34766, total=60039
P=0.59029, R=0.56731, F1=0.57857

[18.20.12]	Average F1 = 0.59780
Accuracy = 36250/60039 = 0.603774
[18.20.12]	Got evaluation for current fold, Avg. F1 = 0.59780
[18.20.12]	Evaluation Done! Final after 4-fold Avg. F1 = 0.59839
[18.20.12]	

Perfmon Summary:
Time Used(s): 88.055671
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33872
ru_minflt ->	43817
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	90
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	15
ru_oublock ->	4144
ru_stime ->	0.104006
ru_utime ->	86.73742

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33872
ru_minflt ->	87299
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	177
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	31
ru_oublock ->	7096
ru_stime ->	0.228014
ru_utime ->	173.762859

=========== ======== ============
		
[18.20.12]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM
[18.20.12]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm
[18.20.12]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm.model
[18.20.33]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm
[18.20.33]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[18.20.33]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[18.20.33]	lable [1]: tp=15640, fp=9840, fn=6573, tn=27980, total=60033
P=0.61381, R=0.70409, F1=0.65586

[18.20.33]	lable [0]: tp=10683, fp=5670, fn=9006, tn=34674, total=60033
P=0.65327, R=0.54259, F1=0.59281

[18.20.33]	lable [2]: tp=10911, fp=7289, fn=7220, tn=34613, total=60033
P=0.59951, R=0.60179, F1=0.60064

[18.20.33]	Average F1 = 0.61644
Accuracy = 37234/60033 = 0.620226
[18.20.33]	Got evaluation for current fold, Avg. F1 = 0.61644
[18.20.33]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm
[18.20.33]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm.model
[18.20.55]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm
[18.20.55]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[18.20.55]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[18.20.55]	lable [1]: tp=15787, fp=10153, fn=6426, tn=27667, total=60033
P=0.60860, R=0.71071, F1=0.65570

[18.20.55]	lable [0]: tp=10433, fp=6085, fn=9256, tn=34259, total=60033
P=0.63161, R=0.52989, F1=0.57630

[18.20.55]	lable [2]: tp=10869, fp=6706, fn=7262, tn=35196, total=60033
P=0.61844, R=0.59947, F1=0.60881

[18.20.55]	Average F1 = 0.61360
Accuracy = 37089/60033 = 0.617810
[18.20.55]	Got evaluation for current fold, Avg. F1 = 0.61360
[18.20.55]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm
[18.20.55]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm.model
[18.21.17]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm
[18.21.17]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[18.21.17]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[18.21.17]	lable [1]: tp=15841, fp=9911, fn=6372, tn=27909, total=60033
P=0.61514, R=0.71314, F1=0.66052

[18.21.17]	lable [0]: tp=10757, fp=5989, fn=8932, tn=34355, total=60033
P=0.64236, R=0.54635, F1=0.59048

[18.21.17]	lable [2]: tp=10763, fp=6772, fn=7368, tn=35130, total=60033
P=0.61380, R=0.59362, F1=0.60354

[18.21.17]	Average F1 = 0.61818
Accuracy = 37361/60033 = 0.622341
[18.21.17]	Got evaluation for current fold, Avg. F1 = 0.61818
[18.21.17]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm
[18.21.17]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm.model
[18.21.37]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm
[18.21.37]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[18.21.37]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[18.21.37]	lable [1]: tp=15780, fp=9985, fn=6436, tn=27839, total=60040
P=0.61246, R=0.71030, F1=0.65776

[18.21.37]	lable [0]: tp=10738, fp=6086, fn=8952, tn=34264, total=60040
P=0.63825, R=0.54535, F1=0.58816

[18.21.37]	lable [2]: tp=10629, fp=6822, fn=7505, tn=35084, total=60040
P=0.60908, R=0.58614, F1=0.59739

[18.21.37]	Average F1 = 0.61443
Accuracy = 37147/60040 = 0.618704
[18.21.37]	Got evaluation for current fold, Avg. F1 = 0.61443
[18.21.37]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61566
[18.21.37]	

Perfmon Summary:
Time Used(s): 85.354012
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33872
ru_minflt ->	87299
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	177
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	31
ru_oublock ->	7096
ru_stime ->	0.228014
ru_utime ->	173.762859

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33948
ru_minflt ->	131223
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	262
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	47
ru_oublock ->	11632
ru_stime ->	0.340021
ru_utime ->	258.10813

=========== ======== ============
		
[18.21.37]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L
[18.21.37]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm
[18.21.37]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm.model
[18.21.58]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm
[18.21.58]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm.predict
[18.21.59]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm.predict
[18.21.59]	lable [1]: tp=15640, fp=9840, fn=6573, tn=27980, total=60033
P=0.61381, R=0.70409, F1=0.65586

[18.21.59]	lable [0]: tp=10683, fp=5670, fn=9006, tn=34674, total=60033
P=0.65327, R=0.54259, F1=0.59281

[18.21.59]	lable [2]: tp=10911, fp=7289, fn=7220, tn=34613, total=60033
P=0.59951, R=0.60179, F1=0.60064

[18.21.59]	Average F1 = 0.61644
Accuracy = 37234/60033 = 0.620226
[18.21.59]	Got evaluation for current fold, Avg. F1 = 0.61644
[18.21.59]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm
[18.21.59]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm.model
[18.22.20]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm
[18.22.20]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm.predict
[18.22.20]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm.predict
[18.22.21]	lable [1]: tp=15787, fp=10153, fn=6426, tn=27667, total=60033
P=0.60860, R=0.71071, F1=0.65570

[18.22.21]	lable [0]: tp=10433, fp=6085, fn=9256, tn=34259, total=60033
P=0.63161, R=0.52989, F1=0.57630

[18.22.21]	lable [2]: tp=10869, fp=6706, fn=7262, tn=35196, total=60033
P=0.61844, R=0.59947, F1=0.60881

[18.22.21]	Average F1 = 0.61360
Accuracy = 37089/60033 = 0.617810
[18.22.21]	Got evaluation for current fold, Avg. F1 = 0.61360
[18.22.21]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm
[18.22.21]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm.model
[18.22.42]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm
[18.22.42]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm.predict
[18.22.42]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm.predict
[18.22.43]	lable [1]: tp=15841, fp=9911, fn=6372, tn=27909, total=60033
P=0.61514, R=0.71314, F1=0.66052

[18.22.43]	lable [0]: tp=10757, fp=5989, fn=8932, tn=34355, total=60033
P=0.64236, R=0.54635, F1=0.59048

[18.22.43]	lable [2]: tp=10763, fp=6772, fn=7368, tn=35130, total=60033
P=0.61380, R=0.59362, F1=0.60354

[18.22.43]	Average F1 = 0.61818
Accuracy = 37361/60033 = 0.622341
[18.22.43]	Got evaluation for current fold, Avg. F1 = 0.61818
[18.22.43]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm
[18.22.43]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm.model
[18.23.02]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm
[18.23.02]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm.predict
[18.23.02]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm.predict
[18.23.02]	lable [1]: tp=15780, fp=9985, fn=6436, tn=27839, total=60040
P=0.61246, R=0.71030, F1=0.65776

[18.23.02]	lable [0]: tp=10738, fp=6086, fn=8952, tn=34264, total=60040
P=0.63825, R=0.54535, F1=0.58816

[18.23.02]	lable [2]: tp=10629, fp=6822, fn=7505, tn=35084, total=60040
P=0.60908, R=0.58614, F1=0.59739

[18.23.02]	Average F1 = 0.61443
Accuracy = 37147/60040 = 0.618704
[18.23.02]	Got evaluation for current fold, Avg. F1 = 0.61443
[18.23.02]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61566
[18.23.02]	

Perfmon Summary:
Time Used(s): 85.164027
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33948
ru_minflt ->	131223
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	262
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	47
ru_oublock ->	11632
ru_stime ->	0.340021
ru_utime ->	258.10813

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33952
ru_minflt ->	175156
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	350
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	63
ru_oublock ->	16168
ru_stime ->	0.408025
ru_utime ->	342.317393

=========== ======== ============
		
[18.23.02]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM
[18.23.02]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[18.23.02]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model
[18.23.24]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[18.23.24]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[18.23.24]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[18.23.24]	lable [1]: tp=15552, fp=10230, fn=6663, tn=27592, total=60037
P=0.60321, R=0.70007, F1=0.64804

[18.23.24]	lable [0]: tp=9995, fp=5134, fn=9694, tn=35214, total=60037
P=0.66065, R=0.50764, F1=0.57413

[18.23.24]	lable [2]: tp=11050, fp=8076, fn=7083, tn=33828, total=60037
P=0.57775, R=0.60939, F1=0.59315

[18.23.24]	Average F1 = 0.60510
Accuracy = 36597/60037 = 0.609574
[18.23.24]	Got evaluation for current fold, Avg. F1 = 0.60510
[18.23.24]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[18.23.24]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model
[18.23.46]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[18.23.46]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[18.23.46]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[18.23.46]	lable [1]: tp=15816, fp=10521, fn=6399, tn=27301, total=60037
P=0.60052, R=0.71195, F1=0.65151

[18.23.46]	lable [0]: tp=9884, fp=5610, fn=9805, tn=34738, total=60037
P=0.63792, R=0.50201, F1=0.56186

[18.23.46]	lable [2]: tp=10946, fp=7260, fn=7187, tn=34644, total=60037
P=0.60123, R=0.60365, F1=0.60244

[18.23.46]	Average F1 = 0.60527
Accuracy = 36646/60037 = 0.610390
[18.23.46]	Got evaluation for current fold, Avg. F1 = 0.60527
[18.23.46]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[18.23.46]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model
[18.24.09]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[18.24.09]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[18.24.09]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[18.24.09]	lable [1]: tp=15882, fp=10318, fn=6333, tn=27504, total=60037
P=0.60618, R=0.71492, F1=0.65608

[18.24.09]	lable [0]: tp=10203, fp=5522, fn=9486, tn=34826, total=60037
P=0.64884, R=0.51821, F1=0.57621

[18.24.09]	lable [2]: tp=10823, fp=7289, fn=7310, tn=34615, total=60037
P=0.59756, R=0.59687, F1=0.59721

[18.24.09]	Average F1 = 0.60983
Accuracy = 36908/60037 = 0.614754
[18.24.09]	Got evaluation for current fold, Avg. F1 = 0.60983
[18.24.09]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[18.24.09]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model
[18.24.30]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[18.24.30]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[18.24.30]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[18.24.31]	lable [1]: tp=15997, fp=10716, fn=6219, tn=27108, total=60040
P=0.59885, R=0.72007, F1=0.65389

[18.24.31]	lable [0]: tp=10084, fp=5512, fn=9607, tn=34837, total=60040
P=0.64658, R=0.51211, F1=0.57154

[18.24.31]	lable [2]: tp=10540, fp=7191, fn=7593, tn=34716, total=60040
P=0.59444, R=0.58126, F1=0.58778

[18.24.31]	Average F1 = 0.60440
Accuracy = 36621/60040 = 0.609943
[18.24.31]	Got evaluation for current fold, Avg. F1 = 0.60440
[18.24.31]	Evaluation Done! Final after 4-fold Avg. F1 = 0.60615
[18.24.31]	

Perfmon Summary:
Time Used(s): 88.242516
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33952
ru_minflt ->	175156
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	350
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	63
ru_oublock ->	16168
ru_stime ->	0.408025
ru_utime ->	342.317393

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33952
ru_minflt ->	219001
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	440
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	79
ru_oublock ->	19984
ru_stime ->	0.49203
ru_utime ->	429.582847

=========== ======== ============
		
[18.24.31]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP
[18.24.31]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[18.24.31]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model
[18.24.52]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[18.24.52]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[18.24.53]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[18.24.53]	lable [1]: tp=15552, fp=10230, fn=6663, tn=27592, total=60037
P=0.60321, R=0.70007, F1=0.64804

[18.24.53]	lable [0]: tp=9995, fp=5134, fn=9694, tn=35214, total=60037
P=0.66065, R=0.50764, F1=0.57413

[18.24.53]	lable [2]: tp=11050, fp=8076, fn=7083, tn=33828, total=60037
P=0.57775, R=0.60939, F1=0.59315

[18.24.53]	Average F1 = 0.60510
Accuracy = 36597/60037 = 0.609574
[18.24.53]	Got evaluation for current fold, Avg. F1 = 0.60510
[18.24.53]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[18.24.53]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model
[18.25.14]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[18.25.14]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[18.25.14]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[18.25.14]	lable [1]: tp=15816, fp=10521, fn=6399, tn=27301, total=60037
P=0.60052, R=0.71195, F1=0.65151

[18.25.14]	lable [0]: tp=9884, fp=5610, fn=9805, tn=34738, total=60037
P=0.63792, R=0.50201, F1=0.56186

[18.25.14]	lable [2]: tp=10946, fp=7260, fn=7187, tn=34644, total=60037
P=0.60123, R=0.60365, F1=0.60244

[18.25.14]	Average F1 = 0.60527
Accuracy = 36646/60037 = 0.610390
[18.25.14]	Got evaluation for current fold, Avg. F1 = 0.60527
[18.25.14]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[18.25.14]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model
[18.25.37]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[18.25.37]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[18.25.37]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[18.25.38]	lable [1]: tp=15882, fp=10318, fn=6333, tn=27504, total=60037
P=0.60618, R=0.71492, F1=0.65608

[18.25.38]	lable [0]: tp=10203, fp=5522, fn=9486, tn=34826, total=60037
P=0.64884, R=0.51821, F1=0.57621

[18.25.38]	lable [2]: tp=10823, fp=7289, fn=7310, tn=34615, total=60037
P=0.59756, R=0.59687, F1=0.59721

[18.25.38]	Average F1 = 0.60983
Accuracy = 36908/60037 = 0.614754
[18.25.38]	Got evaluation for current fold, Avg. F1 = 0.60983
[18.25.38]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[18.25.38]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model
[18.25.59]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[18.25.59]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[18.25.59]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[18.25.59]	lable [1]: tp=15997, fp=10716, fn=6219, tn=27108, total=60040
P=0.59885, R=0.72007, F1=0.65389

[18.25.59]	lable [0]: tp=10084, fp=5512, fn=9607, tn=34837, total=60040
P=0.64658, R=0.51211, F1=0.57154

[18.25.59]	lable [2]: tp=10540, fp=7191, fn=7593, tn=34716, total=60040
P=0.59444, R=0.58126, F1=0.58778

[18.25.59]	Average F1 = 0.60440
Accuracy = 36621/60040 = 0.609943
[18.25.59]	Got evaluation for current fold, Avg. F1 = 0.60440
[18.25.59]	Evaluation Done! Final after 4-fold Avg. F1 = 0.60615
[18.25.59]	

Perfmon Summary:
Time Used(s): 88.433414
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33952
ru_minflt ->	219001
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	440
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	79
ru_oublock ->	19984
ru_stime ->	0.49203
ru_utime ->	429.582847

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	33952
ru_minflt ->	262854
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	531
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	95
ru_oublock ->	23784
ru_stime ->	0.552034
ru_utime ->	517.068314

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130305182903
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[18.29.03]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[18.29.03]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[18.29.03]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model


======================================================
*********************************************************
Start logging 20130305182903
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[18.29.03]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[18.29.03]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[18.29.03]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model


======================================================
*********************************************************
Start logging 20130305182922
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[18.29.22]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM
[18.29.22]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm
[18.29.22]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm.model
[18.30.07]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm
[18.30.07]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[18.30.07]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[18.30.07]	lable [1]: tp=2208, fp=2912, fn=4607, tn=42496, total=52223
P=0.43125, R=0.32399, F1=0.37000

[18.30.07]	lable [0]: tp=3137, fp=4146, fn=5163, tn=39777, total=52223
P=0.43073, R=0.37795, F1=0.40262

[18.30.07]	lable [3]: tp=2601, fp=2938, fn=4855, tn=41829, total=52223
P=0.46958, R=0.34885, F1=0.40031

[18.30.07]	lable [2]: tp=5819, fp=9757, fn=3184, tn=33463, total=52223
P=0.37359, R=0.64634, F1=0.47349

[18.30.07]	lable [5]: tp=3127, fp=5664, fn=4485, tn=38947, total=52223
P=0.35570, R=0.41080, F1=0.38127

[18.30.07]	lable [4]: tp=1826, fp=1979, fn=4463, tn=43955, total=52223
P=0.47989, R=0.29035, F1=0.36180

[18.30.07]	lable [6]: tp=2665, fp=3444, fn=4083, tn=42031, total=52223
P=0.43624, R=0.39493, F1=0.41456

[18.30.07]	Average F1 = 0.40058
Accuracy = 21383/52223 = 0.409456
[18.30.07]	Got evaluation for current fold, Avg. F1 = 0.40058
[18.30.07]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm
[18.30.07]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm.model
[18.30.50]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm
[18.30.50]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[18.30.50]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[18.30.50]	lable [1]: tp=2456, fp=3085, fn=4359, tn=42323, total=52223
P=0.44324, R=0.36038, F1=0.39754

[18.30.50]	lable [0]: tp=3119, fp=4442, fn=5181, tn=39481, total=52223
P=0.41251, R=0.37578, F1=0.39329

[18.30.50]	lable [3]: tp=2682, fp=3321, fn=4774, tn=41446, total=52223
P=0.44678, R=0.35971, F1=0.39854

[18.30.50]	lable [2]: tp=5583, fp=8657, fn=3420, tn=34563, total=52223
P=0.39206, R=0.62013, F1=0.48040

[18.30.50]	lable [5]: tp=3203, fp=5042, fn=4409, tn=39569, total=52223
P=0.38848, R=0.42078, F1=0.40399

[18.30.50]	lable [4]: tp=1934, fp=2398, fn=4355, tn=43536, total=52223
P=0.44645, R=0.30752, F1=0.36418

[18.30.50]	lable [6]: tp=2749, fp=3552, fn=3999, tn=41923, total=52223
P=0.43628, R=0.40738, F1=0.42133

[18.30.50]	Average F1 = 0.40847
Accuracy = 21726/52223 = 0.416024
[18.30.50]	Got evaluation for current fold, Avg. F1 = 0.40847
[18.30.50]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm
[18.30.50]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm.model
[18.31.33]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm
[18.31.33]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[18.31.33]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[18.31.33]	lable [1]: tp=2378, fp=3148, fn=4437, tn=42260, total=52223
P=0.43033, R=0.34894, F1=0.38538

[18.31.33]	lable [0]: tp=2963, fp=4006, fn=5337, tn=39917, total=52223
P=0.42517, R=0.35699, F1=0.38811

[18.31.33]	lable [3]: tp=2809, fp=3554, fn=4647, tn=41213, total=52223
P=0.44146, R=0.37674, F1=0.40654

[18.31.33]	lable [2]: tp=5466, fp=9161, fn=3537, tn=34059, total=52223
P=0.37369, R=0.60713, F1=0.46263

[18.31.33]	lable [5]: tp=3151, fp=5267, fn=4461, tn=39344, total=52223
P=0.37432, R=0.41395, F1=0.39314

[18.31.33]	lable [4]: tp=1792, fp=2145, fn=4497, tn=43789, total=52223
P=0.45517, R=0.28494, F1=0.35048

[18.31.33]	lable [6]: tp=2575, fp=3808, fn=4173, tn=41667, total=52223
P=0.40342, R=0.38159, F1=0.39220

[18.31.33]	Average F1 = 0.39693
Accuracy = 21134/52223 = 0.404688
[18.31.33]	Got evaluation for current fold, Avg. F1 = 0.39693
[18.31.33]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm
[18.31.33]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm.model
[18.32.15]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm
[18.32.15]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[18.32.15]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[18.32.15]	lable [1]: tp=2235, fp=2901, fn=4582, tn=42519, total=52237
P=0.43516, R=0.32786, F1=0.37396

[18.32.15]	lable [0]: tp=3151, fp=4478, fn=5150, tn=39458, total=52237
P=0.41303, R=0.37959, F1=0.39561

[18.32.15]	lable [3]: tp=2745, fp=3750, fn=4714, tn=41028, total=52237
P=0.42263, R=0.36801, F1=0.39344

[18.32.15]	lable [2]: tp=5494, fp=8880, fn=3512, tn=34351, total=52237
P=0.38222, R=0.61004, F1=0.46997

[18.32.15]	lable [5]: tp=3090, fp=5684, fn=4524, tn=38939, total=52237
P=0.35218, R=0.40583, F1=0.37711

[18.32.15]	lable [4]: tp=1926, fp=2316, fn=4366, tn=43629, total=52237
P=0.45403, R=0.30610, F1=0.36567

[18.32.15]	lable [6]: tp=2518, fp=3069, fn=4230, tn=42420, total=52237
P=0.45069, R=0.37315, F1=0.40827

[18.32.15]	Average F1 = 0.39772
Accuracy = 21159/52237 = 0.405058
[18.32.15]	Got evaluation for current fold, Avg. F1 = 0.39772
[18.32.15]	Evaluation Done! Final after 4-fold Avg. F1 = 0.40092
[18.32.15]	

Perfmon Summary:
Time Used(s): 172.505218
Memory Used (Mb): 30.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	30892
ru_minflt ->	52424
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	181
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	16
ru_oublock ->	7824
ru_stime ->	0.112007
ru_utime ->	170.998686

=========== ======== ============
		
[18.32.15]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM
[18.32.15]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm
[18.32.15]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm.model
[18.32.57]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm
[18.32.57]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[18.32.57]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[18.32.57]	lable [1]: tp=2107, fp=2948, fn=4708, tn=42456, total=52219
P=0.41682, R=0.30917, F1=0.35501

[18.32.57]	lable [0]: tp=3012, fp=4104, fn=5287, tn=39816, total=52219
P=0.42327, R=0.36294, F1=0.39079

[18.32.57]	lable [3]: tp=2507, fp=3164, fn=4949, tn=41599, total=52219
P=0.44207, R=0.33624, F1=0.38196

[18.32.57]	lable [2]: tp=5764, fp=10233, fn=3239, tn=32983, total=52219
P=0.36032, R=0.64023, F1=0.46112

[18.32.57]	lable [5]: tp=2951, fp=5693, fn=4660, tn=38915, total=52219
P=0.34139, R=0.38773, F1=0.36309

[18.32.57]	lable [4]: tp=1681, fp=1876, fn=4607, tn=44055, total=52219
P=0.47259, R=0.26733, F1=0.34149

[18.32.57]	lable [6]: tp=2565, fp=3614, fn=4182, tn=41858, total=52219
P=0.41512, R=0.38017, F1=0.39687

[18.32.57]	Average F1 = 0.38433
Accuracy = 20587/52219 = 0.394243
[18.32.57]	Got evaluation for current fold, Avg. F1 = 0.38433
[18.32.57]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm
[18.32.57]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm.model
[18.33.40]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm
[18.33.40]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[18.33.40]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[18.33.40]	lable [1]: tp=2323, fp=3144, fn=4492, tn=42260, total=52219
P=0.42491, R=0.34087, F1=0.37828

[18.33.40]	lable [0]: tp=2954, fp=4323, fn=5345, tn=39597, total=52219
P=0.40594, R=0.35595, F1=0.37930

[18.33.40]	lable [3]: tp=2589, fp=3521, fn=4867, tn=41242, total=52219
P=0.42373, R=0.34724, F1=0.38169

[18.33.40]	lable [2]: tp=5548, fp=9195, fn=3455, tn=34021, total=52219
P=0.37631, R=0.61624, F1=0.46728

[18.33.40]	lable [5]: tp=3049, fp=5200, fn=4562, tn=39408, total=52219
P=0.36962, R=0.40060, F1=0.38449

[18.33.40]	lable [4]: tp=1790, fp=2404, fn=4498, tn=43527, total=52219
P=0.42680, R=0.28467, F1=0.34154

[18.33.40]	lable [6]: tp=2628, fp=3551, fn=4119, tn=41921, total=52219
P=0.42531, R=0.38951, F1=0.40662

[18.33.40]	Average F1 = 0.39131
Accuracy = 20881/52219 = 0.399874
[18.33.40]	Got evaluation for current fold, Avg. F1 = 0.39131
[18.33.40]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm
[18.33.40]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm.model
[18.34.22]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm
[18.34.22]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[18.34.22]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[18.34.23]	lable [1]: tp=2198, fp=3132, fn=4617, tn=42272, total=52219
P=0.41238, R=0.32252, F1=0.36196

[18.34.23]	lable [0]: tp=2847, fp=4027, fn=5452, tn=39893, total=52219
P=0.41417, R=0.34305, F1=0.37527

[18.34.23]	lable [3]: tp=2657, fp=3708, fn=4799, tn=41055, total=52219
P=0.41744, R=0.35636, F1=0.38449

[18.34.23]	lable [2]: tp=5458, fp=9839, fn=3545, tn=33377, total=52219
P=0.35680, R=0.60624, F1=0.44922

[18.34.23]	lable [5]: tp=2959, fp=5244, fn=4652, tn=39364, total=52219
P=0.36072, R=0.38878, F1=0.37423

[18.34.23]	lable [4]: tp=1703, fp=2103, fn=4585, tn=43828, total=52219
P=0.44745, R=0.27083, F1=0.33743

[18.34.23]	lable [6]: tp=2501, fp=3843, fn=4246, tn=41629, total=52219
P=0.39423, R=0.37068, F1=0.38209

[18.34.23]	Average F1 = 0.38067
Accuracy = 20323/52219 = 0.389188
[18.34.23]	Got evaluation for current fold, Avg. F1 = 0.38067
[18.34.23]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm
[18.34.23]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm.model
[18.35.05]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm
[18.35.05]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[18.35.05]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[18.35.05]	lable [1]: tp=2103, fp=2981, fn=4712, tn=42432, total=52228
P=0.41365, R=0.30858, F1=0.35348

[18.35.05]	lable [0]: tp=3022, fp=4420, fn=5278, tn=39508, total=52228
P=0.40607, R=0.36410, F1=0.38394

[18.35.05]	lable [3]: tp=2673, fp=3896, fn=4784, tn=40875, total=52228
P=0.40691, R=0.35846, F1=0.38115

[18.35.05]	lable [2]: tp=5475, fp=9353, fn=3529, tn=33871, total=52228
P=0.36923, R=0.60806, F1=0.45947

[18.35.05]	lable [5]: tp=2917, fp=5711, fn=4696, tn=38904, total=52228
P=0.33809, R=0.38316, F1=0.35921

[18.35.05]	lable [4]: tp=1768, fp=2251, fn=4523, tn=43686, total=52228
P=0.43991, R=0.28104, F1=0.34297

[18.35.05]	lable [6]: tp=2415, fp=3243, fn=4333, tn=42237, total=52228
P=0.42683, R=0.35788, F1=0.38933

[18.35.05]	Average F1 = 0.38136
Accuracy = 20373/52228 = 0.390078
[18.35.05]	Got evaluation for current fold, Avg. F1 = 0.38136
[18.35.05]	Evaluation Done! Final after 4-fold Avg. F1 = 0.38442
[18.35.05]	

Perfmon Summary:
Time Used(s): 170.152769
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	30892
ru_minflt ->	52424
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	181
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	16
ru_oublock ->	7824
ru_stime ->	0.112007
ru_utime ->	170.998686

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	30892
ru_minflt ->	104348
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	358
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	32
ru_oublock ->	13040
ru_stime ->	0.232014
ru_utime ->	339.649226

=========== ======== ============
		
[18.35.05]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM
[18.35.05]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm
[18.35.05]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm.model
[18.35.47]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm
[18.35.47]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[18.35.47]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[18.35.48]	lable [1]: tp=2285, fp=2896, fn=4530, tn=42510, total=52221
P=0.44103, R=0.33529, F1=0.38096

[18.35.48]	lable [0]: tp=3534, fp=5354, fn=4766, tn=38567, total=52221
P=0.39761, R=0.42578, F1=0.41122

[18.35.48]	lable [3]: tp=2571, fp=2843, fn=4885, tn=41922, total=52221
P=0.47488, R=0.34482, F1=0.39953

[18.35.48]	lable [2]: tp=5648, fp=8900, fn=3355, tn=34318, total=52221
P=0.38823, R=0.62735, F1=0.47964

[18.35.48]	lable [5]: tp=3161, fp=5721, fn=4451, tn=38888, total=52221
P=0.35589, R=0.41527, F1=0.38329

[18.35.48]	lable [4]: tp=1815, fp=2079, fn=4473, tn=43854, total=52221
P=0.46610, R=0.28865, F1=0.35651

[18.35.48]	lable [6]: tp=2555, fp=2859, fn=4192, tn=42615, total=52221
P=0.47192, R=0.37869, F1=0.42020

[18.35.48]	Average F1 = 0.40448
Accuracy = 21569/52221 = 0.413033
[18.35.48]	Got evaluation for current fold, Avg. F1 = 0.40448
[18.35.48]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm
[18.35.48]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm.model
[18.36.29]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm
[18.36.29]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[18.36.30]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[18.36.30]	lable [1]: tp=2473, fp=2985, fn=4342, tn=42421, total=52221
P=0.45310, R=0.36288, F1=0.40300

[18.36.30]	lable [0]: tp=3564, fp=5621, fn=4736, tn=38300, total=52221
P=0.38802, R=0.42940, F1=0.40766

[18.36.30]	lable [3]: tp=2694, fp=3227, fn=4762, tn=41538, total=52221
P=0.45499, R=0.36132, F1=0.40278

[18.36.30]	lable [2]: tp=5573, fp=8390, fn=3430, tn=34828, total=52221
P=0.39913, R=0.61902, F1=0.48533

[18.36.30]	lable [5]: tp=3093, fp=4684, fn=4519, tn=39925, total=52221
P=0.39771, R=0.40633, F1=0.40198

[18.36.30]	lable [4]: tp=1946, fp=2325, fn=4342, tn=43608, total=52221
P=0.45563, R=0.30948, F1=0.36860

[18.36.30]	lable [6]: tp=2660, fp=2986, fn=4087, tn=42488, total=52221
P=0.47113, R=0.39425, F1=0.42927

[18.36.30]	Average F1 = 0.41409
Accuracy = 22003/52221 = 0.421344
[18.36.30]	Got evaluation for current fold, Avg. F1 = 0.41409
[18.36.30]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm
[18.36.30]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm.model
[18.37.11]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm
[18.37.11]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[18.37.11]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[18.37.12]	lable [1]: tp=2312, fp=2901, fn=4503, tn=42505, total=52221
P=0.44351, R=0.33925, F1=0.38444

[18.37.12]	lable [0]: tp=3407, fp=5029, fn=4893, tn=38892, total=52221
P=0.40386, R=0.41048, F1=0.40715

[18.37.12]	lable [3]: tp=2798, fp=3265, fn=4658, tn=41500, total=52221
P=0.46149, R=0.37527, F1=0.41394

[18.37.12]	lable [2]: tp=5380, fp=8906, fn=3623, tn=34312, total=52221
P=0.37659, R=0.59758, F1=0.46202

[18.37.12]	lable [5]: tp=3198, fp=5464, fn=4414, tn=39145, total=52221
P=0.36920, R=0.42013, F1=0.39302

[18.37.12]	lable [4]: tp=1860, fp=2159, fn=4428, tn=43774, total=52221
P=0.46280, R=0.29580, F1=0.36092

[18.37.12]	lable [6]: tp=2526, fp=3016, fn=4221, tn=42458, total=52221
P=0.45579, R=0.37439, F1=0.41110

[18.37.12]	Average F1 = 0.40465
Accuracy = 21481/52221 = 0.411348
[18.37.12]	Got evaluation for current fold, Avg. F1 = 0.40465
[18.37.12]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm
[18.37.12]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm.model
[18.37.54]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm
[18.37.54]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[18.37.54]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[18.37.54]	lable [1]: tp=2252, fp=2939, fn=4565, tn=42477, total=52233
P=0.43383, R=0.33035, F1=0.37508

[18.37.54]	lable [0]: tp=3559, fp=5602, fn=4742, tn=38330, total=52233
P=0.38849, R=0.42874, F1=0.40763

[18.37.54]	lable [3]: tp=2756, fp=3707, fn=4702, tn=41068, total=52233
P=0.42643, R=0.36954, F1=0.39595

[18.37.54]	lable [2]: tp=5408, fp=8441, fn=3597, tn=34787, total=52233
P=0.39050, R=0.60056, F1=0.47327

[18.37.54]	lable [5]: tp=2918, fp=5110, fn=4695, tn=39510, total=52233
P=0.36348, R=0.38329, F1=0.37312

[18.37.54]	lable [4]: tp=1918, fp=2218, fn=4373, tn=43724, total=52233
P=0.46373, R=0.30488, F1=0.36789

[18.37.54]	lable [6]: tp=2511, fp=2894, fn=4237, tn=42591, total=52233
P=0.46457, R=0.37211, F1=0.41323

[18.37.54]	Average F1 = 0.40088
Accuracy = 21322/52233 = 0.408209
[18.37.54]	Got evaluation for current fold, Avg. F1 = 0.40088
[18.37.54]	Evaluation Done! Final after 4-fold Avg. F1 = 0.40603
[18.37.54]	

Perfmon Summary:
Time Used(s): 168.955322
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	30892
ru_minflt ->	104348
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	358
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	32
ru_oublock ->	13040
ru_stime ->	0.232014
ru_utime ->	339.649226

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	156966
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	532
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	48
ru_oublock ->	21928
ru_stime ->	0.32002
ru_utime ->	507.127693

=========== ======== ============
		
[18.37.54]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L
[18.37.54]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm
[18.37.54]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm.model
[18.38.34]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm
[18.38.34]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm.predict
[18.38.34]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold0_tst.libsvm.predict
[18.38.34]	lable [1]: tp=2252, fp=2804, fn=4563, tn=42604, total=52223
P=0.44541, R=0.33045, F1=0.37941

[18.38.34]	lable [0]: tp=3264, fp=4607, fn=5036, tn=39316, total=52223
P=0.41469, R=0.39325, F1=0.40369

[18.38.34]	lable [3]: tp=2593, fp=2941, fn=4863, tn=41826, total=52223
P=0.46856, R=0.34777, F1=0.39923

[18.38.34]	lable [2]: tp=5888, fp=9632, fn=3115, tn=33588, total=52223
P=0.37938, R=0.65400, F1=0.48020

[18.38.34]	lable [5]: tp=3160, fp=5491, fn=4452, tn=39120, total=52223
P=0.36528, R=0.41513, F1=0.38861

[18.38.34]	lable [4]: tp=1880, fp=2048, fn=4409, tn=43886, total=52223
P=0.47862, R=0.29893, F1=0.36801

[18.38.34]	lable [6]: tp=2628, fp=3035, fn=4120, tn=42440, total=52223
P=0.46406, R=0.38945, F1=0.42350

[18.38.34]	Average F1 = 0.40609
Accuracy = 21665/52223 = 0.414856
[18.38.34]	Got evaluation for current fold, Avg. F1 = 0.40609
[18.38.34]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm
[18.38.34]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm.model
[18.39.15]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm
[18.39.15]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm.predict
[18.39.15]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold1_tst.libsvm.predict
[18.39.15]	lable [1]: tp=2458, fp=2917, fn=4357, tn=42491, total=52223
P=0.45730, R=0.36067, F1=0.40328

[18.39.15]	lable [0]: tp=3203, fp=4821, fn=5097, tn=39102, total=52223
P=0.39918, R=0.38590, F1=0.39243

[18.39.15]	lable [3]: tp=2721, fp=3263, fn=4735, tn=41504, total=52223
P=0.45471, R=0.36494, F1=0.40491

[18.39.15]	lable [2]: tp=5553, fp=8447, fn=3450, tn=34773, total=52223
P=0.39664, R=0.61679, F1=0.48281

[18.39.15]	lable [5]: tp=3196, fp=5058, fn=4416, tn=39553, total=52223
P=0.38721, R=0.41986, F1=0.40287

[18.39.15]	lable [4]: tp=2004, fp=2543, fn=4285, tn=43391, total=52223
P=0.44073, R=0.31865, F1=0.36988

[18.39.15]	lable [6]: tp=2751, fp=3288, fn=3997, tn=42187, total=52223
P=0.45554, R=0.40768, F1=0.43028

[18.39.15]	Average F1 = 0.41235
Accuracy = 21886/52223 = 0.419087
[18.39.15]	Got evaluation for current fold, Avg. F1 = 0.41235
[18.39.15]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm
[18.39.15]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm.model
[18.39.55]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm
[18.39.55]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm.predict
[18.39.55]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold2_tst.libsvm.predict
[18.39.55]	lable [1]: tp=2397, fp=3050, fn=4418, tn=42358, total=52223
P=0.44006, R=0.35172, F1=0.39096

[18.39.55]	lable [0]: tp=3040, fp=4221, fn=5260, tn=39702, total=52223
P=0.41868, R=0.36627, F1=0.39072

[18.39.55]	lable [3]: tp=2781, fp=3476, fn=4675, tn=41291, total=52223
P=0.44446, R=0.37299, F1=0.40560

[18.39.55]	lable [2]: tp=5487, fp=9192, fn=3516, tn=34028, total=52223
P=0.37380, R=0.60946, F1=0.46339

[18.39.55]	lable [5]: tp=3123, fp=5057, fn=4489, tn=39554, total=52223
P=0.38178, R=0.41027, F1=0.39552

[18.39.55]	lable [4]: tp=1843, fp=2177, fn=4446, tn=43757, total=52223
P=0.45846, R=0.29305, F1=0.35755

[18.39.55]	lable [6]: tp=2608, fp=3771, fn=4140, tn=41704, total=52223
P=0.40884, R=0.38648, F1=0.39735

[18.39.55]	Average F1 = 0.40016
Accuracy = 21279/52223 = 0.407464
[18.39.55]	Got evaluation for current fold, Avg. F1 = 0.40016
[18.39.55]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm
[18.39.55]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm.model
[18.40.35]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm
[18.40.35]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm.predict
[18.40.35]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_CV4/fold3_tst.libsvm.predict
[18.40.36]	lable [1]: tp=2280, fp=2849, fn=4537, tn=42568, total=52234
P=0.44453, R=0.33446, F1=0.38172

[18.40.36]	lable [0]: tp=3305, fp=5088, fn=4995, tn=38846, total=52234
P=0.39378, R=0.39819, F1=0.39597

[18.40.36]	lable [3]: tp=2717, fp=3640, fn=4742, tn=41135, total=52234
P=0.42740, R=0.36426, F1=0.39331

[18.40.36]	lable [2]: tp=5539, fp=8686, fn=3467, tn=34542, total=52234
P=0.38938, R=0.61503, F1=0.47686

[18.40.36]	lable [5]: tp=3071, fp=5219, fn=4542, tn=39402, total=52234
P=0.37045, R=0.40339, F1=0.38622

[18.40.36]	lable [4]: tp=1968, fp=2275, fn=4323, tn=43668, total=52234
P=0.46382, R=0.31283, F1=0.37365

[18.40.36]	lable [6]: tp=2556, fp=3041, fn=4192, tn=42445, total=52234
P=0.45667, R=0.37878, F1=0.41409

[18.40.36]	Average F1 = 0.40312
Accuracy = 21436/52234 = 0.410384
[18.40.36]	Got evaluation for current fold, Avg. F1 = 0.40312
[18.40.36]	Evaluation Done! Final after 4-fold Avg. F1 = 0.40543
[18.40.36]	

Perfmon Summary:
Time Used(s): 161.603219
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	156966
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	532
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	48
ru_oublock ->	21928
ru_stime ->	0.32002
ru_utime ->	507.127693

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	209462
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	701
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	64
ru_oublock ->	30728
ru_stime ->	0.448028
ru_utime ->	667.233699

=========== ======== ============
		
[18.40.36]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM
[18.40.36]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[18.40.36]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model
[18.41.17]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[18.41.17]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[18.41.17]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[18.41.17]	lable [1]: tp=2093, fp=2678, fn=4719, tn=42719, total=52209
P=0.43869, R=0.30725, F1=0.36139

[18.41.17]	lable [0]: tp=2979, fp=4073, fn=5319, tn=39838, total=52209
P=0.42243, R=0.35900, F1=0.38814

[18.41.17]	lable [3]: tp=2597, fp=3110, fn=4858, tn=41644, total=52209
P=0.45506, R=0.34836, F1=0.39462

[18.41.17]	lable [2]: tp=5751, fp=9932, fn=3250, tn=33276, total=52209
P=0.36670, R=0.63893, F1=0.46597

[18.41.17]	lable [5]: tp=3140, fp=6085, fn=4470, tn=38514, total=52209
P=0.34038, R=0.41261, F1=0.37303

[18.41.17]	lable [4]: tp=1793, fp=1985, fn=4494, tn=43937, total=52209
P=0.47459, R=0.28519, F1=0.35628

[18.41.17]	lable [6]: tp=2476, fp=3517, fn=4270, tn=41946, total=52209
P=0.41315, R=0.36703, F1=0.38873

[18.41.17]	Average F1 = 0.38974
Accuracy = 20829/52209 = 0.398954
[18.41.17]	Got evaluation for current fold, Avg. F1 = 0.38974
[18.41.17]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[18.41.17]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model
[18.41.56]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[18.41.56]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[18.41.56]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[18.41.57]	lable [1]: tp=2321, fp=2843, fn=4491, tn=42554, total=52209
P=0.44946, R=0.34072, F1=0.38761

[18.41.57]	lable [0]: tp=2965, fp=4282, fn=5333, tn=39629, total=52209
P=0.40913, R=0.35732, F1=0.38147

[18.41.57]	lable [3]: tp=2701, fp=3627, fn=4754, tn=41127, total=52209
P=0.42683, R=0.36231, F1=0.39193

[18.41.57]	lable [2]: tp=5470, fp=8664, fn=3531, tn=34544, total=52209
P=0.38701, R=0.60771, F1=0.47288

[18.41.57]	lable [5]: tp=3270, fp=5651, fn=4340, tn=38948, total=52209
P=0.36655, R=0.42970, F1=0.39562

[18.41.57]	lable [4]: tp=1884, fp=2314, fn=4403, tn=43608, total=52209
P=0.44879, R=0.29967, F1=0.35937

[18.41.57]	lable [6]: tp=2578, fp=3639, fn=4168, tn=41824, total=52209
P=0.41467, R=0.38215, F1=0.39775

[18.41.57]	Average F1 = 0.39809
Accuracy = 21189/52209 = 0.405850
[18.41.57]	Got evaluation for current fold, Avg. F1 = 0.39809
[18.41.57]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[18.41.57]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model
[18.42.36]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[18.42.36]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[18.42.36]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[18.42.37]	lable [1]: tp=2224, fp=2823, fn=4588, tn=42574, total=52209
P=0.44066, R=0.32648, F1=0.37507

[18.42.37]	lable [0]: tp=2905, fp=4123, fn=5393, tn=39788, total=52209
P=0.41335, R=0.35008, F1=0.37909

[18.42.37]	lable [3]: tp=2826, fp=3819, fn=4629, tn=40935, total=52209
P=0.42528, R=0.37907, F1=0.40085

[18.42.37]	lable [2]: tp=5338, fp=9119, fn=3663, tn=34089, total=52209
P=0.36923, R=0.59305, F1=0.45511

[18.42.37]	lable [5]: tp=3196, fp=5827, fn=4414, tn=38772, total=52209
P=0.35421, R=0.41997, F1=0.38430

[18.42.37]	lable [4]: tp=1758, fp=2060, fn=4529, tn=43862, total=52209
P=0.46045, R=0.27962, F1=0.34795

[18.42.37]	lable [6]: tp=2392, fp=3799, fn=4354, tn=41664, total=52209
P=0.38637, R=0.35458, F1=0.36979

[18.42.37]	Average F1 = 0.38745
Accuracy = 20639/52209 = 0.395315
[18.42.37]	Got evaluation for current fold, Avg. F1 = 0.38745
[18.42.37]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[18.42.37]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model
[18.43.15]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[18.43.15]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[18.43.15]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[18.43.15]	lable [1]: tp=2087, fp=2753, fn=4725, tn=42653, total=52218
P=0.43120, R=0.30637, F1=0.35822

[18.43.15]	lable [0]: tp=3072, fp=4636, fn=5229, tn=39281, total=52218
P=0.39855, R=0.37008, F1=0.38378

[18.43.15]	lable [3]: tp=2762, fp=3994, fn=4696, tn=40766, total=52218
P=0.40882, R=0.37034, F1=0.38863

[18.43.15]	lable [2]: tp=5390, fp=8954, fn=3611, tn=34263, total=52218
P=0.37577, R=0.59882, F1=0.46177

[18.43.15]	lable [5]: tp=3034, fp=5866, fn=4577, tn=38741, total=52218
P=0.34090, R=0.39863, F1=0.36751

[18.43.15]	lable [4]: tp=1899, fp=2239, fn=4390, tn=43690, total=52218
P=0.45892, R=0.30196, F1=0.36425

[18.43.15]	lable [6]: tp=2392, fp=3140, fn=4354, tn=42332, total=52218
P=0.43239, R=0.35458, F1=0.38964

[18.43.15]	Average F1 = 0.38769
Accuracy = 20636/52218 = 0.395189
[18.43.15]	Got evaluation for current fold, Avg. F1 = 0.38769
[18.43.15]	Evaluation Done! Final after 4-fold Avg. F1 = 0.39074
[18.43.15]	

Perfmon Summary:
Time Used(s): 159.701654
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	209462
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	701
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	64
ru_oublock ->	30728
ru_stime ->	0.448028
ru_utime ->	667.233699

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	260717
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	872
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	80
ru_oublock ->	37760
ru_stime ->	0.580036
ru_utime ->	825.435586

=========== ======== ============
		
[18.43.15]	Start LibSVM evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP
[18.43.15]	Fold 0 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[18.43.15]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model
[18.43.42]	Fold 0 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[18.43.42]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[18.43.42]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[18.43.42]	lable [1]: tp=2178, fp=3204, fn=4538, tn=41028, total=50948
P=0.40468, R=0.32430, F1=0.36006

[18.43.42]	lable [0]: tp=3052, fp=3844, fn=5025, tn=39027, total=50948
P=0.44258, R=0.37786, F1=0.40767

[18.43.42]	lable [3]: tp=2460, fp=2810, fn=4831, tn=40847, total=50948
P=0.46679, R=0.33740, F1=0.39169

[18.43.42]	lable [2]: tp=5380, fp=8737, fn=3361, tn=33470, total=50948
P=0.38110, R=0.61549, F1=0.47073

[18.43.42]	lable [5]: tp=3145, fp=6045, fn=4227, tn=37531, total=50948
P=0.34222, R=0.42661, F1=0.37979

[18.43.42]	lable [4]: tp=1806, fp=2202, fn=4365, tn=42575, total=50948
P=0.45060, R=0.29266, F1=0.35485

[18.43.42]	lable [6]: tp=2643, fp=3442, fn=3937, tn=40926, total=50948
P=0.43435, R=0.40167, F1=0.41737

[18.43.42]	Average F1 = 0.39745
Accuracy = 20664/50948 = 0.405590
[18.43.42]	Got evaluation for current fold, Avg. F1 = 0.39745
[18.43.42]	Fold 1 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[18.43.42]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model
[18.44.08]	Fold 1 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[18.44.08]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[18.44.08]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[18.44.09]	lable [1]: tp=2327, fp=3049, fn=4389, tn=41183, total=50948
P=0.43285, R=0.34649, F1=0.38488

[18.44.09]	lable [0]: tp=2985, fp=4459, fn=5092, tn=38412, total=50948
P=0.40099, R=0.36957, F1=0.38464

[18.44.09]	lable [3]: tp=2474, fp=3247, fn=4817, tn=40410, total=50948
P=0.43244, R=0.33932, F1=0.38026

[18.44.09]	lable [2]: tp=5225, fp=8153, fn=3516, tn=34054, total=50948
P=0.39057, R=0.59776, F1=0.47244

[18.44.09]	lable [5]: tp=3062, fp=4981, fn=4310, tn=38595, total=50948
P=0.38070, R=0.41536, F1=0.39728

[18.44.09]	lable [4]: tp=1923, fp=2800, fn=4248, tn=41977, total=50948
P=0.40716, R=0.31162, F1=0.35304

[18.44.09]	lable [6]: tp=2698, fp=3565, fn=3882, tn=40803, total=50948
P=0.43078, R=0.41003, F1=0.42015

[18.44.09]	Average F1 = 0.39896
Accuracy = 20694/50948 = 0.406179
[18.44.09]	Got evaluation for current fold, Avg. F1 = 0.39896
[18.44.09]	Fold 2 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[18.44.09]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model
[18.44.36]	Fold 2 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[18.44.36]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[18.44.36]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[18.44.36]	lable [1]: tp=2351, fp=3416, fn=4365, tn=40816, total=50948
P=0.40766, R=0.35006, F1=0.37667

[18.44.36]	lable [0]: tp=2872, fp=3927, fn=5205, tn=38944, total=50948
P=0.42242, R=0.35558, F1=0.38613

[18.44.36]	lable [3]: tp=2654, fp=3458, fn=4637, tn=40199, total=50948
P=0.43423, R=0.36401, F1=0.39603

[18.44.36]	lable [2]: tp=4987, fp=8204, fn=3754, tn=34003, total=50948
P=0.37806, R=0.57053, F1=0.45477

[18.44.36]	lable [5]: tp=3169, fp=5713, fn=4203, tn=37863, total=50948
P=0.35679, R=0.42987, F1=0.38993

[18.44.36]	lable [4]: tp=1787, fp=2321, fn=4384, tn=42456, total=50948
P=0.43500, R=0.28958, F1=0.34770

[18.44.36]	lable [6]: tp=2504, fp=3585, fn=4076, tn=40783, total=50948
P=0.41123, R=0.38055, F1=0.39530

[18.44.36]	Average F1 = 0.39236
Accuracy = 20324/50948 = 0.398917
[18.44.36]	Got evaluation for current fold, Avg. F1 = 0.39236
[18.44.36]	Fold 3 Training: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[18.44.36]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model
[18.45.02]	Fold 3 Predicting: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[18.45.02]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[18.45.02]	Evaluate on libsvm result:
Gold: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[18.45.03]	lable [1]: tp=2122, fp=2662, fn=4596, tn=41581, total=50961
P=0.44356, R=0.31587, F1=0.36898

[18.45.03]	lable [0]: tp=3053, fp=4504, fn=5025, tn=38379, total=50961
P=0.40400, R=0.37794, F1=0.39053

[18.45.03]	lable [3]: tp=2552, fp=3520, fn=4742, tn=40147, total=50961
P=0.42029, R=0.34988, F1=0.38186

[18.45.03]	lable [2]: tp=5083, fp=7872, fn=3660, tn=34346, total=50961
P=0.39236, R=0.58138, F1=0.46852

[18.45.03]	lable [5]: tp=3015, fp=5709, fn=4359, tn=37878, total=50961
P=0.34560, R=0.40887, F1=0.37458

[18.45.03]	lable [4]: tp=1936, fp=2708, fn=4237, tn=42080, total=50961
P=0.41688, R=0.31362, F1=0.35796

[18.45.03]	lable [6]: tp=2578, fp=3647, fn=4003, tn=40733, total=50961
P=0.41414, R=0.39173, F1=0.40262

[18.45.03]	Average F1 = 0.39215
Accuracy = 20339/50961 = 0.399109
[18.45.03]	Got evaluation for current fold, Avg. F1 = 0.39215
[18.45.03]	Evaluation Done! Final after 4-fold Avg. F1 = 0.39523
[18.45.03]	

Perfmon Summary:
Time Used(s): 107.172679
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	260717
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	872
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	80
ru_oublock ->	37760
ru_stime ->	0.580036
ru_utime ->	825.435586

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	31000
ru_minflt ->	304432
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	983
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	96
ru_oublock ->	45272
ru_stime ->	0.672042
ru_utime ->	931.342205

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130305194332
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[19.43.32]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM
[19.43.32]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM.wekaEval_130305194332.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.arff
[19.52.41]	Correctly Classified Instances       82931               39.6978 %
Incorrectly Classified Instances    125975               60.3022 %



======================================================
*********************************************************
Start logging 20130305202553
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[20.25.53]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[20.25.53]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130305202553.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[20.31.29]	Correctly Classified Instances      142183               59.2057 %
Incorrectly Classified Instances     97968               40.7943 %



======================================================
*********************************************************
Start logging 20130305215214
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[21.52.14]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[21.52.14]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[21.52.14]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model
[21.52.35]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[21.52.35]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[21.52.35]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[21.52.36]	lable [1]: tp=15691, fp=10159, fn=6524, tn=27662, total=60036
P=0.60700, R=0.70632, F1=0.65291

[21.52.36]	lable [0]: tp=10170, fp=5179, fn=9519, tn=35168, total=60036
P=0.66258, R=0.51653, F1=0.58051

[21.52.36]	lable [2]: tp=11062, fp=7775, fn=7070, tn=34129, total=60036
P=0.58725, R=0.61008, F1=0.59845

[21.52.36]	Average F1 = 0.61062
Accuracy = 36923/60036 = 0.615014
[21.52.36]	Got evaluation for current fold, Avg. F1 = 0.61062
[21.52.36]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[21.52.36]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model


======================================================
*********************************************************
Start logging 20130305215505
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[21.55.06]	M5_L_STM: Start constructing Bog
[21.55.06]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130305215514
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[21.55.14]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[21.55.14]	nFold Splitting! Original data set size: 240151
New nFold result size:
	Fold 0 -> 60037
	Fold 1 -> 60037
	Fold 2 -> 60037
	Fold 3 -> 60040
Total = 240151

[21.55.14]	Fold 0 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[21.55.14]	Fold 0 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[21.55.14]	Fold 1 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[21.55.14]	Fold 1 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[21.55.14]	Fold 2 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[21.55.15]	Fold 2 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[21.55.15]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[21.55.15]	Fold 3 train, 180111 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm


======================================================
*********************************************************
Start logging 20130305215529
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[21.55.30]	M5_L_STM: Start constructing Bog
[21.55.30]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[21.55.51]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[21.55.51]	[BogBuilder] First pass vocab scan, #vocab = 28747
[21.55.51]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6130
[21.56.16]	Done! Number of instance wrote: 240151
[21.56.16]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.libsvm
[21.56.26]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.libsvm

[21.56.26]	M10_L_STM: Start constructing Bog
[21.56.26]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff
[21.56.48]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:10 -alphanumonly:False
[21.56.48]	[BogBuilder] First pass vocab scan, #vocab = 28747
[21.56.48]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 3784
[21.57.13]	Done! Number of instance wrote: 240138
[21.57.13]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.libsvm
[21.57.20]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.libsvm

[21.57.20]	M5_STM: Start constructing Bog
[21.57.20]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff
[21.57.41]	BOG setting: BogBuilder -stmmer:True -lower:False -minFreq:5 -alphanumonly:False
[21.57.41]	[BogBuilder] First pass vocab scan, #vocab = 33610
[21.57.41]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6962
[21.58.06]	Done! Number of instance wrote: 240142
[21.58.06]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.libsvm
[21.58.17]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_STM.libsvm

[21.58.17]	M5_L: Start constructing Bog
[21.58.17]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff
[21.58.24]	BOG setting: BogBuilder -stmmer:False -lower:True -minFreq:5 -alphanumonly:False
[21.58.24]	[BogBuilder] First pass vocab scan, #vocab = 33167
[21.58.24]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6885
[21.58.33]	Done! Number of instance wrote: 240149
[21.58.33]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L.libsvm
[21.58.45]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L.libsvm

[21.58.45]	M5_L_STM_ALPHANUM: Start constructing Bog
[21.58.45]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff
[21.59.07]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:True
[21.59.07]	[BogBuilder] First pass vocab scan, #vocab = 23071
[21.59.07]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 5360
[21.59.31]	Done! Number of instance wrote: 240083
[21.59.31]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.libsvm
[21.59.41]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.libsvm

[21.59.41]	M5_L_STM_RMSTP: Start constructing Bog
[21.59.41]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff
[21.59.58]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[21.59.58]	[BogBuilder] First pass vocab scan, #vocab = 28565
[21.59.58]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 5889
[22.00.17]	Done! Number of instance wrote: 234202
[22.00.17]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.libsvm
[22.00.26]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.libsvm



======================================================
*********************************************************
Start logging 20130305220054
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[22.00.55]	M5_L_STM: Start constructing Bog
[22.00.55]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130305220107
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[22.01.07]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[22.01.07]	nFold Splitting! Original data set size: 240151
New nFold result size:
	Fold 0 -> 60037
	Fold 1 -> 60037
	Fold 2 -> 60037
	Fold 3 -> 60040
Total = 240151

[22.01.07]	Fold 0 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[22.01.07]	Fold 0 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[22.01.07]	Fold 1 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[22.01.08]	Fold 1 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[22.01.08]	Fold 2 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[22.01.08]	Fold 2 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[22.01.08]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[22.01.08]	Fold 3 train, 180111 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm


======================================================
*********************************************************
Start logging 20130305220522
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[22.05.23]	M5_L_STM: Start constructing Bog
[22.05.23]	BogBuilder.GetBog(
/home/xj229/data/3nat_lvl123_15K.sen ->
 /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[22.05.45]	BOG setting: BogBuilder -stmmer:True -lower:True -minFreq:5 -alphanumonly:False
[22.05.45]	[BogBuilder] First pass vocab scan, #vocab = 28747
[22.05.45]	[BogBuilder] Applied minimum frequency cut-off (#attr) #vocab = 6130
[22.06.10]	Done! Number of instance wrote: 240151
[22.06.10]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff -o /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.libsvm
[22.06.20]	Finished, output to:
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.libsvm



======================================================
*********************************************************
Start logging 20130305220730
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[22.07.30]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[22.07.31]	nFold Splitting! Original data set size: 240151
New nFold result size:
	Fold 0 -> 60037
	Fold 1 -> 60037
	Fold 2 -> 60037
	Fold 3 -> 60040
Total = 240151

[22.07.31]	Fold 0 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[22.07.31]	Fold 0 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[22.07.31]	Fold 1 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[22.07.31]	Fold 1 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[22.07.31]	Fold 2 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[22.07.31]	Fold 2 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[22.07.31]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[22.07.32]	Fold 3 train, 180111 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm


======================================================
*********************************************************
Start logging 20130305221340
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[22.13.40]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[22.13.41]	nFold Splitting! Original data set size: 240151
New nFold result size:
	Fold 0 -> 60037
	Fold 1 -> 60037
	Fold 2 -> 60037
	Fold 3 -> 60040
Total = 240151

[22.13.41]	Fold 0 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[22.13.41]	Fold 0 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
[22.13.41]	Fold 1 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[22.13.41]	Fold 1 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
[22.13.41]	Fold 2 test, 60037 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[22.13.41]	Fold 2 train, 180114 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
[22.13.41]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[22.13.41]	Fold 3 train, 180111 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
[22.13.41]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[22.13.41]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model
[22.14.03]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm
[22.14.03]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[22.14.03]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold0_tst.libsvm.predict
[22.14.03]	lable [1]: tp=15552, fp=10230, fn=6663, tn=27592, total=60037
P=0.60321, R=0.70007, F1=0.64804

[22.14.03]	lable [0]: tp=9995, fp=5134, fn=9694, tn=35214, total=60037
P=0.66065, R=0.50764, F1=0.57413

[22.14.03]	lable [2]: tp=11050, fp=8076, fn=7083, tn=33828, total=60037
P=0.57775, R=0.60939, F1=0.59315

[22.14.03]	Average F1 = 0.60510
Accuracy = 36597/60037 = 0.609574
[22.14.03]	Got evaluation for current fold, Avg. F1 = 0.60510
[22.14.03]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[22.14.03]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model
[22.14.25]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm
[22.14.25]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[22.14.25]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold1_tst.libsvm.predict
[22.14.25]	lable [1]: tp=15816, fp=10521, fn=6399, tn=27301, total=60037
P=0.60052, R=0.71195, F1=0.65151

[22.14.25]	lable [0]: tp=9884, fp=5610, fn=9805, tn=34738, total=60037
P=0.63792, R=0.50201, F1=0.56186

[22.14.25]	lable [2]: tp=10946, fp=7260, fn=7187, tn=34644, total=60037
P=0.60123, R=0.60365, F1=0.60244

[22.14.25]	Average F1 = 0.60527
Accuracy = 36646/60037 = 0.610390
[22.14.25]	Got evaluation for current fold, Avg. F1 = 0.60527
[22.14.25]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm
[22.14.25]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm.model
[22.14.48]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm
[22.14.48]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[22.14.48]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold2_tst.libsvm.predict
[22.14.48]	lable [1]: tp=15882, fp=10318, fn=6333, tn=27504, total=60037
P=0.60618, R=0.71492, F1=0.65608

[22.14.48]	lable [0]: tp=10203, fp=5522, fn=9486, tn=34826, total=60037
P=0.64884, R=0.51821, F1=0.57621

[22.14.48]	lable [2]: tp=10823, fp=7289, fn=7310, tn=34615, total=60037
P=0.59756, R=0.59687, F1=0.59721

[22.14.48]	Average F1 = 0.60983
Accuracy = 36908/60037 = 0.614754
[22.14.48]	Got evaluation for current fold, Avg. F1 = 0.60983
[22.14.48]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm
[22.14.48]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm.model
[22.15.09]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm
[22.15.09]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[22.15.09]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_CV4/fold3_tst.libsvm.predict
[22.15.10]	lable [1]: tp=15997, fp=10716, fn=6219, tn=27108, total=60040
P=0.59885, R=0.72007, F1=0.65389

[22.15.10]	lable [0]: tp=10084, fp=5512, fn=9607, tn=34837, total=60040
P=0.64658, R=0.51211, F1=0.57154

[22.15.10]	lable [2]: tp=10540, fp=7191, fn=7593, tn=34716, total=60040
P=0.59444, R=0.58126, F1=0.58778

[22.15.10]	Average F1 = 0.60440
Accuracy = 36621/60040 = 0.609943
[22.15.10]	Got evaluation for current fold, Avg. F1 = 0.60440
[22.15.10]	Evaluation Done! Final after 4-fold Avg. F1 = 0.60615
[22.15.10]	

Perfmon Summary:
Time Used(s): 89.330285
Memory Used (Mb): 45.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	43886
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	90
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	16
ru_oublock ->	3808
ru_stime ->	0.088005
ru_utime ->	87.301456

=========== ======== ============
		
[22.15.10]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM
[22.15.10]	nFold Splitting! Original data set size: 240138
New nFold result size:
	Fold 0 -> 60033
	Fold 1 -> 60033
	Fold 2 -> 60033
	Fold 3 -> 60039
Total = 240138

[22.15.10]	Fold 0 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
[22.15.10]	Fold 0 train, 180105 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
[22.15.10]	Fold 1 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
[22.15.10]	Fold 1 train, 180105 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
[22.15.10]	Fold 2 test, 60033 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
[22.15.11]	Fold 2 train, 180105 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
[22.15.11]	Fold 3 test, 60039 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
[22.15.11]	Fold 3 train, 180099 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
[22.15.11]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm
[22.15.11]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm.model
[22.15.32]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm
[22.15.32]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[22.15.33]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold0_tst.libsvm.predict
[22.15.33]	lable [1]: tp=15432, fp=10616, fn=6782, tn=27203, total=60033
P=0.59244, R=0.69470, F1=0.63951

[22.15.33]	lable [0]: tp=9811, fp=5176, fn=9877, tn=35169, total=60033
P=0.65463, R=0.49832, F1=0.56588

[22.15.33]	lable [2]: tp=10767, fp=8231, fn=7364, tn=33671, total=60033
P=0.56674, R=0.59384, F1=0.57998

[22.15.33]	Average F1 = 0.59512
Accuracy = 36010/60033 = 0.599837
[22.15.33]	Got evaluation for current fold, Avg. F1 = 0.59512
[22.15.33]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm
[22.15.33]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm.model
[22.15.56]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm
[22.15.56]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[22.15.56]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold1_tst.libsvm.predict
[22.15.56]	lable [1]: tp=15728, fp=11013, fn=6486, tn=26806, total=60033
P=0.58816, R=0.70802, F1=0.64255

[22.15.56]	lable [0]: tp=9642, fp=5658, fn=10046, tn=34687, total=60033
P=0.63020, R=0.48974, F1=0.55116

[22.15.56]	lable [2]: tp=10596, fp=7396, fn=7535, tn=34506, total=60033
P=0.58893, R=0.58441, F1=0.58666

[22.15.56]	Average F1 = 0.59346
Accuracy = 35966/60033 = 0.599104
[22.15.56]	Got evaluation for current fold, Avg. F1 = 0.59346
[22.15.56]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm
[22.15.56]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm.model
[22.16.17]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm
[22.16.17]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[22.16.18]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold2_tst.libsvm.predict
[22.16.18]	lable [1]: tp=15793, fp=10819, fn=6421, tn=27000, total=60033
P=0.59345, R=0.71095, F1=0.64691

[22.16.18]	lable [0]: tp=9950, fp=5604, fn=9738, tn=34741, total=60033
P=0.63971, R=0.50538, F1=0.56467

[22.16.18]	lable [2]: tp=10466, fp=7401, fn=7665, tn=34501, total=60033
P=0.58577, R=0.57724, F1=0.58148

[22.16.18]	Average F1 = 0.59768
Accuracy = 36209/60033 = 0.603152
[22.16.18]	Got evaluation for current fold, Avg. F1 = 0.59768
[22.16.18]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm
[22.16.18]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm.model
[22.16.39]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm
[22.16.39]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[22.16.39]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM_CV4/fold3_tst.libsvm.predict
[22.16.39]	lable [1]: tp=16001, fp=11189, fn=6216, tn=26633, total=60039
P=0.58849, R=0.72021, F1=0.64772

[22.16.39]	lable [0]: tp=9822, fp=5500, fn=9867, tn=34850, total=60039
P=0.64104, R=0.49886, F1=0.56108

[22.16.39]	lable [2]: tp=10264, fp=7263, fn=7869, tn=34643, total=60039
P=0.58561, R=0.56604, F1=0.57566

[22.16.39]	Average F1 = 0.59482
Accuracy = 36087/60039 = 0.601059
[22.16.39]	Got evaluation for current fold, Avg. F1 = 0.59482
[22.16.39]	Evaluation Done! Final after 4-fold Avg. F1 = 0.59527
[22.16.39]	

Perfmon Summary:
Time Used(s): 89.231534
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	43886
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	90
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	16
ru_oublock ->	3808
ru_stime ->	0.088005
ru_utime ->	87.301456

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	87482
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	178
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	32
ru_oublock ->	6568
ru_stime ->	0.16401
ru_utime ->	174.494905

=========== ======== ============
		
[22.16.39]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM
[22.16.39]	nFold Splitting! Original data set size: 240142
New nFold result size:
	Fold 0 -> 60034
	Fold 1 -> 60034
	Fold 2 -> 60034
	Fold 3 -> 60040
Total = 240142

[22.16.39]	Fold 0 test, 60034 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
[22.16.39]	Fold 0 train, 180108 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
[22.16.39]	Fold 1 test, 60034 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
[22.16.40]	Fold 1 train, 180108 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
[22.16.40]	Fold 2 test, 60034 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
[22.16.40]	Fold 2 train, 180108 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
[22.16.40]	Fold 3 test, 60040 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
[22.16.40]	Fold 3 train, 180102 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
[22.16.40]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm
[22.16.40]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm.model
[22.17.01]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm
[22.17.01]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[22.17.01]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold0_tst.libsvm.predict
[22.17.01]	lable [1]: tp=15502, fp=9883, fn=6711, tn=27938, total=60034
P=0.61068, R=0.69788, F1=0.65137

[22.17.01]	lable [0]: tp=10621, fp=5597, fn=9068, tn=34748, total=60034
P=0.65489, R=0.53944, F1=0.59158

[22.17.01]	lable [2]: tp=10907, fp=7524, fn=7225, tn=34378, total=60034
P=0.59177, R=0.60153, F1=0.59661

[22.17.01]	Average F1 = 0.61319
Accuracy = 37030/60034 = 0.616817
[22.17.01]	Got evaluation for current fold, Avg. F1 = 0.61319
[22.17.01]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm
[22.17.01]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm.model
[22.17.22]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm
[22.17.22]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[22.17.23]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold1_tst.libsvm.predict
[22.17.23]	lable [1]: tp=15838, fp=10416, fn=6375, tn=27405, total=60034
P=0.60326, R=0.71301, F1=0.65356

[22.17.23]	lable [0]: tp=10340, fp=6014, fn=9349, tn=34331, total=60034
P=0.63226, R=0.52517, F1=0.57376

[22.17.23]	lable [2]: tp=10714, fp=6712, fn=7418, tn=35190, total=60034
P=0.61483, R=0.59089, F1=0.60262

[22.17.23]	Average F1 = 0.60998
Accuracy = 36892/60034 = 0.614518
[22.17.23]	Got evaluation for current fold, Avg. F1 = 0.60998
[22.17.23]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm
[22.17.23]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm.model
[22.17.44]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm
[22.17.44]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[22.17.44]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold2_tst.libsvm.predict
[22.17.44]	lable [1]: tp=15778, fp=10027, fn=6435, tn=27794, total=60034
P=0.61143, R=0.71030, F1=0.65717

[22.17.44]	lable [0]: tp=10725, fp=6010, fn=8964, tn=34335, total=60034
P=0.64087, R=0.54472, F1=0.58890

[22.17.44]	lable [2]: tp=10686, fp=6808, fn=7446, tn=35094, total=60034
P=0.61084, R=0.58934, F1=0.59990

[22.17.44]	Average F1 = 0.61532
Accuracy = 37189/60034 = 0.619466
[22.17.44]	Got evaluation for current fold, Avg. F1 = 0.61532
[22.17.44]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm
[22.17.44]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm.model
[22.18.05]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm
[22.18.05]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[22.18.05]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_STM_CV4/fold3_tst.libsvm.predict
[22.18.05]	lable [1]: tp=15817, fp=10098, fn=6399, tn=27726, total=60040
P=0.61034, R=0.71196, F1=0.65725

[22.18.05]	lable [0]: tp=10696, fp=6085, fn=8995, tn=34264, total=60040
P=0.63739, R=0.54319, F1=0.58653

[22.18.05]	lable [2]: tp=10498, fp=6846, fn=7635, tn=35061, total=60040
P=0.60528, R=0.57894, F1=0.59182

[22.18.05]	Average F1 = 0.61187
Accuracy = 37011/60040 = 0.616439
[22.18.05]	Got evaluation for current fold, Avg. F1 = 0.61187
[22.18.05]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61259
[22.18.05]	

Perfmon Summary:
Time Used(s): 86.095253
Memory Used (Mb): 4.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	46392
ru_minflt ->	87482
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	178
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	32
ru_oublock ->	6568
ru_stime ->	0.16401
ru_utime ->	174.494905

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	131471
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	262
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	48
ru_oublock ->	10760
ru_stime ->	0.248015
ru_utime ->	258.524156

=========== ======== ============
		
[22.18.05]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L
[22.18.05]	nFold Splitting! Original data set size: 240149
New nFold result size:
	Fold 0 -> 60036
	Fold 1 -> 60036
	Fold 2 -> 60036
	Fold 3 -> 60041
Total = 240149

[22.18.05]	Fold 0 test, 60036 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
[22.18.05]	Fold 0 train, 180113 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
[22.18.06]	Fold 1 test, 60036 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
[22.18.06]	Fold 1 train, 180113 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
[22.18.06]	Fold 2 test, 60036 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
[22.18.06]	Fold 2 train, 180113 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
[22.18.06]	Fold 3 test, 60041 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
[22.18.06]	Fold 3 train, 180108 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
[22.18.06]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm
[22.18.06]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm.model
[22.18.28]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm
[22.18.28]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm.predict
[22.18.28]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold0_tst.libsvm.predict
[22.18.28]	lable [1]: tp=15691, fp=10159, fn=6524, tn=27662, total=60036
P=0.60700, R=0.70632, F1=0.65291

[22.18.28]	lable [0]: tp=10170, fp=5179, fn=9519, tn=35168, total=60036
P=0.66258, R=0.51653, F1=0.58051

[22.18.28]	lable [2]: tp=11062, fp=7775, fn=7070, tn=34129, total=60036
P=0.58725, R=0.61008, F1=0.59845

[22.18.28]	Average F1 = 0.61062
Accuracy = 36923/60036 = 0.615014
[22.18.28]	Got evaluation for current fold, Avg. F1 = 0.61062
[22.18.28]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm
[22.18.28]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm.model
[22.18.50]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm
[22.18.50]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm.predict
[22.18.50]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold1_tst.libsvm.predict
[22.18.50]	lable [1]: tp=16009, fp=10648, fn=6206, tn=27173, total=60036
P=0.60056, R=0.72064, F1=0.65514

[22.18.50]	lable [0]: tp=9901, fp=5480, fn=9788, tn=34867, total=60036
P=0.64372, R=0.50287, F1=0.56464

[22.18.50]	lable [2]: tp=10959, fp=7039, fn=7173, tn=34865, total=60036
P=0.60890, R=0.60440, F1=0.60664

[22.18.50]	Average F1 = 0.60881
Accuracy = 36869/60036 = 0.614115
[22.18.50]	Got evaluation for current fold, Avg. F1 = 0.60881
[22.18.50]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm
[22.18.50]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm.model
[22.19.12]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm
[22.19.12]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm.predict
[22.19.12]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold2_tst.libsvm.predict
[22.19.12]	lable [1]: tp=16008, fp=10260, fn=6207, tn=27561, total=60036
P=0.60941, R=0.72059, F1=0.66036

[22.19.12]	lable [0]: tp=10211, fp=5446, fn=9478, tn=34901, total=60036
P=0.65217, R=0.51861, F1=0.57777

[22.19.12]	lable [2]: tp=10883, fp=7228, fn=7249, tn=34676, total=60036
P=0.60091, R=0.60021, F1=0.60056

[22.19.12]	Average F1 = 0.61290
Accuracy = 37102/60036 = 0.617996
[22.19.12]	Got evaluation for current fold, Avg. F1 = 0.61290
[22.19.12]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm
[22.19.12]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm.model
[22.19.34]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm
[22.19.34]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm.predict
[22.19.34]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_CV4/fold3_tst.libsvm.predict
[22.19.34]	lable [1]: tp=16096, fp=10679, fn=6120, tn=27146, total=60041
P=0.60116, R=0.72452, F1=0.65710

[22.19.34]	lable [0]: tp=10174, fp=5439, fn=9517, tn=34911, total=60041
P=0.65164, R=0.51668, F1=0.57637

[22.19.34]	lable [2]: tp=10597, fp=7056, fn=7537, tn=34851, total=60041
P=0.60029, R=0.58437, F1=0.59223

[22.19.34]	Average F1 = 0.60856
Accuracy = 36867/60041 = 0.614030
[22.19.34]	Got evaluation for current fold, Avg. F1 = 0.60856
[22.19.34]	Evaluation Done! Final after 4-fold Avg. F1 = 0.61022
[22.19.34]	

Perfmon Summary:
Time Used(s): 88.931242
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	131471
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	262
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	48
ru_oublock ->	10760
ru_stime ->	0.248015
ru_utime ->	258.524156

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	175341
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	351
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	64
ru_oublock ->	14904
ru_stime ->	0.356022
ru_utime ->	345.353583

=========== ======== ============
		
[22.19.34]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM
[22.19.34]	nFold Splitting! Original data set size: 240083
New nFold result size:
	Fold 0 -> 60019
	Fold 1 -> 60019
	Fold 2 -> 60019
	Fold 3 -> 60026
Total = 240083

[22.19.34]	Fold 0 test, 60019 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
[22.19.34]	Fold 0 train, 180064 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
[22.19.34]	Fold 1 test, 60019 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
[22.19.35]	Fold 1 train, 180064 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
[22.19.35]	Fold 2 test, 60019 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
[22.19.35]	Fold 2 train, 180064 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
[22.19.35]	Fold 3 test, 60026 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
[22.19.35]	Fold 3 train, 180057 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
[22.19.35]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[22.19.35]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model
[22.19.55]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm
[22.19.55]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[22.19.55]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold0_tst.libsvm.predict
[22.19.55]	lable [1]: tp=15438, fp=10664, fn=6770, tn=27147, total=60019
P=0.59145, R=0.69515, F1=0.63912

[22.19.55]	lable [0]: tp=9709, fp=5008, fn=9976, tn=35326, total=60019
P=0.65971, R=0.49322, F1=0.56444

[22.19.55]	lable [2]: tp=10863, fp=8337, fn=7263, tn=33556, total=60019
P=0.56578, R=0.59930, F1=0.58206

[22.19.55]	Average F1 = 0.59521
Accuracy = 36010/60019 = 0.599977
[22.19.55]	Got evaluation for current fold, Avg. F1 = 0.59521
[22.19.55]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[22.19.55]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model
[22.20.17]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm
[22.20.17]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[22.20.17]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold1_tst.libsvm.predict
[22.20.17]	lable [1]: tp=15564, fp=10771, fn=6644, tn=27040, total=60019
P=0.59100, R=0.70083, F1=0.64125

[22.20.17]	lable [0]: tp=9635, fp=5784, fn=10050, tn=34550, total=60019
P=0.62488, R=0.48946, F1=0.54894

[22.20.17]	lable [2]: tp=10742, fp=7523, fn=7384, tn=34370, total=60019
P=0.58812, R=0.59263, F1=0.59037

[22.20.17]	Average F1 = 0.59352
Accuracy = 35941/60019 = 0.598827
[22.20.17]	Got evaluation for current fold, Avg. F1 = 0.59352
[22.20.17]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[22.20.17]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model
[22.20.39]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm
[22.20.39]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[22.20.39]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold2_tst.libsvm.predict
[22.20.39]	lable [1]: tp=15672, fp=10520, fn=6536, tn=27291, total=60019
P=0.59835, R=0.70569, F1=0.64760

[22.20.39]	lable [0]: tp=9962, fp=5639, fn=9723, tn=34695, total=60019
P=0.63855, R=0.50607, F1=0.56464

[22.20.39]	lable [2]: tp=10681, fp=7545, fn=7445, tn=34348, total=60019
P=0.58603, R=0.58926, F1=0.58764

[22.20.39]	Average F1 = 0.59996
Accuracy = 36315/60019 = 0.605058
[22.20.39]	Got evaluation for current fold, Avg. F1 = 0.59996
[22.20.39]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[22.20.39]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model
[22.21.00]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm
[22.21.00]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[22.21.00]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM_CV4/fold3_tst.libsvm.predict
[22.21.00]	lable [1]: tp=15760, fp=10929, fn=6449, tn=26888, total=60026
P=0.59051, R=0.70962, F1=0.64461

[22.21.00]	lable [0]: tp=9877, fp=5614, fn=9811, tn=34724, total=60026
P=0.63760, R=0.50168, F1=0.56153

[22.21.00]	lable [2]: tp=10408, fp=7438, fn=7721, tn=34459, total=60026
P=0.58321, R=0.57411, F1=0.57862

[22.21.00]	Average F1 = 0.59492
Accuracy = 36045/60026 = 0.600490
[22.21.00]	Got evaluation for current fold, Avg. F1 = 0.59492
[22.21.00]	Evaluation Done! Final after 4-fold Avg. F1 = 0.59590
[22.21.00]	

Perfmon Summary:
Time Used(s): 86.227544
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	175341
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	351
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	64
ru_oublock ->	14904
ru_stime ->	0.356022
ru_utime ->	345.353583

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	217994
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	436
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	80
ru_oublock ->	18360
ru_stime ->	0.468029
ru_utime ->	429.494841

=========== ======== ============
		
[22.21.00]	Start LibSVM evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP
[22.21.00]	nFold Splitting! Original data set size: 234202
New nFold result size:
	Fold 0 -> 58550
	Fold 1 -> 58550
	Fold 2 -> 58550
	Fold 3 -> 58552
Total = 234202

[22.21.00]	Fold 0 test, 58550 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
[22.21.01]	Fold 0 train, 175652 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
[22.21.01]	Fold 1 test, 58550 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
[22.21.01]	Fold 1 train, 175652 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
[22.21.01]	Fold 2 test, 58550 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
[22.21.01]	Fold 2 train, 175652 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
[22.21.01]	Fold 3 test, 58552 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
[22.21.01]	Fold 3 train, 175650 data, output to /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
[22.21.01]	Fold 0 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[22.21.01]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model
[22.21.16]	Fold 0 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm
[22.21.16]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[22.21.16]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold0_tst.libsvm.predict
[22.21.16]	lable [1]: tp=14934, fp=9832, fn=6713, tn=27071, total=58550
P=0.60300, R=0.68989, F1=0.64353

[22.21.16]	lable [0]: tp=9651, fp=4945, fn=9654, tn=34300, total=58550
P=0.66121, R=0.49992, F1=0.56936

[22.21.16]	lable [2]: tp=10797, fp=8391, fn=6801, tn=32561, total=58550
P=0.56270, R=0.61354, F1=0.58702

[22.21.16]	Average F1 = 0.59997
Accuracy = 35382/58550 = 0.604304
[22.21.16]	Got evaluation for current fold, Avg. F1 = 0.59997
[22.21.16]	Fold 1 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[22.21.16]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model
[22.21.31]	Fold 1 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm
[22.21.31]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[22.21.31]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold1_tst.libsvm.predict
[22.21.32]	lable [1]: tp=15024, fp=9895, fn=6623, tn=27008, total=58550
P=0.60291, R=0.69405, F1=0.64528

[22.21.32]	lable [0]: tp=9614, fp=5387, fn=9691, tn=33858, total=58550
P=0.64089, R=0.49801, F1=0.56049

[22.21.32]	lable [2]: tp=10829, fp=7801, fn=6769, tn=33151, total=58550
P=0.58127, R=0.61535, F1=0.59782

[22.21.32]	Average F1 = 0.60120
Accuracy = 35467/58550 = 0.605756
[22.21.32]	Got evaluation for current fold, Avg. F1 = 0.60120
[22.21.32]	Fold 2 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[22.21.32]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model
[22.21.46]	Fold 2 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm
[22.21.46]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[22.21.46]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold2_tst.libsvm.predict
[22.21.46]	lable [1]: tp=15104, fp=9754, fn=6543, tn=27149, total=58550
P=0.60761, R=0.69774, F1=0.64956

[22.21.46]	lable [0]: tp=9793, fp=5288, fn=9512, tn=33957, total=58550
P=0.64936, R=0.50728, F1=0.56959

[22.21.46]	lable [2]: tp=10772, fp=7839, fn=6826, tn=33113, total=58550
P=0.57880, R=0.61212, F1=0.59499

[22.21.46]	Average F1 = 0.60472
Accuracy = 35669/58550 = 0.609206
[22.21.46]	Got evaluation for current fold, Avg. F1 = 0.60472
[22.21.46]	Fold 3 Training: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[22.21.46]	/home/xj229/tools/liblinear-1.93/train /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model
[22.22.01]	Fold 3 Predicting: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm
[22.22.01]	/home/xj229/tools/liblinear-1.93/predict /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_trn.libsvm.model /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[22.22.01]	Evaluate on libsvm result:
Gold: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm
Sys:/home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP_CV4/fold3_tst.libsvm.predict
[22.22.01]	lable [1]: tp=14998, fp=9740, fn=6649, tn=27165, total=58552
P=0.60627, R=0.69284, F1=0.64667

[22.22.01]	lable [0]: tp=9893, fp=5471, fn=9414, tn=33774, total=58552
P=0.64391, R=0.51240, F1=0.57068

[22.22.01]	lable [2]: tp=10554, fp=7896, fn=7044, tn=33058, total=58552
P=0.57203, R=0.59973, F1=0.58555

[22.22.01]	Average F1 = 0.60097
Accuracy = 35445/58552 = 0.605359
[22.22.01]	Got evaluation for current fold, Avg. F1 = 0.60097
[22.22.01]	Evaluation Done! Final after 4-fold Avg. F1 = 0.60171
[22.22.01]	

Perfmon Summary:
Time Used(s): 61.293768
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	217994
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	436
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	80
ru_oublock ->	18360
ru_stime ->	0.468029
ru_utime ->	429.494841

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	50720
ru_minflt ->	252802
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	499
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	96
ru_oublock ->	22016
ru_stime ->	0.544034
ru_utime ->	488.966558

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130306030945
 ../Util/Log.py

[03.09.45]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130305202553.log
[03.09.45]	lable [ru]: tp=38002, fp=21752, fn=40756, tn=139641, total=240151
P=0.63597, R=0.48252, F1=0.54872

[03.09.45]	lable [cn]: tp=60739, fp=42742, fn=28122, tn=108548, total=240151
P=0.58696, R=0.68353, F1=0.63157

[03.09.45]	lable [br]: tp=43442, fp=33474, fn=29090, tn=134145, total=240151
P=0.56480, R=0.59894, F1=0.58137

[03.09.45]	Weka Accuracy = 142183/240151 = 0.59206


======================================================
*********************************************************
Start logging 20130306031145
 ../Util/Log.pyc

[03.11.45]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130305202553.log
[03.11.45]	lable [ru]: tp=38002, fp=21752, fn=40756, tn=139641, total=240151
P=0.63597, R=0.48252, F1=0.54872

[03.11.45]	lable [cn]: tp=60739, fp=42742, fn=28122, tn=108548, total=240151
P=0.58696, R=0.68353, F1=0.63157

[03.11.45]	lable [br]: tp=43442, fp=33474, fn=29090, tn=134145, total=240151
P=0.56480, R=0.59894, F1=0.58137

[03.11.45]	Weka Accuracy = 142183/240151 = 0.59206


======================================================
*********************************************************
Start logging 20130306031200
 ../Util/Log.pyc

[03.12.00]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130305202553.log
[03.12.01]	lable [ru]: tp=38002, fp=21752, fn=40756, tn=139641, total=240151
P=0.63597, R=0.48252, F1=0.54872

[03.12.01]	lable [cn]: tp=60739, fp=42742, fn=28122, tn=108548, total=240151
P=0.58696, R=0.68353, F1=0.63157

[03.12.01]	lable [br]: tp=43442, fp=33474, fn=29090, tn=134145, total=240151
P=0.56480, R=0.59894, F1=0.58137

[03.12.01]	Weka Accuracy = 142183/240151 = 0.59206
[03.12.01]	Final weka Avg. F1 = 0.58722


======================================================
*********************************************************
Start logging 20130306031808
 /home/xj229/workspace/AcsProj/Util/Log.py

[03.18.08]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.18.08]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306031808.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[03.23.44]	Correctly Classified Instances      142183               59.2057 %
Incorrectly Classified Instances     97968               40.7943 %



======================================================
*********************************************************
Start logging 20130306033142
 ../Util/Log.py

[03.31.42]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.31.42]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306033142.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130306033607
 ../Util/Log.pyc

[03.36.07]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.36.07]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306033607.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130306033614
 ../Util/Log.pyc

[03.36.14]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.36.14]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306033614.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[03.41.56]	Correctly Classified Instances      142183               59.2057 %
Incorrectly Classified Instances     97968               40.7943 %



======================================================
*********************************************************
Start logging 20130306034301
 ../Util/Log.pyc

[03.43.01]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM


======================================================
*********************************************************
Start logging 20130306034323
 ../Util/Log.pyc

[03.43.23]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.43.23]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306034323.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130306034338
 ../Util/Log.pyc

[03.43.38]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.43.38]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306034338.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130306034418
 /home/xj229/workspace/AcsProj/Util/Log.py

[03.44.18]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM
[03.44.18]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306034418.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM.arff
[03.50.01]	Correctly Classified Instances      142183               59.2057 %
Incorrectly Classified Instances     97968               40.7943 %

[03.50.01]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM.wekaEval_130306034418.log
[03.50.01]	lable [ru]: tp=38002, fp=21752, fn=40756, tn=139641, total=240151
P=0.63597, R=0.48252, F1=0.54872

[03.50.01]	lable [cn]: tp=60739, fp=42742, fn=28122, tn=108548, total=240151
P=0.58696, R=0.68353, F1=0.63157

[03.50.01]	lable [br]: tp=43442, fp=33474, fn=29090, tn=134145, total=240151
P=0.56480, R=0.59894, F1=0.58137

[03.50.01]	Weka Accuracy = 142183/240151 = 0.59206
[03.50.01]	Final F1 = 0.59
[03.50.01]	

Perfmon Summary:
Time Used(s): 343.147348
Memory Used (Mb): 553.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	1
ru_maxrss ->	566900
ru_minflt ->	149523
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	455
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	7739
ru_oublock ->	1992
ru_stime ->	0.472029
ru_utime ->	344.101505

=========== ======== ============
		
[03.50.01]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM
[03.50.01]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M10_L_STM.wekaEval_130306035001.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M10_L_STM.arff
[03.53.36]	Correctly Classified Instances      139625               58.1437 %
Incorrectly Classified Instances    100513               41.8563 %

[03.53.36]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M10_L_STM.wekaEval_130306035001.log
[03.53.36]	lable [ru]: tp=37273, fp=22780, fn=41480, tn=138605, total=240138
P=0.62067, R=0.47329, F1=0.53705

[03.53.36]	lable [cn]: tp=59421, fp=42893, fn=29438, tn=108386, total=240138
P=0.58077, R=0.66871, F1=0.62165

[03.53.36]	lable [br]: tp=42931, fp=34840, fn=29595, tn=132772, total=240138
P=0.55202, R=0.59194, F1=0.57128

[03.53.36]	Weka Accuracy = 139625/240138 = 0.58144
[03.53.36]	Final F1 = 0.58
[03.53.36]	

Perfmon Summary:
Time Used(s): 215.606804
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	1
ru_maxrss ->	566900
ru_minflt ->	149523
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	455
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	7739
ru_oublock ->	1992
ru_stime ->	0.472029
ru_utime ->	344.101505

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	566900
ru_minflt ->	285910
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	726
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	12792
ru_oublock ->	3264
ru_stime ->	0.97206
ru_utime ->	560.923055

=========== ======== ============
		
[03.53.36]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_STM
[03.53.36]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_STM.wekaEval_130306035336.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_STM.arff
[04.00.06]	Correctly Classified Instances      142827               59.4761 %
Incorrectly Classified Instances     97315               40.5239 %

[04.00.06]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_STM.wekaEval_130306035336.log
[04.00.06]	lable [ru]: tp=38545, fp=21504, fn=40213, tn=139880, total=240142
P=0.64189, R=0.48941, F1=0.55538

[04.00.06]	lable [cn]: tp=61178, fp=43175, fn=27677, tn=108112, total=240142
P=0.58626, R=0.68851, F1=0.63329

[04.00.06]	lable [br]: tp=43104, fp=32636, fn=29425, tn=134977, total=240142
P=0.56910, R=0.59430, F1=0.58143

[04.00.06]	Weka Accuracy = 142827/240142 = 0.59476
[04.00.06]	Final F1 = 0.59
[04.00.06]	

Perfmon Summary:
Time Used(s): 390.045332
Memory Used (Mb): 20.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	566900
ru_minflt ->	285910
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	726
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	12792
ru_oublock ->	3264
ru_stime ->	0.97206
ru_utime ->	560.923055

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	3
ru_maxrss ->	587752
ru_minflt ->	439790
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1157
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	21452
ru_oublock ->	5512
ru_stime ->	1.44409
ru_utime ->	951.411459

=========== ======== ============
		
[04.00.06]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L
[04.00.06]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L.wekaEval_130306040006.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L.arff
[04.06.35]	Correctly Classified Instances      143093               59.5851 %
Incorrectly Classified Instances     97056               40.4149 %

[04.06.35]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L.wekaEval_130306040006.log
[04.06.35]	lable [ru]: tp=38254, fp=21648, fn=40504, tn=139743, total=240149
P=0.63861, R=0.48572, F1=0.55177

[04.06.35]	lable [cn]: tp=60914, fp=41977, fn=27947, tn=109311, total=240149
P=0.59202, R=0.68550, F1=0.63534

[04.06.35]	lable [br]: tp=43925, fp=33431, fn=28605, tn=134188, total=240149
P=0.56783, R=0.60561, F1=0.58611

[04.06.35]	Weka Accuracy = 143093/240149 = 0.59585
[04.06.35]	Final F1 = 0.59
[04.06.35]	

Perfmon Summary:
Time Used(s): 388.607082
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	3
ru_maxrss ->	587752
ru_minflt ->	439790
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1157
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	21452
ru_oublock ->	5512
ru_stime ->	1.44409
ru_utime ->	951.411459

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	4
ru_maxrss ->	587752
ru_minflt ->	592490
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1586
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	30145
ru_oublock ->	7800
ru_stime ->	1.968123
ru_utime ->	1340.799794

=========== ======== ============
		
[04.06.35]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM
[04.06.35]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.wekaEval_130306040635.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.arff
[04.11.35]	Correctly Classified Instances      139914               58.2773 %
Incorrectly Classified Instances    100169               41.7227 %

[04.11.35]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM_ALPHANUM.wekaEval_130306040635.log
[04.11.35]	lable [ru]: tp=36809, fp=21924, fn=41934, tn=139416, total=240083
P=0.62672, R=0.46746, F1=0.53550

[04.11.35]	lable [cn]: tp=60118, fp=43051, fn=28715, tn=108199, total=240083
P=0.58271, R=0.67675, F1=0.62622

[04.11.35]	lable [br]: tp=42987, fp=35194, fn=29520, tn=132382, total=240083
P=0.54984, R=0.59287, F1=0.57054

[04.11.35]	Weka Accuracy = 139914/240083 = 0.58277
[04.11.35]	Final F1 = 0.58
[04.11.35]	

Perfmon Summary:
Time Used(s): 300.362059
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	4
ru_maxrss ->	587752
ru_minflt ->	592490
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1586
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	30145
ru_oublock ->	7800
ru_stime ->	1.968123
ru_utime ->	1340.799794

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	5
ru_maxrss ->	587752
ru_minflt ->	729679
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1910
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	36972
ru_oublock ->	9528
ru_stime ->	2.396149
ru_utime ->	1642.174629

=========== ======== ============
		
[04.11.35]	Start Weka evaluation: /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP
[04.11.35]	Executing command (redirect to file: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.wekaEval_130306041135.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.arff
[04.17.02]	Correctly Classified Instances      139752               59.6716 %
Incorrectly Classified Instances     94450               40.3284 %

[04.17.02]	Calc P/R/F from weka output log: /home/xj229/logs/3nat_lvl123_15K.bog_M5_L_STM_RMSTP.wekaEval_130306041135.log
[04.17.02]	lable [ru]: tp=37404, fp=20071, fn=39818, tn=136909, total=234202
P=0.65079, R=0.48437, F1=0.55538

[04.17.02]	lable [cn]: tp=61482, fp=45150, fn=25106, tn=102464, total=234202
P=0.57658, R=0.71005, F1=0.63639

[04.17.02]	lable [br]: tp=40866, fp=29229, fn=29526, tn=134581, total=234202
P=0.58301, R=0.58055, F1=0.58178

[04.17.02]	Weka Accuracy = 139752/234202 = 0.59672
[04.17.02]	Final F1 = 0.59
[04.17.02]	

Perfmon Summary:
Time Used(s): 327.142933
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	5
ru_maxrss ->	587752
ru_minflt ->	729679
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1910
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	36972
ru_oublock ->	9528
ru_stime ->	2.396149
ru_utime ->	1642.174629

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	6
ru_maxrss ->	587752
ru_minflt ->	857879
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	2298
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	44231
ru_oublock ->	11432
ru_stime ->	2.788174
ru_utime ->	1970.335138

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130306101328
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[10.13.28]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM
[10.13.28]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM.wekaEval_130306101328.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.arff


======================================================
*********************************************************
Start logging 20130306101630
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[10.16.30]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM
[10.16.30]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM.wekaEval_130306101630.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM.arff
[10.25.35]	Correctly Classified Instances       82931               39.6978 %
Incorrectly Classified Instances    125975               60.3022 %

[10.25.35]	Calc P/R/F from weka output log: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM.wekaEval_130306101630.log
[10.25.35]	lable [ru]: tp=12008, fp=17724, fn=21193, tn=157981, total=208906
P=0.40387, R=0.36168, F1=0.38161

[10.25.35]	lable [fr]: tp=8094, fp=7438, fn=19168, tn=174206, total=208906
P=0.52112, R=0.29690, F1=0.37828

[10.25.35]	lable [cn]: tp=22478, fp=40746, fn=13537, tn=132145, total=208906
P=0.35553, R=0.62413, F1=0.45301

[10.25.35]	lable [de]: tp=10029, fp=11695, fn=19798, tn=167384, total=208906
P=0.46166, R=0.33624, F1=0.38909

[10.25.35]	lable [it]: tp=6749, fp=7662, fn=18410, tn=176085, total=208906
P=0.46832, R=0.26825, F1=0.34112

[10.25.35]	lable [br]: tp=14128, fp=29742, fn=16322, tn=148714, total=208906
P=0.32204, R=0.46397, F1=0.38019

[10.25.35]	lable [mx]: tp=9445, fp=10968, fn=17547, tn=170946, total=208906
P=0.46270, R=0.34992, F1=0.39848

[10.25.35]	Weka Accuracy = 82931/208906 = 0.39698
[10.25.35]	Final F1 = 0.38883
[10.25.35]	

Perfmon Summary:
Time Used(s): 545.090536
Memory Used (Mb): 539.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	0
ru_maxrss ->	0
ru_minflt ->	0
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	0
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	0
ru_oublock ->	0
ru_stime ->	0.0
ru_utime ->	0.0

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	1
ru_maxrss ->	552400
ru_minflt ->	145172
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	567
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	11908
ru_oublock ->	3416
ru_stime ->	0.464029
ru_utime ->	545.042063

=========== ======== ============
		
[10.25.35]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM
[10.25.35]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M10_L_STM.wekaEval_130306102535.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M10_L_STM.arff
[10.31.13]	Correctly Classified Instances       79863               38.233  %
Incorrectly Classified Instances    129022               61.767  %

[10.31.13]	Calc P/R/F from weka output log: /home/xj229/logs/7nat_lvl123_6000each.bog_M10_L_STM.wekaEval_130306102535.log
[10.31.13]	lable [ru]: tp=11232, fp=16725, fn=21965, tn=158963, total=208885
P=0.40176, R=0.33834, F1=0.36733

[10.31.13]	lable [fr]: tp=7558, fp=7712, fn=19702, tn=173913, total=208885
P=0.49496, R=0.27726, F1=0.35542

[10.31.13]	lable [cn]: tp=21921, fp=41087, fn=14092, tn=131785, total=208885
P=0.34791, R=0.60870, F1=0.44275

[10.31.13]	lable [de]: tp=9601, fp=11908, fn=20224, tn=167152, total=208885
P=0.44637, R=0.32191, F1=0.37406

[10.31.13]	lable [it]: tp=6484, fp=8058, fn=18671, tn=175672, total=208885
P=0.44588, R=0.25776, F1=0.32667

[10.31.13]	lable [br]: tp=13953, fp=31805, fn=16493, tn=146634, total=208885
P=0.30493, R=0.45829, F1=0.36620

[10.31.13]	lable [mx]: tp=9114, fp=11727, fn=17875, tn=170169, total=208885
P=0.43731, R=0.33769, F1=0.38110

[10.31.13]	Weka Accuracy = 79863/208885 = 0.38233
[10.31.13]	Final F1 = 0.37336
[10.31.13]	

Perfmon Summary:
Time Used(s): 337.947651
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	1
ru_maxrss ->	552400
ru_minflt ->	145172
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	567
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	11908
ru_oublock ->	3416
ru_stime ->	0.464029
ru_utime ->	545.042063

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	552400
ru_minflt ->	269884
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	931
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	19460
ru_oublock ->	5560
ru_stime ->	0.756047
ru_utime ->	883.595221

=========== ======== ============
		
[10.31.13]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM
[10.31.13]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_STM.wekaEval_130306103113.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_STM.arff
[10.42.50]	Correctly Classified Instances       83075               39.7686 %
Incorrectly Classified Instances    125821               60.2314 %

[10.42.50]	Calc P/R/F from weka output log: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_STM.wekaEval_130306103113.log
[10.42.50]	lable [ru]: tp=12284, fp=17777, fn=20917, tn=157918, total=208896
P=0.40864, R=0.36999, F1=0.38835

[10.42.50]	lable [fr]: tp=8122, fp=8099, fn=19140, tn=173535, total=208896
P=0.50071, R=0.29792, F1=0.37357

[10.42.50]	lable [cn]: tp=22433, fp=40901, fn=13581, tn=131981, total=208896
P=0.35420, R=0.62290, F1=0.45160

[10.42.50]	lable [de]: tp=9935, fp=11185, fn=19891, tn=167885, total=208896
P=0.47041, R=0.33310, F1=0.39002

[10.42.50]	lable [it]: tp=6889, fp=8240, fn=18266, tn=175501, total=208896
P=0.45535, R=0.27386, F1=0.34202

[10.42.50]	lable [br]: tp=13923, fp=28721, fn=16526, tn=149726, total=208896
P=0.32649, R=0.45726, F1=0.38097

[10.42.50]	lable [mx]: tp=9489, fp=10898, fn=17500, tn=171009, total=208896
P=0.46544, R=0.35159, F1=0.40058

[10.42.50]	Weka Accuracy = 83075/208896 = 0.39769
[10.42.50]	Final F1 = 0.38959
[10.42.50]	

Perfmon Summary:
Time Used(s): 697.359955
Memory Used (Mb): 31.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	2
ru_maxrss ->	552400
ru_minflt ->	269884
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	931
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	19460
ru_oublock ->	5560
ru_stime ->	0.756047
ru_utime ->	883.595221

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	3
ru_maxrss ->	584688
ru_minflt ->	423629
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1659
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	34501
ru_oublock ->	9512
ru_stime ->	1.224076
ru_utime ->	1580.57878

=========== ======== ============
		
[10.42.50]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L
[10.42.50]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L.wekaEval_130306104250.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_L.arff
[10.54.32]	Correctly Classified Instances       83866               40.1459 %
Incorrectly Classified Instances    125037               59.8541 %

[10.54.32]	Calc P/R/F from weka output log: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L.wekaEval_130306104250.log
[10.54.32]	lable [ru]: tp=12026, fp=17676, fn=21174, tn=158027, total=208903
P=0.40489, R=0.36223, F1=0.38237

[10.54.32]	lable [fr]: tp=8269, fp=7302, fn=18993, tn=174339, total=208903
P=0.53105, R=0.30332, F1=0.38610

[10.54.32]	lable [cn]: tp=22480, fp=39750, fn=13535, tn=133138, total=208903
P=0.36124, R=0.62418, F1=0.45763

[10.54.32]	lable [de]: tp=9960, fp=10932, fn=19867, tn=168144, total=208903
P=0.47674, R=0.33393, F1=0.39275

[10.54.32]	lable [it]: tp=7072, fp=8041, fn=18086, tn=175704, total=208903
P=0.46794, R=0.28110, F1=0.35122

[10.54.32]	lable [br]: tp=14321, fp=29650, fn=16128, tn=148804, total=208903
P=0.32569, R=0.47033, F1=0.38487

[10.54.32]	lable [mx]: tp=9738, fp=11686, fn=17254, tn=170225, total=208903
P=0.45454, R=0.36077, F1=0.40226

[10.54.32]	Weka Accuracy = 83866/208903 = 0.40146
[10.54.32]	Final F1 = 0.39389
[10.54.32]	

Perfmon Summary:
Time Used(s): 702.231987
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	3
ru_maxrss ->	584688
ru_minflt ->	423629
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	1659
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	34501
ru_oublock ->	9512
ru_stime ->	1.224076
ru_utime ->	1580.57878

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	4
ru_maxrss ->	584688
ru_minflt ->	575197
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	2418
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	49709
ru_oublock ->	13544
ru_stime ->	1.652103
ru_utime ->	2282.498647

=========== ======== ============
		
[10.54.32]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM
[10.54.32]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.wekaEval_130306105432.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.arff
[11.02.30]	Correctly Classified Instances       81367               38.9605 %
Incorrectly Classified Instances    127478               61.0395 %

[11.02.30]	Calc P/R/F from weka output log: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM_ALPHANUM.wekaEval_130306105432.log
[11.02.31]	lable [ru]: tp=11584, fp=17696, fn=21611, tn=157954, total=208845
P=0.39563, R=0.34897, F1=0.37084

[11.02.31]	lable [fr]: tp=7772, fp=7163, fn=19476, tn=174434, total=208845
P=0.52039, R=0.28523, F1=0.36849

[11.02.31]	lable [cn]: tp=22315, fp=41210, fn=13689, tn=131631, total=208845
P=0.35128, R=0.61979, F1=0.44841

[11.02.31]	lable [de]: tp=9962, fp=11649, fn=19861, tn=167373, total=208845
P=0.46097, R=0.33404, F1=0.38737

[11.02.31]	lable [it]: tp=6752, fp=7560, fn=18398, tn=176135, total=208845
P=0.47177, R=0.26847, F1=0.34220

[11.02.31]	lable [br]: tp=14263, fp=31832, fn=16178, tn=146572, total=208845
P=0.30943, R=0.46855, F1=0.37271

[11.02.31]	lable [mx]: tp=8719, fp=10368, fn=18265, tn=171493, total=208845
P=0.45680, R=0.32312, F1=0.37850

[11.02.31]	Weka Accuracy = 81367/208845 = 0.38960
[11.02.31]	Final F1 = 0.38122
[11.02.31]	

Perfmon Summary:
Time Used(s): 478.165102
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	4
ru_maxrss ->	584688
ru_minflt ->	575197
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	2418
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	49709
ru_oublock ->	13544
ru_stime ->	1.652103
ru_utime ->	2282.498647

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	5
ru_maxrss ->	584688
ru_minflt ->	707116
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	2962
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	60179
ru_oublock ->	16576
ru_stime ->	1.952122
ru_utime ->	2760.840541

=========== ======== ============
		
[11.02.31]	Start Weka evaluation: /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP
[11.02.31]	Executing command (redirect to file: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.wekaEval_130306110231.log):
java -cp /home/xj229/tools/weka/weka.jar weka.classifiers.bayes.NaiveBayes -v -c first -x 4 -t /home/xj229/data/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.arff
[11.11.08]	Correctly Classified Instances       82079               40.2733 %
Incorrectly Classified Instances    121726               59.7267 %

[11.11.08]	Calc P/R/F from weka output log: /home/xj229/logs/7nat_lvl123_6000each.bog_M5_L_STM_RMSTP.wekaEval_130306110231.log
[11.11.08]	lable [ru]: tp=12020, fp=18153, fn=20289, tn=153343, total=203805
P=0.39837, R=0.37203, F1=0.38475

[11.11.08]	lable [fr]: tp=8279, fp=7589, fn=18587, tn=169350, total=203805
P=0.52174, R=0.30816, F1=0.38747

[11.11.08]	lable [cn]: tp=23181, fp=45460, fn=11785, tn=123379, total=203805
P=0.33771, R=0.66296, F1=0.44748

[11.11.08]	lable [de]: tp=9645, fp=9708, fn=19522, tn=164930, total=203805
P=0.49837, R=0.33068, F1=0.39757

[11.11.08]	lable [it]: tp=6758, fp=6602, fn=17928, tn=172517, total=203805
P=0.50584, R=0.27376, F1=0.35525

[11.11.08]	lable [br]: tp=12601, fp=23327, fn=16889, tn=150988, total=203805
P=0.35073, R=0.42730, F1=0.38525

[11.11.08]	lable [mx]: tp=9595, fp=10887, fn=16726, tn=166597, total=203805
P=0.46846, R=0.36454, F1=0.41002

[11.11.08]	Weka Accuracy = 82079/203805 = 0.40273
[11.11.08]	Final F1 = 0.39540
[11.11.08]	

Perfmon Summary:
Time Used(s): 517.627916
Memory Used (Mb): 0.000000
=========== Prev Mem ============
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	5
ru_maxrss ->	584688
ru_minflt ->	707116
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	2962
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	60179
ru_oublock ->	16576
ru_stime ->	1.952122
ru_utime ->	2760.840541

=========== ======== ============
		
=========== After Mem ===========
n_fields ->	16
n_sequence_fields ->	16
n_unnamed_fields ->	0
ru_idrss ->	0
ru_inblock ->	0
ru_isrss ->	0
ru_ixrss ->	0
ru_majflt ->	6
ru_maxrss ->	584688
ru_minflt ->	840804
ru_msgrcv ->	0
ru_msgsnd ->	0
ru_nivcsw ->	3509
ru_nsignals ->	0
ru_nswap ->	0
ru_nvcsw ->	71428
ru_oublock ->	19880
ru_stime ->	2.348146
ru_utime ->	3279.08893

=========== ======== ============
		


======================================================
*********************************************************
Start logging 20130315105354
 ../Util/Log.pyc



======================================================
*********************************************************
Start logging 20130315105441
 ../Util/Log.pyc

[10.54.41]	Ngram Feature Extractor initialized, n = 2


======================================================
*********************************************************
Start logging 20130315105504
 ../Util/Log.pyc

[10.55.04]	Ngram Feature Extractor initialized, n = 2
[10.55.04]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130315105526
 ../Util/Log.pyc

[10.55.26]	Ngram Feature Extractor initialized, n = 2
[10.55.26]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130315130717
 ../Util/Log.pyc

[13.07.17]	Ngram Feature Extractor initialized, n = 2
[13.07.17]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130315130828
 ../Util/Log.pyc

[13.08.28]	Ngram Feature Extractor initialized, n = 2
[13.08.28]	Start extract ngram feature! n = 2
[13.08.30]	[NGramFE] First pass vocab scan, #vocab = 1


======================================================
*********************************************************
Start logging 20130315131014
 ../Util/Log.pyc

[13.10.14]	Ngram Feature Extractor initialized, n = 2
[13.10.14]	Start extract ngram feature! n = 2
[13.10.15]	[NGramFE] First pass vocab scan, #vocab = 1
[13.10.15]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1


======================================================
*********************************************************
Start logging 20130315133746
 ../Util/Log.pyc

[13.37.46]	Ngram Feature Extractor initialized, n = 2
[13.37.46]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317101404
 ../Util/Log.pyc

[10.14.04]	Ngram Feature Extractor initialized, n = 2
[10.14.04]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317101558
 ../Util/Log.pyc

[10.15.58]	Ngram Feature Extractor initialized, n = 2
[10.15.58]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317101709
 ../Util/Log.pyc

[10.17.09]	Ngram Feature Extractor initialized, n = 2
[10.17.09]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317101924
 ../Util/Log.pyc

[10.19.24]	Ngram Feature Extractor initialized, n = 2
[10.19.24]	Start extract ngram feature! n = 2
[10.19.25]	[NGramFE] First pass vocab scan, #vocab = 809
[10.19.25]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809


======================================================
*********************************************************
Start logging 20130317102243
 ../Util/Log.pyc

[10.22.43]	Ngram Feature Extractor initialized, n = 2
[10.22.43]	Start extract ngram feature! n = 2
[10.22.44]	[NGramFE] First pass vocab scan, #vocab = 809
[10.22.44]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809


======================================================
*********************************************************
Start logging 20130317102259
 ../Util/Log.pyc

[10.22.59]	Ngram Feature Extractor initialized, n = 2
[10.22.59]	Start extract ngram feature! n = 2
[10.23.01]	[NGramFE] First pass vocab scan, #vocab = 809
[10.23.01]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809


======================================================
*********************************************************
Start logging 20130317102330
 ../Util/Log.pyc

[10.23.30]	Ngram Feature Extractor initialized, n = 2
[10.23.30]	Start extract ngram feature! n = 2
[10.23.31]	[NGramFE] First pass vocab scan, #vocab = 809
[10.23.31]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809


======================================================
*********************************************************
Start logging 20130317102833
 ../Util/Log.pyc

[10.28.33]	Ngram Feature Extractor initialized, n = 2
[10.28.33]	Start extract ngram feature! n = 2
[10.28.34]	[NGramFE] First pass vocab scan, #vocab = 809
[10.28.34]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809


======================================================
*********************************************************
Start logging 20130317102926
 ../Util/Log.pyc

[10.29.26]	Ngram Feature Extractor initialized, n = 2
[10.29.26]	Start extract ngram feature! n = 2
[10.29.28]	[NGramFE] First pass vocab scan, #vocab = 809
[10.29.28]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809


======================================================
*********************************************************
Start logging 20130317103001
 ../Util/Log.pyc

[10.30.01]	Ngram Feature Extractor initialized, n = 2
[10.30.01]	Start extract ngram feature! n = 2
[10.30.02]	[NGramFE] First pass vocab scan, #vocab = 809
[10.30.02]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809
[10.30.02]	Done! Number of instance wrote: 140


======================================================
*********************************************************
Start logging 20130317103621
 ../Util/Log.pyc

[10.36.21]	Ngram Feature Extractor initialized, n = 2
[10.36.21]	Start extract ngram feature! n = 2
[10.36.22]	[NGramFE] First pass vocab scan, #vocab = 809
[10.36.22]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 809
[10.36.22]	Done! Number of instance wrote: 140


======================================================
*********************************************************
Start logging 20130317104946
 ../Util/Log.pyc

[10.49.46]	Ngram Feature Extractor initialized, n = 2
[10.49.46]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317105528
 ../Util/Log.pyc

[10.55.28]	Ngram Feature Extractor initialized, n = 2
[10.55.28]	Start extract ngram feature! n = 2
[11.03.42]	[NGramFE] First pass vocab scan, #vocab = 1650638
[11.03.42]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1650638


======================================================
*********************************************************
Start logging 20130317110511
 ../Util/Log.pyc

[11.05.11]	Ngram Feature Extractor initialized, n = 2
[11.05.11]	Start extract ngram feature! n = 2
[11.07.36]	[NGramFE] First pass vocab scan, #vocab = 2199040
[11.07.36]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 2199040
[11.11.09]	Done! Number of instance wrote: 2897755


======================================================
*********************************************************
Start logging 20130317111806
 ../Util/Log.pyc

[11.18.06]	Ngram Feature Extractor initialized, n = 2
[11.18.06]	Start extract ngram feature! n = 2
[11.18.17]	[NGramFE] First pass vocab scan, #vocab = 186654
[11.18.17]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 186654
[11.18.31]	Done! Number of instance wrote: 240163


======================================================
*********************************************************
Start logging 20130317112049
 ../Util/Log.pyc

[11.20.49]	Ngram Feature Extractor initialized, n = 2
[11.20.49]	Start extract ngram feature! n = 2
[11.21.20]	[NGramFE] First pass vocab scan, #vocab = 153879
[11.21.20]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 153879
[11.21.54]	Done! Number of instance wrote: 240163


======================================================
*********************************************************
Start logging 20130317112620
 ../Util/Log.pyc

[11.26.20]	Ngram Feature Extractor initialized, n = 2
[11.26.20]	Start extract ngram feature! n = 2
[11.27.07]	[NGramFE] First pass vocab scan, #vocab = 153879
[11.27.07]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 153879
[11.27.59]	Done! Number of instance wrote: 240163


======================================================
*********************************************************
Start logging 20130317113821
 ../Util/Log.pyc

[11.38.21]	Ngram Feature Extractor initialized, n = 2
[11.38.21]	Start extract ngram feature! n = 2
[11.38.46]	[NGramFE] First pass vocab scan, #vocab = 168280
[11.38.46]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 168280
[11.39.15]	Done! Number of instance wrote: 240163


======================================================
*********************************************************
Start logging 20130317115542
 ../Util/Log.pyc

[11.55.42]	Ngram Feature Extractor initialized, n = 2
[11.55.42]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317121058
 ../Util/Log.pyc

[12.10.58]	Ngram Feature Extractor initialized, n = 2
[12.10.58]	Start extract ngram feature! n = 2


======================================================
*********************************************************
Start logging 20130317121123
 ../Util/Log.pyc

[12.11.23]	Ngram Feature Extractor initialized, n = 2
[12.11.23]	Start extract ngram feature! n = 2
[12.11.47]	[NGramFE] First pass vocab scan, #vocab = 168275
[12.11.47]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 168275
[12.12.15]	Done! Number of instance wrote: 240163


======================================================
*********************************************************
Start logging 20130317121506
 ../Util/Log.pyc

[12.15.06]	Ngram Feature Extractor initialized, n = 2
[12.15.06]	Start extract ngram feature! n = 2
[12.15.30]	[NGramFE] First pass vocab scan, #vocab = 168275


======================================================
*********************************************************
Start logging 20130317121637
 ../Util/Log.pyc

[12.16.37]	Ngram Feature Extractor initialized, n = 2
[12.16.37]	Start extract ngram feature! n = 2
[12.17.00]	[NGramFE] First pass vocab scan, #vocab = 168275
[12.17.00]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 21313
[12.17.26]	Done! Number of instance wrote: 238733


======================================================
*********************************************************
Start logging 20130317152706
 ../Util/Log.pyc

[15.27.06]	Ngram Feature Extractor initialized, n = 2
[15.27.06]	Start extract ngram feature! n = 2
[15.27.30]	[NGramFE] First pass vocab scan, #vocab = 168275
[15.27.31]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 21313
[15.27.57]	Done! Number of instance wrote: 238733


======================================================
*********************************************************
Start logging 20130317152849
 ../Util/Log.pyc

[15.28.49]	Ngram Feature Extractor initialized, n = 2
[15.28.49]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/nfeout.arff
to: /home/xj229/test/nfeout.arff.libsvm


======================================================
*********************************************************
Start logging 20130317152923
 ../Util/Log.pyc

[15.29.23]	Ngram Feature Extractor initialized, n = 2
[15.29.23]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/nfeout.arff
to: /home/xj229/test/nfeout.arff.libsvm
[15.29.23]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/nfeout.arff -o /home/xj229/test/nfeout.arff.libsvm


======================================================
*********************************************************
Start logging 20130317153718
 ../Util/Log.pyc

[15.37.18]	Ngram Feature Extractor initialized, n = 3
[15.37.18]	Start extract ngram feature! n = 3
[15.37.42]	[NGramFE] First pass vocab scan, #vocab = 336268
[15.37.42]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 24845
[15.38.08]	Done! Number of instance wrote: 222955
[15.38.08]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/nfeout_3gram.arff
to: /home/xj229/test/nfeout_3gram.arff.libsvm
[15.38.08]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/nfeout_3gram.arff -o /home/xj229/test/nfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130318182130
 ../Util/Log.pyc

[18.21.31]	

Processing cn
[18.21.31]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[18.21.31]	

Processing br
[18.21.31]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[18.21.31]	

Processing ru
[18.21.31]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[18.21.31]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318182230
 ../Util/Log.pyc

[18.22.31]	

Processing cn
[18.22.31]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[18.22.31]	

Processing br
[18.22.31]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[18.22.31]	

Processing ru
[18.22.31]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[18.22.31]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318182313
 ../Util/Log.pyc

[18.23.15]	

Processing cn
[18.23.15]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[18.23.15]	

Processing br
[18.23.15]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[18.23.15]	

Processing ru
[18.23.15]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[18.23.15]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318182436
 ../Util/Log.pyc

[18.24.37]	

Processing cn
[18.24.37]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[18.24.37]	

Processing br
[18.24.37]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[18.24.37]	

Processing ru
[18.24.37]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[18.24.37]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree
[18.24.51]	516334 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318182556
 ../Util/Log.pyc

[18.25.58]	

Processing cn
[18.25.58]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[18.25.58]	

Processing br
[18.25.58]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[18.25.58]	

Processing ru
[18.25.58]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[18.25.58]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree
[18.26.11]	516334 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318182733
 ../Util/Log.pyc

[18.27.34]	

Processing cn
[18.27.34]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[18.27.34]	

Processing br
[18.27.34]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[18.27.34]	

Processing ru
[18.27.34]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[18.27.34]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree
[18.27.56]	516334 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318201911
 ../Util/Log.pyc

[20.19.13]	

Processing cn
[20.19.13]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[20.19.13]	

Processing br
[20.19.13]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[20.19.13]	

Processing ru
[20.19.13]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[20.19.13]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree
[20.19.38]	516334 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree


======================================================
*********************************************************
Start logging 20130318202042
 ../Util/Log.pyc

[20.20.44]	

Processing cn
[20.20.44]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[20.20.44]	

Processing br
[20.20.44]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[20.20.44]	

Processing ru
[20.20.44]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[20.20.44]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree
[20.21.00]	516334 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_42K.tree.
[20.21.00]	1225 writings missed!


======================================================
*********************************************************
Start logging 20130318202457
 ../Util/Log.pyc

[20.24.58]	

Processing cn
[20.24.58]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[20.24.58]	

Processing br
[20.24.58]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[20.24.58]	

Processing ru
[20.24.58]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[20.24.58]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.tree
[20.25.14]	240168 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.tree.
[20.25.14]	655 writings missed!


======================================================
*********************************************************
Start logging 20130318230123
 ../Util/Log.pyc

[23.01.23]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318230138
 ../Util/Log.pyc

[23.01.38]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318230219
 ../Util/Log.pyc

[23.02.19]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318230230
 ../Util/Log.pyc

[23.02.30]	POS Ngram Feature Extractor initialized, n = 3
[23.02.31]	[PosNGramFE] First pass vocab scan, #vocab = 0
[23.02.31]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0
[23.02.31]	Done! Number of instance wrote: 0
[23.02.31]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.02.31]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130318230400
 ../Util/Log.pyc

[23.04.00]	POS Ngram Feature Extractor initialized, n = 3
[23.04.01]	[PosNGramFE] First pass vocab scan, #vocab = 0
[23.04.01]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0
[23.04.01]	Done! Number of instance wrote: 0
[23.04.01]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.04.01]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.04.01]	POS Ngram Feature Extractor initialized, n = 3
[23.04.01]	[PosNGramFE] First pass vocab scan, #vocab = 0
[23.04.01]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0
[23.04.01]	Done! Number of instance wrote: 0
[23.04.01]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.04.01]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130318230603
 ../Util/Log.pyc

[23.06.03]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318230822
 ../Util/Log.pyc

[23.08.22]	POS Ngram Feature Extractor initialized, n = 3
[23.08.39]	[PosNGramFE] First pass vocab scan, #vocab = 0
[23.08.39]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0
[23.08.39]	Done! Number of instance wrote: 0
[23.08.39]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.08.39]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.08.40]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318230917
 ../Util/Log.pyc

[23.09.17]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318231100
 ../Util/Log.pyc

[23.11.00]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318231116
 ../Util/Log.pyc

[23.11.16]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130318231301
 ../Util/Log.pyc

[23.13.01]	POS Ngram Feature Extractor initialized, n = 3
[23.13.39]	[PosNGramFE] First pass vocab scan, #vocab = 1
[23.13.39]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1


======================================================
*********************************************************
Start logging 20130318231408
 ../Util/Log.pyc

[23.14.08]	POS Ngram Feature Extractor initialized, n = 3
[23.14.46]	[PosNGramFE] First pass vocab scan, #vocab = 1
[23.14.46]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1
[23.15.25]	Done! Number of instance wrote: 240168
[23.15.25]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.15.25]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[23.15.26]	POS Ngram Feature Extractor initialized, n = 3
[23.16.19]	[PosNGramFE] First pass vocab scan, #vocab = 1
[23.16.19]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1


======================================================
*********************************************************
Start logging 20130319093226
 ../Util/Log.pyc

[09.32.26]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130319093316
 ../Util/Log.pyc

[09.33.16]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130319093538
 ../Util/Log.pyc

[09.35.38]	POS Ngram Feature Extractor initialized, n = 3
[09.35.40]	[PosNGramFE] First pass vocab scan, #vocab = 1046
[09.35.40]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 246
[09.35.40]	Done! Number of instance wrote: 974
[09.35.40]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.35.40]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.35.40]	POS Ngram Feature Extractor initialized, n = 3
[09.35.40]	[PosNGramFE] First pass vocab scan, #vocab = 1046
[09.35.40]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 246
[09.35.40]	Done! Number of instance wrote: 974
[09.35.40]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.35.40]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319094632
 ../Util/Log.pyc

[09.46.32]	POS Ngram Feature Extractor initialized, n = 3
[09.46.34]	[PosNGramFE] First pass vocab scan, #vocab = 1046
[09.46.34]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 246
[09.46.34]	Done! Number of instance wrote: 974
[09.46.34]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.46.34]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.46.34]	POS Ngram Feature Extractor initialized, n = 3
[09.46.34]	[PosNGramFE] First pass vocab scan, #vocab = 1046
[09.46.34]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 246
[09.46.35]	Done! Number of instance wrote: 974
[09.46.35]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.46.35]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319094821
 ../Util/Log.pyc

[09.48.21]	POS Ngram Feature Extractor initialized, n = 3
[09.48.23]	[PosNGramFE] First pass vocab scan, #vocab = 1046
[09.48.23]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 246
[09.48.23]	Done! Number of instance wrote: 974
[09.48.23]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.48.23]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.48.23]	POS Ngram Feature Extractor initialized, n = 3
[09.48.23]	[PosNGramFE] First pass vocab scan, #vocab = 1046
[09.48.23]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 246
[09.48.23]	Done! Number of instance wrote: 974
[09.48.23]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.48.23]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319094917
 ../Util/Log.pyc

[09.49.17]	POS Ngram Feature Extractor initialized, n = 3
[09.49.57]	[PosNGramFE] First pass vocab scan, #vocab = 13436
[09.49.57]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6233
[09.50.40]	Done! Number of instance wrote: 240127
[09.50.40]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.50.40]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.50.40]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130319095254
 ../Util/Log.pyc

[09.52.54]	POS Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130319095345
 ../Util/Log.pyc

[09.53.45]	POS Ngram Feature Extractor initialized, n = 3
[09.53.45]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[09.53.45]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319100110
 ../Util/Log.pyc

[10.01.10]	POS Ngram Feature Extractor initialized, n = 2
[10.02.08]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[10.02.08]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 997
[10.03.11]	Done! Number of instance wrote: 240168
[10.03.11]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[10.03.11]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319100406
 ../Util/Log.pyc

[10.04.06]	POS Ngram Feature Extractor initialized, n = 2
[10.05.04]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[10.05.04]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 997
[10.06.07]	Done! Number of instance wrote: 240168
[10.06.07]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/posnfeout_3gram.arff
to: /home/xj229/test/posnfeout_3gram.arff.libsvm
[10.06.07]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/posnfeout_3gram.arff -o /home/xj229/test/posnfeout_3gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319112326
 ../Util/Log.pyc

[11.23.26]	POS Ngram Feature Extractor initialized, n = 2


======================================================
*********************************************************
Start logging 20130319112425
 ../Util/Log.pyc

[11.24.25]	ProdRule Feature Extractor initialized, n = 2
[11.25.25]	[ProdRuleFe] First pass vocab scan, #vocab = 9362
[11.25.25]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 2111
[11.26.28]	Done! Number of instance wrote: 239840
[11.26.28]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/prodRule_bog.arff
to: /home/xj229/test/prodRule_bog.arff.libsvm
[11.26.28]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/prodRule_bog.arff -o /home/xj229/test/prodRule_bog.arff.libsvm


======================================================
*********************************************************
Start logging 20130319112920
 ../Util/Log.pyc

[11.29.20]	ProdRule Feature Extractor initialized, n = 2
[11.30.22]	[ProdRuleFe] First pass vocab scan, #vocab = 9362
[11.30.22]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 2111
[11.31.25]	Done! Number of instance wrote: 239840
[11.31.25]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/prodRule_bog.arff
to: /home/xj229/test/prodRule_bog.arff.libsvm
[11.31.25]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/prodRule_bog.arff -o /home/xj229/test/prodRule_bog.arff.libsvm


======================================================
*********************************************************
Start logging 20130319113942
 ../Util/Log.pyc

[11.39.42]	ProdRule Feature Extractor initialized, n = 2


======================================================
*********************************************************
Start logging 20130319113955
 ../Util/Log.pyc

[11.39.55]	ProdRule Feature Extractor initialized, n = 2
[11.39.57]	[ProdRuleFe] First pass vocab scan, #vocab = 338
[11.39.57]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 93
[11.39.57]	Done! Number of instance wrote: 993
[11.39.57]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/prodRule_bog.arff
to: /home/xj229/test/prodRule_bog.arff.libsvm
[11.39.57]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/prodRule_bog.arff -o /home/xj229/test/prodRule_bog.arff.libsvm


======================================================
*********************************************************
Start logging 20130319114108
 ../Util/Log.pyc

[11.41.08]	ProdRule Feature Extractor initialized, n = 2
[11.41.10]	[ProdRuleFe] First pass vocab scan, #vocab = 338
[11.41.10]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 93
[11.41.10]	Done! Number of instance wrote: 993
[11.41.10]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/prodRule_bog.arff
to: /home/xj229/test/prodRule_bog.arff.libsvm
[11.41.10]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/prodRule_bog.arff -o /home/xj229/test/prodRule_bog.arff.libsvm


======================================================
*********************************************************
Start logging 20130319114128
 ../Util/Log.pyc

[11.41.28]	ProdRule Feature Extractor initialized, n = 2
[11.42.30]	[ProdRuleFe] First pass vocab scan, #vocab = 9362
[11.42.30]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 2111
[11.43.34]	Done! Number of instance wrote: 239840
[11.43.34]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/prodRule_bog.arff
to: /home/xj229/test/prodRule_bog.arff.libsvm
[11.43.34]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/prodRule_bog.arff -o /home/xj229/test/prodRule_bog.arff.libsvm


======================================================
*********************************************************
Start logging 20130319154252
 ../Util/Log.pyc

[15.42.53]	

Processing cn
[15.42.53]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[15.42.53]	

Processing br
[15.42.53]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[15.42.53]	

Processing ru
[15.42.53]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[15.42.53]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.depd


======================================================
*********************************************************
Start logging 20130319154359
 ../Util/Log.pyc

[15.44.00]	

Processing cn
[15.44.00]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[15.44.00]	

Processing br
[15.44.00]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[15.44.00]	

Processing ru
[15.44.00]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[15.44.00]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.depd
[15.44.05]	240168 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.depd.
[15.44.05]	655 writings missed!


======================================================
*********************************************************
Start logging 20130319154757
 ../Util/Log.pyc

[15.47.58]	

Processing cn
[15.47.58]	Read 63795 wid from file /home/xj229/workspace/AcsProj/data/cn_lvl123.widlist
[15.47.58]	

Processing br
[15.47.58]	Read 41969 wid from file /home/xj229/workspace/AcsProj/data/br_lvl123.widlist
[15.47.58]	

Processing ru
[15.47.58]	Read 14362 wid from file /home/xj229/workspace/AcsProj/data/ru_lvl123.widlist
[15.47.58]	Output 3 nat lvl 123 each treedata to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.depd
[15.48.24]	240168 sentences has been wrote to /home/xj229/workspace/AcsProj/data/3nat_lvl123_15K.depd.
[15.48.24]	655 writings missed!


======================================================
*********************************************************
Start logging 20130319195601
 ../Util/Log.pyc



======================================================
*********************************************************
Start logging 20130319195708
 ../Util/Log.pyc

[19.57.08]	Depedancy extractor initlized!


======================================================
*********************************************************
Start logging 20130319195731
 ../Util/Log.pyc

[19.57.31]	Depedancy extractor initlized!


======================================================
*********************************************************
Start logging 20130319195807
 ../Util/Log.pyc

[19.58.07]	Depedancy extractor initlized!


======================================================
*********************************************************
Start logging 20130319200040
 ../Util/Log.pyc

[20.00.40]	Depedancy extractor initlized!


======================================================
*********************************************************
Start logging 20130319200200
 ../Util/Log.pyc

[20.02.00]	Depedancy extractor initlized!


======================================================
*********************************************************
Start logging 20130319200213
 ../Util/Log.pyc

[20.02.13]	Depedancy extractor initlized!
[20.02.20]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.02.20]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319200244
 ../Util/Log.pyc

[20.02.44]	Depedancy extractor initlized!
[20.02.50]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.02.50]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319200345
 ../Util/Log.pyc

[20.03.45]	Depedancy extractor initlized!
[20.03.52]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.03.52]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319200452
 ../Util/Log.pyc

[20.04.52]	Depedancy extractor initlized!
[20.04.58]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.04.58]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319200551
 ../Util/Log.pyc

[20.05.51]	Depedancy extractor initlized!
[20.05.57]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.05.57]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319200645
 ../Util/Log.pyc

[20.06.45]	Depedancy extractor initlized!
[20.06.51]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.06.51]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319200727
 ../Util/Log.pyc

[20.07.27]	Depedancy extractor initlized!
[20.07.33]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.07.33]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152


======================================================
*********************************************************
Start logging 20130319202254
 ../Util/Log.pyc

[20.22.54]	Depedancy extractor initlized!
[20.23.00]	[DepdExtractor] First pass vocab scan, #vocab = 363
[20.23.00]	[DepdExtractor] Applied minimum frequency cut-off (#attr) #vocab = 152
[20.23.11]	Done! Number of instance wrote: 240166
[20.23.11]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/prodRule_bog.arff
to: /home/xj229/test/prodRule_bog.arff.libsvm
[20.23.11]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/prodRule_bog.arff -o /home/xj229/test/prodRule_bog.arff.libsvm


======================================================
*********************************************************
Start logging 20130319222923
 ../Util/Log.pyc

[22.29.23]	Ngram Feature Extractor initialized, n = 3
[22.29.23]	Start extract ngram feature! n = 1
[22.29.40]	[NGramFE] First pass vocab scan, #vocab = 0
[22.29.40]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0
[22.29.58]	Done! Number of instance wrote: 240168
[22.29.58]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/nfeout_1gram.arff
to: /home/xj229/test/nfeout_1gram.arff.libsvm
[22.29.58]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/nfeout_1gram.arff -o /home/xj229/test/nfeout_1gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319223343
 ../Util/Log.pyc

[22.33.43]	Ngram Feature Extractor initialized, n = 3
[22.33.43]	Start extract ngram feature! n = 1
[22.34.00]	[NGramFE] First pass vocab scan, #vocab = 0
[22.34.00]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0


======================================================
*********************************************************
Start logging 20130319223557
 /home/xj229/workspace/AcsProj/Util/Log.py

[22.35.57]	Ngram Feature Extractor initialized, n = 3
[22.35.57]	Start extract ngram feature! n = 1


======================================================
*********************************************************
Start logging 20130319223819
 ../Util/Log.py

[22.38.19]	Ngram Feature Extractor initialized, n = 3
[22.38.19]	Start extract ngram feature! n = 1
[22.38.42]	[NGramFE] First pass vocab scan, #vocab = 31044
[22.38.42]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 31044


======================================================
*********************************************************
Start logging 20130319224546
 ../Util/Log.pyc

[22.45.46]	Ngram Feature Extractor initialized, n = 3
[22.45.46]	Ngram Feature Extractor initialized, n = 3
[22.45.46]	Start extract ngram feature! n = 1


======================================================
*********************************************************
Start logging 20130319224556
 ../Util/Log.pyc

[22.45.56]	Ngram Feature Extractor initialized, n = 3
[22.45.56]	Ngram Feature Extractor initialized, n = 3
[22.45.56]	Start extract ngram feature! n = 1


======================================================
*********************************************************
Start logging 20130319224629
 ../Util/Log.pyc

[22.46.29]	Ngram Feature Extractor initialized, n = 3
[22.46.29]	Ngram Feature Extractor initialized, n = 3
[22.46.29]	Start extract ngram feature! n = 1
[22.46.44]	[NGramFE] First pass vocab scan, #vocab = 31044
[22.46.44]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[22.47.05]	Start extract ngram feature! n = 2
[22.47.20]	[NGramFE] First pass vocab scan, #vocab = 168275
[22.47.20]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 21313


======================================================
*********************************************************
Start logging 20130319225135
 ../Util/Log.pyc

[22.51.35]	Ngram Feature Extractor initialized, n = 3
[22.51.35]	Ngram Feature Extractor initialized, n = 3
[22.51.35]	Start extract ngram feature! n = 1
[22.51.50]	[NGramFE] First pass vocab scan, #vocab = 31044
[22.51.50]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[22.52.10]	Start extract ngram feature! n = 2
[22.52.25]	[NGramFE] First pass vocab scan, #vocab = 168275
[22.52.25]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 21313
[22.53.06]	Done! Number of instance wrote: 1561156
[22.53.06]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/12gram.arff
to: /home/xj229/test/12gram.arff.libsvm
[22.53.06]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/12gram.arff -o /home/xj229/test/12gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130319225659
 /home/xj229/workspace/AcsProj/Util/Log.py

[22.56.59]	Ngram Feature Extractor initialized, n = 3
[22.56.59]	Ngram Feature Extractor initialized, n = 3
[22.56.59]	Start extract ngram feature! n = 1


======================================================
*********************************************************
Start logging 20130319225729
 /home/xj229/workspace/AcsProj/Util/Log.pyc

[22.57.29]	Ngram Feature Extractor initialized, n = 3
[22.57.29]	Ngram Feature Extractor initialized, n = 3
[22.57.29]	Start extract ngram feature! n = 1
[22.57.30]	[NGramFE] First pass vocab scan, #vocab = 817
[22.57.30]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 190
[22.57.34]	Start extract ngram feature! n = 2
[22.57.34]	[NGramFE] First pass vocab scan, #vocab = 2000
[22.57.34]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 249


======================================================
*********************************************************
Start logging 20130319230326
 ../Util/Log.py

[23.03.26]	Ngram Feature Extractor initialized, n = 3
[23.03.26]	Ngram Feature Extractor initialized, n = 3
[23.03.26]	Start extract ngram feature! n = 1
[23.03.42]	[NGramFE] First pass vocab scan, #vocab = 31044
[23.03.42]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[23.04.01]	Start extract ngram feature! n = 2
[23.04.16]	[NGramFE] First pass vocab scan, #vocab = 168275
[23.04.16]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 21313
[23.04.46]	Done! Number of instance wrote: 240154
[23.04.46]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/test/12gram.arff
to: /home/xj229/test/12gram.arff.libsvm
[23.04.46]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/test/12gram.arff -o /home/xj229/test/12gram.arff.libsvm


======================================================
*********************************************************
Start logging 20130320003431
 ../Util/Log.pyc

[00.34.31]	Ngram Feature Extractor initialized, n = 3
[00.34.31]	Ngram Feature Extractor initialized, n = 3
[00.34.31]	Start extract ngram feature! n = 1
[00.34.46]	[NGramFE] First pass vocab scan, #vocab = 31044
[00.34.46]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[00.35.05]	POS Ngram Feature Extractor initialized, n = 2
[00.35.43]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[00.35.43]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1117


======================================================
*********************************************************
Start logging 20130320003849
 ../Util/Log.pyc

[00.38.49]	Ngram Feature Extractor initialized, n = 3
[00.38.49]	Ngram Feature Extractor initialized, n = 3
[00.38.49]	Start extract ngram feature! n = 1
[00.39.05]	[NGramFE] First pass vocab scan, #vocab = 31044
[00.39.05]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[00.39.23]	POS Ngram Feature Extractor initialized, n = 2
[00.40.01]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[00.40.01]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1117


======================================================
*********************************************************
Start logging 20130320004128
 ../Util/Log.pyc

[00.41.28]	Ngram Feature Extractor initialized, n = 3
[00.41.28]	Ngram Feature Extractor initialized, n = 3
[00.41.29]	POS Ngram Feature Extractor initialized, n = 2
[00.42.09]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[00.42.09]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1117


======================================================
*********************************************************
Start logging 20130320004605
 ../Util/Log.pyc

[00.46.05]	Ngram Feature Extractor initialized, n = 3
[00.46.05]	Ngram Feature Extractor initialized, n = 3
[00.46.06]	ProdRule Feature Extractor initialized, n = 2
[00.46.46]	[ProdRuleFe] First pass vocab scan, #vocab = 9362
[00.46.46]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 3001


======================================================
*********************************************************
Start logging 20130320005040
 ../Util/Log.pyc

[00.50.40]	Ngram Feature Extractor initialized, n = 3
[00.50.40]	Ngram Feature Extractor initialized, n = 3
[00.50.40]	Start extract ngram feature! n = 1
[00.50.55]	[NGramFE] First pass vocab scan, #vocab = 31044
[00.50.55]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[00.51.12]	Start extract ngram feature! n = 2
[00.51.27]	[NGramFE] First pass vocab scan, #vocab = 168275
[00.51.27]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 21313
[00.51.46]	Done! Number of instance wrote: 240154
[00.51.46]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram.arff.libsvm
[00.51.46]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram.arff -o /home/xj229/data/3nat_lvl123_15K.1gram.arff.libsvm
[00.51.58]	Done! Number of instance wrote: 238733
[00.51.58]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.2gram.arff
to: /home/xj229/data/3nat_lvl123_15K.2gram.arff.libsvm
[00.51.58]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.2gram.arff -o /home/xj229/data/3nat_lvl123_15K.2gram.arff.libsvm
[00.52.38]	Done! Number of instance wrote: 240154
[00.52.38]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.12gram.arff
to: /home/xj229/data/3nat_lvl123_15K.12gram.arff.libsvm
[00.52.38]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.12gram.arff -o /home/xj229/data/3nat_lvl123_15K.12gram.arff.libsvm
[00.53.37]	POS Ngram Feature Extractor initialized, n = 2
[00.54.16]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[00.54.16]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1117
[00.54.59]	Done! Number of instance wrote: 240168
[00.54.59]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS.arff
to: /home/xj229/data/3nat_lvl123_15K.POS.arff.libsvm
[00.54.59]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS.arff -o /home/xj229/data/3nat_lvl123_15K.POS.arff.libsvm
[00.55.08]	Done! Number of instance wrote: 240168
[00.55.08]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram_POS.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram_POS.arff.libsvm
[00.55.08]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram_POS.arff -o /home/xj229/data/3nat_lvl123_15K.1gram_POS.arff.libsvm
[00.56.09]	ProdRule Feature Extractor initialized, n = 2
[00.56.48]	[ProdRuleFe] First pass vocab scan, #vocab = 9362
[00.56.48]	[ProdRuleFe] Applied minimum frequency cut-off (#attr) #vocab = 4178
[00.57.31]	Done! Number of instance wrote: 240006
[00.57.31]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.Pr.arff
to: /home/xj229/data/3nat_lvl123_15K.Pr.arff.libsvm
[00.57.31]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.Pr.arff -o /home/xj229/data/3nat_lvl123_15K.Pr.arff.libsvm
[00.57.42]	Done! Number of instance wrote: 240167
[00.57.42]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram_Pr.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram_Pr.arff.libsvm
[00.57.42]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram_Pr.arff -o /home/xj229/data/3nat_lvl123_15K.1gram_Pr.arff.libsvm


======================================================
*********************************************************
Start logging 20130320112301
 ../Util/Log.pyc

[11.23.01]	POS Ngram Feature Extractor initialized, n = 2
[11.23.34]	[PosNGramFE] First pass vocab scan, #vocab = 0
[11.23.34]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 0
[11.24.09]	Done! Number of instance wrote: 0
[11.24.09]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS1.arff
to: /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm
[11.24.09]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS1.arff -o /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm


======================================================
*********************************************************
Start logging 20130320112441
 ../Util/Log.pyc

[11.24.41]	POS Ngram Feature Extractor initialized, n = 2
[11.25.19]	[PosNGramFE] First pass vocab scan, #vocab = 46
[11.25.19]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 46
[11.26.01]	Done! Number of instance wrote: 240168
[11.26.01]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS1.arff
to: /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm
[11.26.01]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS1.arff -o /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm


======================================================
*********************************************************
Start logging 20130320112650
 ../Util/Log.pyc

[11.26.50]	Ngram Feature Extractor initialized, n = 3


======================================================
*********************************************************
Start logging 20130320112719
 ../Util/Log.pyc

[11.27.19]	Ngram Feature Extractor initialized, n = 3
[11.27.19]	Start extract ngram feature! n = 1
[11.27.34]	[NGramFE] First pass vocab scan, #vocab = 31044
[11.27.34]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[11.27.52]	POS Ngram Feature Extractor initialized, n = 2
[11.28.28]	[PosNGramFE] First pass vocab scan, #vocab = 46
[11.28.28]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 46
[11.29.10]	Done! Number of instance wrote: 240168
[11.29.10]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS1.arff
to: /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm
[11.29.10]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS1.arff -o /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm
[11.29.17]	Done! Number of instance wrote: 240168
[11.29.17]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff.libsvm
[11.29.17]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff -o /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff.libsvm
[11.29.18]	POS Ngram Feature Extractor initialized, n = 2
[11.29.56]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[11.29.56]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1117
[11.30.40]	Done! Number of instance wrote: 240168
[11.30.40]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS2.arff
to: /home/xj229/data/3nat_lvl123_15K.POS2.arff.libsvm
[11.30.40]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS2.arff -o /home/xj229/data/3nat_lvl123_15K.POS2.arff.libsvm
[11.30.49]	Done! Number of instance wrote: 240168
[11.30.49]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff.libsvm
[11.30.49]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff -o /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff.libsvm
[11.30.55]	Done! Number of instance wrote: 240168
[11.30.55]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS12.arff
to: /home/xj229/data/3nat_lvl123_15K.POS12.arff.libsvm
[11.30.55]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS12.arff -o /home/xj229/data/3nat_lvl123_15K.POS12.arff.libsvm


======================================================
*********************************************************
Start logging 20130320115211
 ../Util/Log.pyc

[11.52.11]	Ngram Feature Extractor initialized, n = 3
[11.52.11]	Start extract ngram feature! n = 1
[11.52.27]	[NGramFE] First pass vocab scan, #vocab = 31044
[11.52.27]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 6591
[11.52.44]	POS Ngram Feature Extractor initialized, n = 2
[11.53.21]	[PosNGramFE] First pass vocab scan, #vocab = 46
[11.53.21]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 46
[11.54.03]	Done! Number of instance wrote: 240168
[11.54.03]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS1.arff
to: /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm
[11.54.03]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS1.arff -o /home/xj229/data/3nat_lvl123_15K.POS1.arff.libsvm
[11.54.10]	Done! Number of instance wrote: 240168
[11.54.10]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff.libsvm
[11.54.10]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff -o /home/xj229/data/3nat_lvl123_15K.1gram_POS1.arff.libsvm
[11.54.28]	POS Ngram Feature Extractor initialized, n = 2
[11.55.07]	[PosNGramFE] First pass vocab scan, #vocab = 1344
[11.55.07]	[NGramFE] Applied minimum frequency cut-off (#attr) #vocab = 1117
[11.55.50]	Done! Number of instance wrote: 240168
[11.55.50]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS2.arff
to: /home/xj229/data/3nat_lvl123_15K.POS2.arff.libsvm
[11.55.50]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS2.arff -o /home/xj229/data/3nat_lvl123_15K.POS2.arff.libsvm
[11.55.59]	Done! Number of instance wrote: 240168
[11.55.59]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff
to: /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff.libsvm
[11.55.59]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff -o /home/xj229/data/3nat_lvl123_15K.1gram_POS2.arff.libsvm
[11.56.25]	Done! Number of instance wrote: 240168
[11.56.25]	Start converting from ARFF to LIBSVM format:
from: /home/xj229/data/3nat_lvl123_15K.POS12.arff
to: /home/xj229/data/3nat_lvl123_15K.POS12.arff.libsvm
[11.56.25]	java -Xmx5000M -cp /home/xj229/tools/weka/weka.jar weka.core.converters.LibSVMSaver -c first -i /home/xj229/data/3nat_lvl123_15K.POS12.arff -o /home/xj229/data/3nat_lvl123_15K.POS12.arff.libsvm
